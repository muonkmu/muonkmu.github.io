[{"content":"본 강좌에서는 Object Detection의 개념과 이를 위한 YOLO알고리즘의 기초에 대하여 정리한다.\nhttps://www.coursera.org/learn/convolutional-neural-networks 하기 블로그에 더 잘 정리되어 있다..(누군지 존경스럽다.)\nhttps://junstar92.tistory.com/140 Object Localization Classification with localization : object class 뿐 아니라, 알고리즘이 object를 대상으로 bounding box를 표시하는 것을 의미\n이를 위해 이미지를 CNN에 입력 출력으로 class 뿐만 아니라 이미지에 object가 존재할 확률($p_c$), Bounding box의 위치 및 크기를 같이 출력(Bx, By, Bh, Bw) Loss function은 MSE(mean squared error)를 사용한다면 Y 각 요소의 에러의 합과 같다. Pc가 0일 경우 Pc의 에러만 사용한다. $$ L(\\hat{y},y) = \\begin{cases} (\\hat{y}_1-y_1)^2+(\\hat{y}_2-y_2)^2+\\cdots+(\\hat{y}_8-y_8)^2 \u0026amp; \\text{if } y_1=1 \\\\ (\\hat{y}_1-y_1)^2 \u0026amp; \\text{if } y_1=0 \\end{cases} $$\nMSE를 예시로 설명했지만, $c_1$, $c_2$, $c_3$에는 log-likelihood loss와 softmax를 사용하고, bounding box 정보에는 MSE를, 그리고 $p_c$ 에는 Logistic Regression Loss를 사용할 수도 있다.\nLandmark Detection Bounding box가 아닌 일반적인 Face recognition이나 pose detection의 같은 일반적인 경우 이미지의 주요 포인트(landmark)를 X와 Y의 좌표로 나타낼 수 있다. Object Detection Sliding Windows Detection 알고리즘을 사용해서 Object Detection을 위해 ConvNet을 사용하는 방법 알아본다. (CS231n 강의에서는 Sliding window는 하지말라던데 아마 이해를 위해 넣어놓은 것 같다.) 방법은 하기와 같다. object의 클래스를 구분할 수 있는 모델 생성 전체 이미지 중 특정 size의 window를 골라 탐색 window 살짝 옮겨서 반복 더 큰 박스를 이용하여 반복 그러나 이 방법은 computing cost가 높다. 다음 절에서 이를 줄일 수 있는 방법을 알아본다 Convolutional Implementation of Sliding Windows Sliding window 방법은 매우 느린데 이를 해결하기 위해 FC(Full connected) layer를 Convolutional Layer로 튜닝하는 것을 알아보자. 절차는 하기와 같다 FC layer를 이와 같은 output을 낼 수 있는 Filter로 변환 sliding window 시 각각 수행이 아닌 convolution처럼 한번에 연산. 이렇게 하면 중복되는 연산은 공유가 가능하다. 그러나 이 방법은 bounding box의 위치가 정확하지 않다는 단점이 있는데 이를 아래 방법으르 해결한다. Bounding Box Predictions Sliding window 방법은 object가 그 위치에 있지 않거나 일부분만 걸칠 수 있는데 이를 YOLO 알고리즘으로 극복 가능하다. 전체 이미지에 3x3 grid 를 설정(보통은 19x19 사용) 위에서 배운 object localization을 각각의 grid에 적용, 즉 이해한바로는 test set에서 각각의 그리드에 localization방법으로 labeling하고 학습 각 grid에 object가 존재한다면 object의 중간점을 위해서 object를 할당한다. 이때 object의 크기는 1이 넘어갈 수 있다.(gird를 넘어가거나 클 수 있으므로) Bounding box를 설정하는 방법은 여러가지가 있지만(ex. PCA 이용), YOLO논문을 살펴보면 잘 동작할 수 있도록 파라미터화 된 것들이 있다. Intersection Over Union Intersection over union(IoU)은 Object Detection이 잘 동작하는지 판단하기 위한 함수 labeling 된 bounding box와 예측한 bounding box의 전체 넓이와 겹치는 부분 넓이의 비율을 계산 보통 0.5 이상이면 예측한 bounding box의 결과가 옳다고 판단 Non-max Suppression 현재까지 알아본 Object detection의 문제점은 한 Object를 여러번 탐지할 수 있다는 것이다. 즉 한 object가 한 그리드 이상에의 면적을 차지할 경우 이 object의 중심점이 여러 Cell에서 탐지 될 수 있다. 이 경우에 Non-max suppression을 사용하면 알고리즘이 하나의 object를 하나의 cell에서 한번만 탐지할 수 있다. 만약 분류 class 가 1개여서 $p_c$가 class의 확률이라 가정한다. (실제로는 클래스는 여러개) $p_c$를 조사하여 가장 큰 것만 취함 나머지 box와 $p_c$값이 가장 큰 박스와 IoU 조사 IoU가 높은 박스는 제거 만약 class가 여러개라면 class 당 non-max suppression을 수행한다. Anchor Boxes 현재까지 소개한 알고리즘의 문제점 중 하나는 각 grid cell이 오직 하나의 object만 감지할 수 있다는 것이며 이를 anchor box라는 아이디어를 가지고 해결할 수 있다. anchor 박스의 모양을 미리 정의 각각의 anchor box는 각 output을 가지게 한다. anchor box의 선택은 manual로 선택을 할 수도 있고, K-mean알고리즘을 통해서 얻고자하는 유형의 object모양 끼리 그룹화 할 수도 있다. YOLO Algorithm 위의 내용을 모두 종합하여 YOLO object detection algorithm을 정리해보자 이미지의 anchor box와 grid 수를 정하고 이와 같이 labeling된 데이터 셋으로 모델을 학습 상기 모델로 추론을 수행하게 되면 각 grid cell은 anchor box 수만큼의 bounding box를 가질 수 있다. 여기서 낮은 확률을 가지는 예측결과는 제거하고 각 class에 non-max suppression을 적용하여 최종 예측 결과를 얻는다. YOLO 알고리즘은 가장 효과적인 Object Detection 알고리즘 중 하나 ","date":"2023-01-10T00:00:00Z","permalink":"https://muonkmu.github.io/p/cnn-week-03-object-detection/","title":"[CNN] week 03 Object detection"},{"content":"본 챕터에서는 몇가지 주요한 Paralle Architecture에 대하여 소개한다. 이 페이지에서는 NVDLA와 Google TPU에 대해서 기술한다.\nNVIDIA Deep Learning Accelerator (NVDLA) NVDLA는 FPGA로 구성 가능한 추론을 위한 오픈소스 아키텍쳐 (http://nvdla.org) Primitive functional blocks으로 CNN을 지원 (convolution, activation, pooling, normalization) 각 블럭은 next layer의 active와 configuration을 위한 double buffer를 가짐 next layer의 operation은 active operation이 완료되어야 시작 independent mode와 pipeline을 사용하는 fused mode가 있음 Figure. NVDLA core architecture Convolution Operation Direct convolution, Image input convolution, winograd convolution, Batch convolution 지원 (상세내역은 책 참조) Single Data Point Operation(SDP) SDP는 linear functions와 Look-up Table nonlinear functions을 통해 activation과 normalizatin을 지원 (상세내역은 책 참조) Planar Data Operation(PDP) PDP는 maximum/minimum/average pooling을 지원 Multiplane Operation Cross Channel Data Processor(CPD)은 Local Response Normalization(LRN)을 수행 Data Memory and Reshape Operations bridge DMA는 외부 메모리와 메모리 인터페이스간 데이터 전송을 담당 data reshape engine은 data trasnformations, splitting, slicing, merging, contraction, reshape transpose 를 담당 System Configuration NVDLA는 small/large system model로 구현할 수 있음 small system model : IoT 기기와 같이 작은 모델을 위한 모델, 복잡도와 storage를 낮추고 single task를 수행 large system model : mutiple task를 위한 coprocessor와 메모리 인터페이스 추가 External Interface NVDLA는 외부와 통신을 위한 Configuration Space Bus(CSB), Data backbone(DBB), SRAM interface, Interrupt interface를 가짐 (상세내용은 책 참조) Software Design NVDLA SW는 Trained model을 parser/compiler/optimizer를 통해 loadable로 변환 User Mode Driver(UMD)에 의해 Loadalbe이 로딩 되고 Job이 Kernel Mode Driver(KMD)로 제출됨, KMD는 스케줄링 수행 Google Tensor Processing Unit(TPU) 구글은 speech recognition 수요 해결을 위해 TPU v1(stand alone)과 v2/v3(cloud)를 개발 TPU v1은 하기 스펙으로 MLP 0/1, CNN 0/1, RNN 0/1 6가지 neural network application을 수행 가능 256 × 256 eight bits MAC unit 4 Mb on-chip Accumulator Memory (AM) 24 Mb Unified Buffer (UB) – activation memory 8 Gb off-chip weight DRAM memory Two 2133 MHz DDR3 channels System Architecture Multipy-Accumulate(MAC) Systolic Array New Brain Floating-point Format Performance Comparision Cloud TPU configuration Cloud Software Architecture ","date":"2022-12-30T00:00:00Z","permalink":"https://muonkmu.github.io/p/ai-hw-design-chap03-parallel-architecture-2/2/","title":"[AI HW Design] Chap03 Parallel Architecture (2/2)"},{"content":"IDEC에서 수강한 KiCad 강좌 요약 이다. 디자인 플로우 중 Footprint와 PCB에 대해 정리한다.\nFootprint Footprint design flow footprint 편집기를 연다 실부품 측정 또는 데이터 시트를 참조하여 부품 치수 확인 필요 시 풋프린트 라이브러리 생성 (파일-\u0026gt;새라이브러리) 라이브러리 선택 후 새 풋프린트 생성 하거나 유사한 부품 불러 온 후 다른 이름으로 저장 십자선 커서 이용하여 원점에서 스페이스바를 눌러 원점 위치 선정 실크 레이어에 부품 외형선 그리기 패드와 홀 위치 시킨 후 사이즈 속성 편집 패드 위치에 맞게 번호 편집, 핀번호는 심볼과 일치하도록 할 것 저장 SMD Component Footprint SMD 부품의 경우 패드의 속성을 SMD로 변경 뒷면 실장 component 뒷면에 실장할 경우 레이어를 관련 레이어를 B.* 레이어로 변경해야 한다. F.Cu, F.Silkscreen, F.Courtyard, F.Fab 내용을 B.* 레이어로 이동 PCB design 프로젝트 매니저에서 PCB 편집기 열기 회로도 PCB 전환(F8)을 이용하여 회로도에서 컴포넌트를 로딩 Edge.Cuts layer에서 PCB 외형선을 그리기 외형선 내부에 컴포넌트 배치 및 컴포넌트 레퍼런스/value 위치 조정 필요한 텍스트를 Silkscreen에 부가 트랙 설정 및 배선 (일반적으로 신호선 12mil, 전원선 30mil) 동박면 씌우기 (GND와 연결) DRC 검사 Plot을 통해 거버/드릴링/포지션 파일 생성 및 검사 ","date":"2022-12-28T00:00:00Z","permalink":"https://muonkmu.github.io/p/kicad-footprint-and-pcb/","title":"[KiCad] Footprint and PCB"},{"content":"IDEC에서 수강한 KiCad 강좌 요약 이다. 디자인 플로우 중 Symbol and Schemetic에 대해 정리한다.\nKiCad 개요 회로도 및 PCB가 함께 설계되는 오픈소스 통합 설계도구 거버 /드릴/ 부품위치 파일 생성 및 PCB 계산기, 거버 뷰어, 3D 뷰어, SPICE 시뮬레이터 포함 프로젝트 기반 관리로 한번에 하나의 프로젝트만 열 수 있음 파일구성 *.kicad_pro : 회로도와 pcb간 공유되는 설정이 포함된 프로젝트 파일 *.kicad_sch : 모든 정보와 구성 요소 자체를 포함시키는 회로도 파일 *.kicad_sym : 회로도 심볼 라이브러리 파일로 심볼 요소 설명을 포함 *.kicad_pcb : pcb 보드 파일 *.pretty : 풋프린트 라이브러리 폴더 *.kicad_dru : pcb 사용자 설계 규칙 파일 *.net. : 회로도에 의해 생성되는 넷리스트 파일 KiCad PCB design workflow 프로젝트 생성 회로도 그리기 회로도 심볼을 심볼 라이브러리에서 찾아 지정된 선 연결, 심볼이 없을 경우 새로 심볼을 새로 만듬 각 구성 요소에 대해 풋프린트를 배정하고 풋프린트가 없는 경우 풋프린트를 생성하여 반영 회로도 완성 시 전기 규칙 점검(ERC 수행) pcb 편집기로 전송하여 레이아웃 시작(넷리스트 생성 및 부품 간 선 연결 일치 시킴) 기판 크기(Edge.Cuts) 그리기 및 풋프린트 위치를 선정 배치 배치 후 요소 사이 트랙 연결 트랙은 규정에 따라 전류 용량, 임피던스, 고전압 누화 등을 고려 선폭/선간 설정 (pcb계산기 참조) 트랙은 신호선의 경우 보통 12mil, 6mil 이하로 하면 pcb 제작 단가 상승 레이아웃이 완료되고 설계 규칙 검사(DRC) 및 수정 거버 파일 제작 출력 및 PCB 제작 의회 프로젝트 관리 창 Tip 1 : 프로젝트 생성 시 템플릿을 지정하여 생성 가능 (큰 회사에서 기초 설정 등을 지정한 형식) Tip 2 : 환경 설정에서 텍스트 편집기를 등록하면 텍스트 편집기 사용이 가능하다. Symbol 생성 필요 시 심볼 라이브러리 생성 (파일-\u0026gt;새라이브러리) 라이브러리 선택 후 새 심볼 생성 생성된 심볼에서 레퍼런스, 심볼값을 원하는 위치로 이동 외형선 그리기, 핀 부가, 핀 더블 클릭 하여 속성(이름, 번호, 유형 등) 설정 필요 시 원점 설정 (단축키 space)(심볼 로딩 위치 및 로테이션 시 회전 점) 저장 Tip) 편집 시 원하는 위치에 지정할 수 없을 때 그리드 속성을 편집하여 그리드 간격을 조절하자 회로도 그리기 프로젝트 매니저에서 {프로젝트 이름}.kicad_sch 파일을 연다 심볼을 배치한다 (전원의 경우 pspice 라이브러리는 시뮬레이션 용이니 Power라이브러리 사용) 선을 연결하고 텍스트 위치 조정한다. 레퍼런스 (부품번호, ex. R100) 지정자 채우기 로 레퍼런스 설정 PCB 풋 프린트 배정 ERC 수행/수정 및 BOM 출력 ","date":"2022-12-28T00:00:00Z","permalink":"https://muonkmu.github.io/p/kicad-symbol-and-schemetic/","title":"[KiCad] Symbol and Schemetic"},{"content":"본 chapter에서는 Reinforcement Learning에 대해서 알아보자\nVideo : https://www.youtube.com/watch?v=lvoHnicueoE\u0026list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv\u0026index=15 Slide : http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture14.pdf (TODO: 귀차니즘의 압박으로 정리를 안했다.. 근데 강의가 무척 어려워서 잘 이해가 안된다.)\n","date":"2022-12-23T00:00:00Z","permalink":"https://muonkmu.github.io/p/cs231n-chap-14-reinforcement-learning/","title":"[CS231n] Chap 14 Reinforcement Learning"},{"content":"Petalinux Booting and Packaging petalinux Packaging petalinux-package 명령을 이용하여 하기 내역을 수행 할 수 있다. .BIN 또는 .MCS파일을 생성 (\u0026ndash;boot 옵션) BSP (.BSP 파일) 또는 Package image 생성 (\u0026ndash;bsp, \u0026ndash;image 옵션) prebuilt 디렉토리 생성 (\u0026ndash;prebuilt 옵션) Vitis 를 위한 sysroot 설치 (\u0026ndash;sysroot 옵션) petalinux booting QEMU, SD card, Jtag, TFTP, QSPI에 의한 Booting을 지원한다. (jtag Boot는 속도가 느려 잘 사용안함)\nPetalinux Debugging 상세 내용은 교제의 Petalinux Application Debugging 및 LAB5 참조\nPetalinux는 Application Debugging 시 System Debugger(Vitis) 와 GNU Debugger를 지원한다. Vitis는 Target Communication Framework(TCF)와 Xilinx System DBugger(XSDB)를 이용한 Debugging 환경을 제공 일반적인 Linux GNU Debugger 지원 System Debugger 방법 https://xilinx.github.io/Embedded-Design-Tutorials/docs/2022.2/build/html/docs/Introduction/ZynqMPSoC-EDT/ZynqMPSoC-EDT.html 참조 petalinux-config -c rootfs를 이용하여 Root File system에 하기 내역을 포함 시킨다. tcf-agent (default enable) openssh-sftp-server dropbear (default disable) 이미지를 빌드 하고 디버깅하고자 하는 Application을 실행 시킨다. QEMU의 경우 GEM0만 연결되어 있으므로 필요 시 GEM3 등의 Device Tree를 추가하여 빌드한다. vitis를 실행 시키고 *.XSA 파일 등을 이용하여 platform project를 구성한다. platform project에 빈 linux Applicaiton domain을 추가한다. 4)항의 항목내 Debug configuration을 이용하여 Single Application Debug를 추가한다. target 보드의 debug IP/port를 설정하고 파일 패스를 설정한다. GNU Debuger GNU 디버거를 사용하기 위해서는 Root file System에 gdbserver를 포함하여야 한다. Custom HW and Driver Development Xilinx는 Custop IP에 대한 디바이스 제어를 위해 하기의 방법을 제안한다. Linux Device Driver 제작 mmap의 사용 (사용이 쉽다. 인터럽트 핸들링이 안됨) User space I/O (UIO 사용) (간단한 IRQ핸들링이 된다, Latency가 가변적이고 DMA가 지원되지 않는다) Petalinux는 빌드 시 Device Tree Generator가 DTSI/DTS파일을 생성하고 DTB를 만든다 *.XSA 파일을 분석하여 기본적인 DTSI/DTS 파일을 만든다 {project-root}/components/plnx_workspace/device-tree/device-tree에 생성되는 DTSI파일은 다음과 같다 pl.dtsi : memory-mapped PL IP node pcw.dtsi : Dynamic properties of the PS peripheral system-top.dts : boot argument 와 console, memory information zynqmp.dtsi : PS peri and CPU information zynqmp-clk-ccf.dtsi : IP peri를 위한 clock information Custop IP 추가 등 Device tree를 업데이트 하기 위해 하기 DTSI를 업데이트 한다. {project-root}/project-spec/meta-user/recipes-bsp/device-tree/files/system-user.dtsi Custom HW and Petalinux 개발 절차 Custop IP를 개발(RTL 등) 후 Vivado IP Packer를 통하여 IP-XACT Standard Format으로 패키징 한다. Vivado를 이용하여 1)항의 IP와 기타 사용자 IP를 조합하여 *.XSA 파일을 생성한다. petalinux-creat -t project -n {project 이름}를 이용하여 project를 생성하고 *.XSA 파일을 import한다. petalinux-creat -t module -n {driver 이름}을 이용하여 모듈을 생성한다. {project-root}/project-spec/meta-user/recipes-bsp/device-tree/files/system-user.dtsi에 Custom IP에 관련된 Device tree를 업데이트한다. 작성 시 pl.dtsi를 확인하여 module name 및 address 등을 확인한다. 모듈 내부 드라이버 파일을 작성하고 Yocto 레시피를 수정한다. 커널에 로딩할 지 모듈로 rootfs에 등록할지 결정한 후 빌드한다. ","date":"2022-12-22T00:00:00Z","permalink":"https://muonkmu.github.io/p/petalinux-petalinux-advance/","title":"[Petalinux] Petalinux Advance"},{"content":"Petalinux Basic petalinux 정의 Petalinux는 xillinx FPGA를 위한 임베디드 리눅스 개발 툴로 YOCTO 프로젝트 Wrapper이다. Hardware description file(*.XSA) 또는 BSP 파일을 입력으로 리눅스 이미지 생성 Petalinux 프로젝트의 레이아웃은 프로젝트 생성 시, XSA import 시, build 시 추가/달라짐 (교재 p66을 참조 및 https://docs.xilinx.com/r/2021.1-English/ug1144-petalinux-tools-reference-guide/Image-Selector?tocId=nfcK0XF5PXQyI2ebTdA8fA) 기본 명령어 및 Design Flow 상세 내용은 교제의 Petalinux Tool : Design Flow 및 LAB2 참조\n프로젝트 생성\npetalinux-create -t {type} -n {name} \u0026ndash;template {기초 템플릿} 1 petalinux-create -t project -n test_prj --template zynqMP 프로젝트 설정 : Hardware Description 및 boot, rootfs, kernel\npetalinux-config -c {rootfs/kernel/device-tree/u-boot} 1 2 cd test_prj petalinux-config --get-hw-description={xsa file} --silentconfig 프로젝트 빌드\n1 petalinux-build 프로젝트 패키징\n.BIN 또는 .MCS 생성 ( = fsbl + ssbl + pmu + bitstream) 1 petalinux-package --boot --fsbl zynqmp_fsbl.elf --u-boot u-boot.elf --pmufw pmufw.elf --fpga system.bit 부트\nSD카드에 이미지 복사(BOOT.BIN, Image, rootfs.cpio.gz.u-boot, boot.scr) 후 보드 부팅 qemu로 에뮬레이션 가능 1 petalinux-boot --qemu --kernel Application development 상세 내용은 교제의 p133 Petalinux Application Development 및 LAB3 참조\nPetalinux의 project가 생성된 상태에서 petalinux-create를 사용하여 app을 생성\nproject-spec/meta-user/recipes-apps/{app_name}에서 생성된 파일(bb 및 source) 확인 가능 1 petalinux-create -t apps --name helloworld --template c source 및 makefile을 생성 또는 복사한다.\nproject-spec/meta-user/recipes-apps/{app_name}/file에서 수정한다. Yocto Recipe file를 수정한다.\nproject-spec/meta-user/recipes-apps/{app_name}의 {app_name}.bb파일에 관련파일을 등록한다. root filesystem에 등록한다.\npetalinux-config -c rootfs 수행 후 apps 메뉴에서 등록 build 후 /usr/bin에서 app을 확인 가능하다.\n프로젝트 설정 상세 내용은 교제의 p150 Customizing the project 참조 petalinux-config를 이용하여 하기 설정이 가능하다\nfirmware version 정보 root filesystem 종류 : INITRD, INITRAMFS JFFS2, UBI/UBIFS, NFS, EXT4(SD/eMMC\u0026hellip;) U-boot 이미지 저장 위치 : bootenv 조절을 통해 Jtag/DDR, QSPI, NAND의 image offset을 조정할 수 있다. Primary Flash(QSPI?)의 파티션 조절 가능 File system package를 조절하여 Kernel image size 및 Root file system 이미지 사이즈를 줄일 수 있다. TFTP 부팅을 위한 pre-built 이미지 위치를 설정할 수 있다 NFS 또는 SD card를 통한 Root file system 로딩을 설정 할 수 있다. Root file system customize 상세 내용은 교제의 p212 Customizing the Root File System 참조\ncustom applications, libraries, module을 추가하거나 생성 가능 pre-compiled applications, libraries, module을 추가하거나 생성 가능 YOCTO layer, recipes 또는 package 추가 가능 ","date":"2022-12-19T00:00:00Z","permalink":"https://muonkmu.github.io/p/petalinux-petalinux-basic/","title":"[Petalinux] Petalinux Basic"},{"content":"목표 개인 기술 정리를 위한 블로그의 생성 markdown 사용이 편리한 github.io를 이용하기로 결정 빌드가 빠른 HUGO framework을 사용 (github에서는 Jekyll framework가 기본이나 컨텐츠가 쌓이면 빌드가 느려지는 단점이 있음) Hugo theme는 STACK을 사용 개발 환경 Oracle Cloud Arm server Ubuntu 20.40 code-server 사전 준비 GO 설치 Hugo는 GO로 작성되 있으므로 GO를 설치한다.\nref : https://go.dev/doc/install 필요 시 GO의 설치 경로를 PATH에 등록한다. Hugo 설치 리눅스의 경우 패키지 관리자를 이용하여 설치가 가능하나 이 경우 old 버전이 설치된다. STACK 테마의 경우 최신버전과 hugo extension이 필요하므로 Go를 이용하여 설치한다. https://gohugo.io/installation/linux/ 1 go install -tags extended github.com/gohugoio/hugo@latest 필요 시 Hugo의 설치 경로를 PATH에 등록한다. git repo 생성 hosting을 위한 repo를 생성한다. repo의 이름은 {git ID}.github.io 형식 ex) muonkmu.github.io 호스팅 목적이므로 repo는 public hugo 빌드 전 소스를 보관할 repo를 생성한다. 이름은 상관 없음 ex) blog 소스 보관용이므로 public/private은 개인 취향 블로그 작성 및 배포 hugo 프로젝트 생성 및 테마 설정 프로젝트를 생성 후 폴더 이동, 하기 예제의 이름은 hugoBlog로 가정 1 2 hugo new site hugoBlog cd hugoBlog git 초기화 및 테마 설정 하기 예제에서는 Stack 테마 사용 clone으로 테마 소스를 themes폴더에 넣을 수도 있으나 submodule을 추천 1 2 git init git submodule add https://github.com/CaiJimmy/hugo-theme-stack.git themes/hugo-theme-stack config파일 설정 config.toml을 수정, 하기 예제에서는 stack 테마의 예제 파일을 복사/수정 한다. config.yaml의 baseurl, theme, title 등을 수정한다. 1 2 3 rm config.toml cp themes/hugo-theme-stack/exampleSite/config.yaml ./ cp themes/hugo-theme-stack/exampleSite/content ./ 1 2 3 4 5 baseurl: https://muonkmu.github.io/ languageCode: en-us theme: hugo-theme-stack paginate: 7 title: MW Devlog 컨텐츠 작성 및 테스트 categories, post, page 등을 작성한다. 하기 예제에서는 stack 테마의 예제 파일을 복사/수정 한다. content/post 내 예제 파일을 참조하여 post를 작성한다(예제포스트는 지워도 된다.) 1 2 rm -r content cp themes/hugo-theme-stack/exampleSite/content ./ 테스트 서버를 구동하여 동작을 확인한다. 하기 예제에는 orcle 서버에서 개발하는 것을 가정, 내부 바인딩과 포트를 별도로 할당였다(오라클 서버에서 방화벽에 우선적으로 포트을 열어둬야 함) 웹 브라우저로 테스트 서버에 접속해 동작을 확인한다. 1 hugo server -D --bind=0.0.0.0 -p 8070 빌드 및 배포 github repo를 연결한다. 소스 repo에 프로젝트 폴더를 연결 host repo에 public 폴더를 연결 1 2 3 git remote add origin https://github.com/muonkmu/blog.git rm -r public git submodule add -b master https://github.com/muonkmu/muonkmu.github.io.git public 소스를 빌드한다. 하기 예제에서는 stack 테마의 사용 경우이다. 1 hugo -t hugo-theme-stack 빌드 및 소스 파일을 push 한다. 1 2 3 4 5 6 7 8 9 10 cd public git add . git commit -m \u0026#34;first commit\u0026#34; git branch -M main git push origin main cd .. git add . git commit -m \u0026#34;first commit\u0026#34; git branch -M main git push origin main (option)배포에 시 사용할 쉘 스크립트를 작성한다. ex)deploy.sh 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #!/bin/bash hugo -t hugo-theme-stack cd public git add . msg=\u0026#34;rebuilding site `date`\u0026#34; if [ $# -eq 1 ] then msg=\u0026#34;$1\u0026#34; fi git commit -m \u0026#34;$msg\u0026#34; git push origin main cd .. git add . msg=\u0026#34;rebuilding site `date`\u0026#34; if [ $# -eq 1 ] then msg=\u0026#34;$1\u0026#34; fi git commit -m \u0026#34;$msg\u0026#34; git push origin main ","date":"2022-12-13T00:00:00Z","permalink":"https://muonkmu.github.io/p/github-blog-%EB%A7%8C%EB%93%A4%EA%B8%B0/","title":"Github blog 만들기"},{"content":"본 챕터에서는 몇가지 주요한 Paralle Architecture에 대하여 소개한다. 이 페이지에서는 CPU와 GPU에 대해서 우선 기술한다.\nIntel Central Processing Unit (CPU) https://www.intel.com/content/www/us/en/developer/articles/technical/xeon-processor-scalable-family-technical-overview.html CPU는 병렬 프로세싱을 위해 Single Instruction Single Data (SISD) architecture에서 Single Instruction Multiple Data (SIMD)로 진화함. 그러나 이는 딥러닝과 같은 거대 병렬 처리에 적합하지 못하여 2017년 딥러닝 어플리케이션을 위한 Xeon processor scalable family (purley platform) 발표 Purley platform은 하기 특징을 가짐 Skylake mesh architecture 이전 Grantley platform에서는 Last-Level Chache(LLC)등이 Intel Quick Path Interconnect(QPI) ring achitecture로 연결 상기 구조는 코어 증가 시 코어 마다 사용가능한 bandwidth가 줄어들어서 메모리 latency가 증가 Grantley platform에서는 Intel Ultra Path Interconnect(UPI) mesh archictecture로 업그레이드 Comnined Home Agent(CHA)가 통합, 이는 LLC 등의 주소 정보 지도를 작성하며 이는 mesh 연결에서 목적지까지의 라우팅 정보를 제공 Fig1. Intel Xeon processor Scalable family mesh architecture Intel Ultra Path Interconnect UPI는 어드레스를 공유하는 mutiple processor coherent interconnect UPI는 vertical/horizontal path를 통한 한 코어에서 다른 코어로의 최단 경로를 제공 2소켓, 4소켓 링, 8소켓+크로스바 등 다양한 구조 지원 SubNon-Unified Memory Access Clustering 플랫폼은 모든 코어/LLC를 반씩 + 메모리 컨트롤를 1개씩 가진 SNC 0,1 도메인을 가짐 각 도메인은 각 메모리 컨트롤러에 매핑되는 유니크한 LLC 주소를 가지며 이는 LLC access latency를 낮춤 Cache Hierarchy Change 하기 그림과 같이 변경 LLC 및 MLC size 변경으로 hit rate 증가 Figure 11. Generational cache comparison single/Multiple Socket Parallel Processing UPI와 sub-NUMA의 지원으로 딥러닝 worker process들은 코어셋이나 싱글소켓, 다중소켓에 assign 될 수 있음 Advanced vector software extension Intel Advanced Vector Extension 512(Intel AVX-512)가 Vector Neural Network Instruction(VNNI)를 지원하는 AVX-512)_VNNI로 발전 대충 더 빨라지고 8/16/32 FP vector 연산을 지원한다는 듯(자세한 사항은 책 참조) Math Kernel Library for Deep Neural Network(MKL-DNN) Convolution, pooling, activation, batch normalization으로 구성된 최적화된 MKL-DNN 지원 key feature는 prefetching, data reuse, cache blocking, data layout, vectorization, register blocking이며 자세한 사항은 책 참조 NVIDIA Graphics Processing Unit (GPU) GPU 장점 : 효율적인 floating point 연산, high speed memory support Turing architecture를 개발함 (NVLink2를 위한 HBM2 적용, 캐시 구조 변경 등등) Tensor Core Architecture tensor core란 : 행렬연산 및 MAC를 위한 전용 코어 Turing Tensor core는 이전(Pascal)이 matrix row by row만 지원했으나 4X4X4 연산을 지원하도록 변경 INT8, INT4를 지원하며 정확도를 낮추면 연산 속도 증가 Matrix사이즈가 크면 이를 나누어 연산, 다양한 size의 매트릭스 연산에 대응 가능 https://www.nvidia.com/ko-kr/data-center/tensor-cores/ Winograd Transform 곱셈 횟수를 줄일 수 있는 Winograd Transform을 지원 상기 변환에 대한 연산식은 책과 다른 자료를 참조할 것 Simultaneous Multithreading (SMT) SMT의 경우 Matrix는 행렬을 여러 그룹으로 나누고 이를 병렬로 처리 (Single Instruction Multiple Thread, SIMT 방식) 연산 후 하위 그룹을 재그룹 시킴 High Bandwidth Memory (HBM2) Memory Bottleneck해결을 위해 HBM2 적용 (memory die를 TSV로 뚫어서 스택함) HBM2는 GPU와 NVLink2로 연결됨 NVLink2 Configuration NVLink는 엔비디아가 개발한 와이어 기반 통신 프로토콜 시리얼 멀티 레인 근범위 통신 링크 (PCIE의 속도 문제 해결) Turing 아키텍쳐는 sing MIO를 two×8 bidirectional differential pair NVLink2로 대체 CPU/GPU 메모리 간 directly load/store/atomic 가능 (데이터를 GPU메모리에서 바로 읽을 수 있고 CPU cache에 바로 저장 가능) 다양한 구성을 지원한다. (책을 참조하자) ","date":"2022-12-12T00:00:00Z","permalink":"https://muonkmu.github.io/p/ai-hw-design-chap03-parallel-architecture-1/2/","title":"[AI HW Design] Chap03 Parallel Architecture (1/2)"},{"content":"목적 Ubuntu 20.04 LTS 설치 후 나에게 맞는 설정 및 설정 방법 정리 유의사항 설치 시 언어는 영어, 키보드 영어 자판으로 설치를 권장 개인 설정 Nvidia 그래픽 카드 설정 설치 가능한 드라이버 확인 1 ubuntu-drivers devices 권장 드라이버 설치 1 sudo ubuntu-drivers autoinstall 한영키 동작 설정 입력기 설치 : setting → Region and Language → Input Source → Korean(Hangul) 추가 1항의 추가된 항목 설정에서 Hangul Toggle Key를 Hangul만 남김(option) /usr/share/X11/xkb/symbols/altwin 편집 4행의 key \u0026lt;RALT\u0026gt; ... 부분에서 symbols[Gropu1] = [ Alt_R, Meta_R ] 부분을 [ Hangul ] 로 수정한다. VNC 설치 tigerVNC 설치 1 sudo apt-get install tigervnc-standalone-server tigervnc-xorg-extension 비밀번호 설정 1 vncpasswd ~/.vnc/xstartup 작성 1 2 3 4 5 6 #!/bin/sh # Start Gnome 3 Desktop [ -x /etc/vnc/xstartup ] \u0026amp;\u0026amp; exec /etc/vnc/xstartup [ -r $HOME/.Xresources ] \u0026amp;\u0026amp; xrdb $HOME/.Xresources vncconfig -iconic \u0026amp; dbus-launch --exit-with-session gnome-session \u0026amp; vnc 서버 실행 1 vncserver -localhost no vnc 서버 종료 1 vncserver -kill :2 설정변경 : $\u0026gt;sudo vim /etc/vnc.conf 1 2 $geometry = \u0026#34;1920x1080\u0026#34;; $depth = \u0026#34;16\u0026#34;; SSH 설치 서버 설치 1 sudo apt install openssh-server 실행여부 확인 1 sudo systemctl status ssh 서버 실행 1 2 sudo systemctl enable ssh sudo systemctl start ssh xforward 설정 팡일의 /etc/ssh/ssh_config 의 x11Forward no → x11Forward yes로 변경 ssh서버 재실행 및 클라언트 실행 시 -X 옵션 추가 ZSH/om-my-zsh 설치 및 설정 zsh 설치 1 sudo apt-get install zsh 설치확인 1 cat /etc/shells 기본쉘 변경 1 chsh -s $(which zsh) oh-my-zsh 설치(curl설치필요) 1 sh -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\u0026#34; 테마변경 ~/.zshrc 파일 내 ZSH_THEME=\u0026quot;agnoster\u0026quot; 로 변경 글자깨질 시 Powerline폰트 설치 1 sudo apt-get install fonts-powerline 커맨드라인 컴퓨터 이름 감추기 ~/.zshrc 하단에 하기 내용 추가 1 2 3 4 5 prompt_context() { if [[ \u0026#34;$USER\u0026#34; != \u0026#34;$DEFAULT_USER\u0026#34; || -n \u0026#34;$SSH_CLIENT\u0026#34; ]]; then prompt_segment black default \u0026#34;%(!.%{%F{yellow}%}.)$USER\u0026#34; fi } zsh-autosuggestions 플러그인 설치 1 git clone https://github.com/zsh-users/zsh-autosuggestions.git $ZSH_CUSTOM/plugins/zsh-autosuggestions zsh-syntax-highlighting 플러그인 설치 1 git clone https://github.com/zsh-users/zsh-syntax-highlighting.git $ZSH_CUSTOM/plugins/zsh-syntax-highlighting autojump 설치 1 2 3 git clone https://github.com/wting/autojump.git cd autojump ./install.py 사용법 j [디렉토리 명] 또는 j -s 플러그인 활성화\n~/.zshrc 파일 내 plugins=(git zsh-autosuggestions zsh-syntax-highlighting autojump) 로 변경 줄바꿈 적용(멀티라인 입력)\n~/.oh-my-zsh/themes/agnoster.zsh-theme파일 수정 prompt_hg 하단에 prompt_newline 추가 후 파일 최하단 하기 프롬프트 추가 1 2 3 4 5 6 7 8 9 10 prompt_newline() { if [[ -n $CURRENT_BG ]]; then echo -n \u0026#34;%{%k%F{$CURRENT_BG}%}$SEGMENT_SEPARATOR %{%k%F{blue}%}$SEGMENT_SEPARATOR\u0026#34; else echo -n \u0026#34;%{%k%}\u0026#34; fi echo -n \u0026#34;%{%f%}\u0026#34; CURRENT_BG=\u0026#39;\u0026#39; } ","date":"2022-12-12T00:00:00Z","permalink":"https://muonkmu.github.io/p/ubuntu-20.04-%EA%B0%9C%EC%9D%B8-%ED%99%98%EA%B2%BD-%EC%84%A4%EC%A0%95/","title":"Ubuntu 20.04 개인 환경 설정"},{"content":"목적 클라우드 서버를 이용하여 원격으로 접속 가능한 개발 서버의 구축 최종 목표 고정 IP를 가진 ubuntu 서버 무료 클라우드 서버 중 오라클이 ARM64-4core/24GB ram/200GB storage VM 머신 제공 (타사 대비 월등히 좋음) 원격 개발을 위한 code-server 설치 서버 구축 클라우드 서버 구축 오라클 클라우드 Free tier 가입 리전은 원하는 곳(춘천이 빠르고 ARM 서버 리소스가 남음) 카드 정보를 기입(실제로 결제가 되지는 않음) 가입 완료 후 하단의 Create a VM instance 시작 instance Name 입력 image는 원하는거 선택, ex) canonical Ubuntu 20.04 shape는 Ampere 선택 core는 4, memory는 24GB 까지 무료 상기 리소스를 나누어 무료 VM를 생성할 수 있다.ex) 2core-12GB 인스턴스 2개 무료 VCN이 없다면 페이지에서 VCN을 생성하여 연결 본인의 PC에서 SSH를 생성하여 Public키를 업로드 한다. http://taewan.kim/oci_docs/98_misc_tips/ssh_key_pairs/ 부트 볼륨 생성 Specify a custom boot volume size을 클릭 후 원하는 볼륨생성 200GB까지 무료이며 상기 리소스를 나누어 무료 VM생성 가능 Create로 생성 해당 리전의 리소스가 부족하여 생성이 안되는 경우가 있다. 상기의 경우 리소스가 풀릴 때 까지 기다리거나 유료계정으로 업그레이드 (승인되는데 시간 걸림) 유료 계정이 되더라도 무료 리소스까지만 쓰면 과금이 되지 않는다. 클라우드 서버 환경 설정 고정 IP 설정 Compute \u0026gt; Instances \u0026gt; Instance Details \u0026gt; Attached VNICs \u0026gt; VNIC Details \u0026gt; IPv4 Addresses 상기 경로에서 NO PUBLIC IP 선택하여 IP 삭제 후 RESERVED PUBLIC IP로 변경 우분터 사용자 계정 생성(option) ssh 로그인 현재 계정 ubuntu 암호 생성 사용자 계정 생성 생성 계정에 sudo 권한 부여 계정 변경 ssh 비번으로 접속 설정 /etc/ssh/sshd_config파일의 PasswordAuthentication 값을 \u0026ldquo;yes\u0026quot;로 변경 클라우드 포트 개방 Networking \u0026gt; Virtual Cloud Networks \u0026gt; {사용중인 VNC} \u0026gt; Security List Details 상기 경로에서 포트 개방 추가 우분투 방화벽 포트 개방 1 sudo iptables -I INPUT 5 -p tcp --dport 8070 -m state --state NEW,ESTABLISHED -j ACCEPT code-server 설치 code-server 다운로드 및 설치 https://coder.com/docs/code-server/latest/install 1 curl -fsSL https://code-server.dev/install.sh | sh 서비스로 실행하기 위해 systemctl로 enable 1 sudo systemctl enable --now code-server@$USER 외부 접속을 위해 .config/code-server/config.yaml파일을 수정한다. 1 2 3 4 bind-addr: 0.0.0.0:{포트번호} auth: password password: {비밀번호} cert: false 서비스를 재시작 후 동작을 확인한다. 1 2 sudo systemctl restart --now code-server@$USER sudo systemctl status code-server@$USER chrome 브라우저에서 접속 시 이미지가 안보일 경우 하기 세팅을 수행 chrome://flags 설정 의 Insecure origins treated as secure Enable 후 http://{접속IP}:{접속Port} 추가 ","date":"2022-12-12T00:00:00Z","permalink":"https://muonkmu.github.io/p/%EC%9B%90%EA%B2%A9-%EA%B0%9C%EB%B0%9C-%EC%84%9C%EB%B2%84-%EA%B5%AC%EC%B6%95/","title":"원격 개발 서버 구축"},{"content":"본 chapter에서는 Gradient를 구하기 위한 Backpropagation을 이해하고 Neural Network의 기본에 대해 설명한다.\nVideo : https://www.youtube.com/watch?v=d14TUNcbn1k Slide : http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture4.pdf (TODO: 귀차니즘의 압박으로 정리를 안해놓았지만 언젠간 해야지)\nBackpropagation Chain rule Sigmoid gate example Patterns in backward flow Gradients add at branches Vectorized operations Neural Network Artificial Neural Network Activation Function Neural networks Architectures ","date":"2022-10-25T00:00:00Z","permalink":"https://muonkmu.github.io/p/cs231n-chap-04-introduction-to-neural-networks/","title":"[CS231n] Chap 04 Introduction to Neural Networks"},{"content":"본 chapter에서는 딥러닝의 기본 개념인 Loss Function, Regularization, Optization(Gradient Descent)에 대해 다룬다\nVideo : https://www.youtube.com/watch?v=h7iBpEHGVNc Slide : http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture3.pdf (TODO: 귀차니즘의 압박으로 정리를 안해놓았지만 언젠간 해야지)\nLoss function Regularization Softmax and SVM Optimization Image Feature ","date":"2022-10-17T00:00:00Z","permalink":"https://muonkmu.github.io/p/cs231n-chap-03-loss-function-and-optimization/","title":"[CS231n] Chap 03 Loss Function and Optimization"},{"content":"본 chapter에서는 Computer Vision의 핵심 Task 중 하나인 Image classification에 대해 이해하고 초기의 방법인 K-Nearest Neighbor Algorithm과 Linear Classification에 대하여 다룬다.\nVideo : www.youtube.com/watch?v=OoUX-nOEjG0\u0026list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk\u0026index=2 Slide : http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture2.pdf (TODO: 귀차니즘의 압박으로 정리를 안해놓았지만 언젠간 해야지)\nImage Classification 개요 K-Nearest Neighbor Algorithm Linear Classification ","date":"2022-10-08T00:00:00Z","permalink":"https://muonkmu.github.io/p/cs231n-chap-02-image-classification/","title":"[CS231n] Chap 02 Image classification"},{"content":"6개월에 걸쳐 수료를 완료 했다. 3개월 코스라고 하던데\u0026hellip;\nhttps://www.coursera.org/learn/machine-learning homework repo : https://github.com/muonkmu/Coursera_AndrewNg_ML_Program.git (TODO: 귀차니즘의 압박으로 정리를 안해놓았지만 언젠간 해야지)\n","date":"2022-01-25T00:00:00Z","permalink":"https://muonkmu.github.io/p/coursera_ml-course-certificate/","title":"[Coursera_ML] Course certificate"},{"content":"이번 강의에서는 대규모의 대규모의 데이터가 있을 때, 처리하는 알고리즘에 대해서 알아보자.\nhttps://www.coursera.org/learn/machine-learning homework repo : https://github.com/muonkmu/Coursera_AndrewNg_ML_Program.git (TODO: 귀차니즘의 압박으로 정리를 안해놓았지만 언젠간 해야지)\n","date":"2022-01-07T00:00:00Z","permalink":"https://muonkmu.github.io/p/coursera_ml-week_10-gradient-descent-with-large-datasets/","title":"[Coursera_ML] Week_10) Gradient Descent with Large Datasets"}]