<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>TVM on MW Devlog</title>
        <link>https://muonkmu.github.io/tags/tvm/</link>
        <description>Recent content in TVM on MW Devlog</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Tue, 15 Apr 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://muonkmu.github.io/tags/tvm/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>[TVM_0.20] Design and Architecture</title>
        <link>https://muonkmu.github.io/p/tvm_0.20-design-and-architecture/</link>
        <pubDate>Tue, 15 Apr 2025 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/tvm_0.20-design-and-architecture/</guid>
        <description>&lt;p&gt;TVM이 0.18버전부터 Transformer등으로 대표되는 LLM 등에 대응하기 위해 TVM Unity로 진화하였다.(가장 큰 변화는 relay 대신 relax를 사용)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://discuss.tvm.apache.org/t/relax-co-designing-high-level-abstraction-towards-tvm-unity/12496&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://discuss.tvm.apache.org/t/relax-co-designing-high-level-abstraction-towards-tvm-unity/12496&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;TVM을 다룰 수 있어야 신규 ACCELERATOR를 개발하더라도 이에 맞는 컴파일러를 구축할 수 있기에 현재 TVM에 대한 이론을 정리하고자 한다.&lt;/p&gt;
&lt;h2 id=&#34;overall-flow&#34;&gt;Overall Flow&lt;/h2&gt;
&lt;p&gt;전체적인 Compile flow를 다룬다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Model Creation
&lt;ul&gt;
&lt;li&gt;compile/optimize 될 모델을 생성, IRModule의 형태이며 NNModule, TVMScript을 사용하여 직접 코딩하거나 기존 pre-trained model(pytorch 같은)을 Relax frontend를 이용하여 import 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Transformation
&lt;ul&gt;
&lt;li&gt;IRModule을 다른 IRModule 형태로 변환 (대표적으로 quantization), Target과 독립적이지만 타겟이 transformation pipeline의 설정에 영향을 끼치도록 할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Target Translation
&lt;ul&gt;
&lt;li&gt;IRModule을 Target에 실행 가능한 codegen 과정&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Runtime Execution
&lt;ul&gt;
&lt;li&gt;컴파일된 모듈을 runtime.Module에 적재하여 실행시키는 것
&lt;img src=&#34;https://muonkmu.github.io/p/tvm_0.20-design-and-architecture/01_tvm_overall_flow.svg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;key-data-structures&#34;&gt;Key data structures&lt;/h2&gt;
&lt;p&gt;IRModule은  primary data structure이며 2가지 주요한 형태의 function을 제공&lt;/p&gt;
&lt;h3 id=&#34;relaxfunction&#34;&gt;relax::Function&lt;/h3&gt;
&lt;p&gt;high-level functional program representation. 주로 end-to-end model 또는 전체 모델의 sub-graph 에 대응, control-flow와 complex data structure를 지원하는 computational graph로 생각할 수 있다.&lt;/p&gt;
&lt;h3 id=&#34;tirprimfunc&#34;&gt;tir::PrimFunc&lt;/h3&gt;
&lt;p&gt;low-level program representation이며 loop-nest choice, multi-dimensional load/store, threading, vector/tensor instructions을 포함. 모델 레이어를 실행하는 operator program에 대응&lt;/p&gt;
&lt;p&gt;Compilation/Transformation과정에서 모든 Relax operator는 Target device에서 바로 실행 가능한 tir::PrimFunc 또는 TVM PackedFunc으로 lowering 된다. 반면 Relax operator의 Call은 R.call_tir / R.call_dps 같은 low-level function으로 lowering 된다.&lt;/p&gt;
&lt;h2 id=&#34;transformations&#34;&gt;Transformations&lt;/h2&gt;
&lt;p&gt;Key data structure 간 변환 작업을 Transformations이라 하며 하기 2가지 목표를 가진다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;optimization : 동등하거나 최적화된 변환&lt;/li&gt;
&lt;li&gt;lowering : 타겟에 가까운 lower-level representation로 변환&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;relax-transformations&#34;&gt;relax transformations&lt;/h3&gt;
&lt;p&gt;Relax function에 적용되는 graph-level optimizations. constant folding / dead-code elimination / library dispatch 등&lt;/p&gt;
&lt;h3 id=&#34;tir-transformations&#34;&gt;tir transformations&lt;/h3&gt;
&lt;p&gt;tir function에 적용되며 하기 2가지 타입의 변환이 있음&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;TensorIR schedule
&lt;ul&gt;
&lt;li&gt;TensorIR functions을 target 코드를 생성하기 위한 user-guided instructions과 control을 가지고 최적화 하는 방법을 정의&lt;/li&gt;
&lt;li&gt;TVM unity는 TensorIR schedule을 자동으로 찾아주는 &lt;code&gt;MetaSchedule&lt;/code&gt;을 제공&lt;/li&gt;
&lt;li&gt;TensorIR 챕터에서 더 자세히 다룰 예정
(역자 주 : Tensor는 다차원 배열을 의미한다. TensorIR schedule이란 Tensor를 어떻게 분할하여 처리할 것인가를 정의하는 것이라 생각할 수 있다.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Lowering Passes
&lt;ul&gt;
&lt;li&gt;TensorIR schedule 적용 후 TIR PrimFunc을 좀 더 Target에 적합한 TIR PrimFunc로 변환&lt;/li&gt;
&lt;li&gt;예를 들어 multi-dimensional access를 one-dimensional pointer access로 flatten, 내장함수를 타겟에 맞도록 확장, runtime calling convention에 맞는 function decorate.
(내장함수 : __enable_interrupt() 같은 컴파일러 제공함수?)&lt;/li&gt;
&lt;li&gt;TVM은 low-level optimization은 타겟 컴파일러에가 맞기기 때문에 거의 다루지 않는다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;cross-level-trasnsformation&#34;&gt;cross-level trasnsformation&lt;/h3&gt;
&lt;p&gt;TVM은 end-to-end 모델을 최적화 하기 위한 단일 전략을 채용. 즉 IRModule이 relax와 tir function을 둘다 가지고 있으므로 이들에게 각각 다른 Transformation을 적용한다.
예를 들어 relax.LegalizeOps는 relax operator를 lowering 하고 TIR PrimFunc을 IRModule에 추가한다음, relax연산자를  TIR PrimFunc로 호출하는 것으로 대체한다.
다른 예로, fusion pipeline(relax.FuseOps,relax.FuseTIR 등)은 이는 여러 연속적인 텐서 연산을 하나로 융합함.&lt;/p&gt;
&lt;h2 id=&#34;target-translation&#34;&gt;Target Translation&lt;/h2&gt;
&lt;p&gt;IRModule을 Target 실행 바이너리로 변환, TVM은 Relax function (sub-graph)를 외부 코드 제너레이터를 이용하여 translation 하는 것을 지원한다.&lt;/p&gt;
&lt;h2 id=&#34;runtime-execution&#34;&gt;Runtime Execution&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;TVM’s runtime의 주요 목적은 컴파일된 artifact의 로딩과 실행을 위한 간소한 API를 제공하는 것(C++, Rust, Go 등)&lt;/li&gt;
&lt;li&gt;tvm.runtime.Module은 컴파일 결과를 캡슐화하고 PackedFuncs을 얻기 위한 GetFunction method를 가짐&lt;/li&gt;
&lt;li&gt;tvm.runtime.PackedFunc은 생성 코드를 위한(실행을 위한) type-erased function&lt;/li&gt;
&lt;li&gt;좀 더 자세한 내용은 runtime chapter에서 다룸&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;summary-and-discussions&#34;&gt;Summary and Discussions&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;컴파일 flow에서 key data structure
&lt;ul&gt;
&lt;li&gt;IRModule: relax.Function, tir.PrimFunc 포함&lt;/li&gt;
&lt;li&gt;runtime.Module: runtime.PackedFunc 포함&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;컴파일에서 주요한 파트는 key data structure간 Transformation
&lt;ul&gt;
&lt;li&gt;relax/transform, tir/transform는 determinstic rule-based transformations&lt;/li&gt;
&lt;li&gt;meta-schedule은 search-based transformations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;TVM은 key data structures와 transformations을 python, C++ API로 노출 시키므로 TVM을 numpy 사용하듯 사용할 수 있다.
&lt;ul&gt;
&lt;li&gt;IRModule을 python API를 이용하여 직접 구축할 수 있다.&lt;/li&gt;
&lt;li&gt;custom transformations(e.g. customize quantization) 작성할 수 있다.&lt;/li&gt;
&lt;li&gt;TVM의 파이썬 API를 사용하여 직접 IR을 조작할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>[TVM&amp;VTA] Project result</title>
        <link>https://muonkmu.github.io/p/tvmvta-project-result/</link>
        <pubDate>Mon, 14 Apr 2025 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/tvmvta-project-result/</guid>
        <description>&lt;h2 id=&#34;result&#34;&gt;Result&lt;/h2&gt;
&lt;p&gt;TVM에서 VTA를 레거시 코드로 인식하여 매뉴얼대로 실행하여도 정상적으로 진행이 되지 않고 수많은 에러에 봉착하게 된다.
이를 해결하기 위해&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Compiler 및 runtime 빌드 시 자신의 보드 설정을 추가 해야 한다.
&lt;ul&gt;
&lt;li&gt;필자의 경우 ZCU104 보드를 추가하고 이에 맞는 LLVM 버전 및 다른 설정들을 추가하였다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;필자는 RPC 서버를 활용하지 않고 TARGET(ZCU104)에 바이너리를 카피해두고 로컬환경에서 바로 카메라 입력을 받아 처리함
&lt;ul&gt;
&lt;li&gt;TVM에서 제공하는 RPC서버의 경우 FPGA Bit 파일이 PL영역 로드 명령이 수행되지 않는다.(Pynq 버전 차이 인듯)&lt;/li&gt;
&lt;li&gt;TVM에서 제공하는 RPC서버의 경우 런타임 수행명령에 의해 런타임이 재구성 되는데 이때 정상적으로 런타임이 재구성 되지 않아 오류가 난다.&lt;/li&gt;
&lt;li&gt;TVM에서 제공하는 예제의 경우 OpenCV명령이 예전 버전이라 현재의 Pynq와 호환이 되지 않는다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2항을 위해 Target을 위한 SW를 제작하였다.
&lt;ul&gt;
&lt;li&gt;FPGA Bit파일 / TVM Runtime / 모델 바이너리를 로딩&lt;/li&gt;
&lt;li&gt;카메라 입력을 VTA에 전송하고 출력을 받아옴&lt;/li&gt;
&lt;li&gt;VTA 출력에 NMS를 적용하고 Box와 class Tag를 그리기&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;상세한 과정은 다음에 기회가 되면 정리하겠다. 다만 TVM 컴파일러가 대대적으로 개편이 되고 FPGA 지원이 빠지면서 TVM을 조금 다시 공부할 필요가 있어 이를 다시 공부하고자 한다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://muonkmu.github.io/p/tvmvta-project-result/result.gif&#34;
	width=&#34;344&#34;
	height=&#34;194&#34;
	srcset=&#34;https://muonkmu.github.io/p/tvmvta-project-result/result_hu93633e32315c91e1b22a2812ee891a8f_9143761_480x0_resize_box_1.gif 480w, https://muonkmu.github.io/p/tvmvta-project-result/result_hu93633e32315c91e1b22a2812ee891a8f_9143761_1024x0_resize_box_1.gif 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;425px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>[TVM&amp;VTA] TVM Install (base on CONDA)</title>
        <link>https://muonkmu.github.io/p/tvmvta-tvm-install-base-on-conda/</link>
        <pubDate>Thu, 22 Feb 2024 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/tvmvta-tvm-install-base-on-conda/</guid>
        <description>&lt;h2 id=&#34;사전-설치-파일&#34;&gt;사전 설치 파일&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;필요 패키지를 설치한다&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;cmake는 3.18 이상 버전이 필요하다(우분투 20.04에서는 apt로 설치 시 3.10버전이 설치되므로 repo를 등록하여 업데이트 하자)&lt;/li&gt;
&lt;li&gt;llvm을 설치하기를 권장하고 있다. 최신버전은 llvm-18은 호환성 문제로 tvm이 빌드가 안된다. apt를 이용시 llvm-10이 설치되므로 이를 이용하자.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt-get update
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt-get install -y python3 python3-dev python3-setuptools gcc libtinfo-dev zlib1g-dev build-essential cmake libedit-dev libxml2-dev llvm
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;conda를 설치하고 python=3.8 버전의 환경을 구성한다.(option)&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;필자는 패키지 의존성 꼬이는게 싫어서 conda 환경을 구성했다. 그러나 문제가 많이 생겨서 삽질 많이함&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda create -n tvm &lt;span class=&#34;nv&#34;&gt;python&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;3.8
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda active tvm
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;빌드-및-설치&#34;&gt;빌드 및 설치&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;소스를 다운로드 한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone --recursive https://github.com/apache/tvm tvm
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;공식 매뉴얼에 conda 환경을 꾸미고 conda 환경에서 tvm 빌드 및 설치하는 방법이 나와 있으나 매뉴얼 대로 진행시 정상적으로 동작하지 않는다. 따라서 Cmake를 이용하여 빌드할 예정이다.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;tvm/conda 폴더에 보면 해당 파일들이 확인 가능하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;build 폴더 생성, config파일 수정 복사를 진행한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;mkdir build
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cp cmake/config.cmake build
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;llvm을 사용할 경우 &lt;code&gt;set(USE_LLVM ON)&lt;/code&gt;, 가상환경을 사용하므로 &lt;code&gt;set(USE_LLVM &amp;quot;/path/to/llvm-config --link-static&amp;quot;)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;디버깅을 위해 &lt;code&gt;set(USE_GRAPH_EXECUTOR ON)&lt;/code&gt; 및 &lt;code&gt;set(USE_PROFILER ON)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;IR 디버깅시 set(USE_RELAY_DEBUG ON) 및 환경변수 선언 &lt;code&gt;export TVM_LOG_DEBUG=&amp;quot;ir/transform.cc=1,relay/ir/transform.cc=1&amp;quot;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;tvm 빌드&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; build
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cmake ..
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;make -j4
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;python dependecies 패키지 설치(설치중에 패키지가 필요할 수 있으므로 미리 설치한다)&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;tvm/python 폴더에 gen_requirements.py를 실행하면 필수 패키지들을 볼 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda install numpy decorator attrs   //필수 패키지
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda install typing-extensions psutil scipy   //tvmc 사용시
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda install tornado   //RPC talker 사용시
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda install tornado psutil &lt;span class=&#34;s1&#34;&gt;&amp;#39;xgboost&amp;gt;=1.1.0&amp;#39;&lt;/span&gt; cloudpickle   // auto-tuning 모듈 사용시
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol&gt;
&lt;li&gt;tvm 패키지 설치&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;환경 변수 설정, 환경변수를 선언해 놓으면 변경사항이 즉시 반영된다고 한다(변경 시setup 호출이 필요하지 않음)(필요 시 ~./bashrc 추가)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;export TVM_HOME=/path/to/tvm
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;export PYTHONPATH=$TVM_HOME/python:${PYTHONPATH}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;라이브러리 복사&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; python&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; python setup.py install&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; ..
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;pynq2.7 설치
cmake 지우고 재설치 (sudo ln -s /opt/cmake-3.29.0-linux-aarch64/bin/* /usr/local/bin/)
tvm 다운로드 ()
git tag version&lt;/p&gt;
&lt;p&gt;zcu104 플래그 추가하고 빌드&lt;/p&gt;
&lt;p&gt;에러 해결
AttributeError: /home/xilinx/tvm/vta/python/vta/../../../build/libvta.so: undefined symbol: VTARuntimeShutdown
리빌드 링크
&lt;a class=&#34;link&#34; href=&#34;https://discuss.tvm.apache.org/t/error-vtaruntimeshutdown-symbol-is-undefined/6832/10&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://discuss.tvm.apache.org/t/error-vtaruntimeshutdown-symbol-is-undefined/6832/10&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
