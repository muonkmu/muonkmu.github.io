<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Eyeriss on MW Devlog</title>
        <link>https://muonkmu.github.io/tags/eyeriss/</link>
        <description>Recent content in Eyeriss on MW Devlog</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Sat, 18 Feb 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://muonkmu.github.io/tags/eyeriss/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>[AI HW Design] Chap05 Convolution Optimization (2/3)</title>
        <link>https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/</link>
        <pubDate>Sat, 18 Feb 2023 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/</guid>
        <description>&lt;p&gt;유명한 MIT의 Eyeriss Accelerator 논문이다. 아직까지 관련 프로젝트가 진행 중인 것으로 보이며 찾아보면 관련 논문에 대하여 리뷰해논 자료가 꽤 많다.
잘 소개된 곳 한 곳 (허락없는 링크..)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&amp;amp;blogId=kangdonghyun&amp;amp;logNo=220990374125&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&amp;blogId=kangdonghyun&amp;logNo=220990374125&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;eyeriss-accelerator&#34;&gt;Eyeriss Accelerator&lt;/h2&gt;
&lt;p&gt;Eyeriss Accelerator는 data access를 최소화하기 위한 Row Stationary (RS) Dataflow를 제안하며 다음과 같은 특징을 지님&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spartial architecture with sequential processing configuration
&lt;ul&gt;
&lt;li&gt;Spartial architecture can exploit high compute parallelism using direct communication between an array of relatively simple processing engines (PEs).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Row Stationary (RS) Dataflow 구현&lt;/li&gt;
&lt;li&gt;Four level memory hierarchy : PE scratch pad와 inter-PE 통신을 최대한 이용하고 Global Buffer와 외부 메모리의 data transfer를 최소화&lt;/li&gt;
&lt;li&gt;point-to-point &amp;amp; multicast Network-on-Chip(NoC) 아키텍쳐 지원&lt;/li&gt;
&lt;li&gt;Run-Length Compression (RLC) 포맷 지원 : zero operation 제거&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;eyeriss-system-architecture&#34;&gt;Eyeriss System Architecture&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Eyeriss는 과 communication link clock 두가지 clock domain을 가짐
&lt;ul&gt;
&lt;li&gt;data processing core clock : 12X14 PE array, Global Buffer(GLB), RLC codec, ReLu 배치, PE가 local scratchpad를 이용하여 연산하거나 PE가 인접 PE 또는 GLB와 통신 하는것을 가능하게 함&lt;/li&gt;
&lt;li&gt;communication link clock&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Four level memory hierarchy
&lt;ul&gt;
&lt;li&gt;GLB &amp;lt;-&amp;gt; external memory : asynchronous FIFO 이용&lt;/li&gt;
&lt;li&gt;PE &amp;lt;-&amp;gt; GLB : NoC 이용&lt;/li&gt;
&lt;li&gt;ReLU &amp;lt;-&amp;gt; RLC codec&lt;/li&gt;
&lt;li&gt;local temporary data storage using scratchpad&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;분리된 clock으로 PE는 다른 PE와 같은 클럭 시간에 독립적으로 동작가능하고 link clock은 external memory와 64bit 양방향 버스로 data 전송을 제어&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/01_Eyeriss_system_archi.png&#34;
	width=&#34;882&#34;
	height=&#34;311&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/01_Eyeriss_system_archi_huf1524314c1b2ba265b52bb1365fc6338_34365_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/01_Eyeriss_system_archi_huf1524314c1b2ba265b52bb1365fc6338_34365_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Eyeriss system architecture&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;283&#34;
		data-flex-basis=&#34;680px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;Eyeriss Acc는 Convolution network를 레이어 단위로 진행
&lt;ul&gt;
&lt;li&gt;첫째로 PE array를 레이어 function/size에 맞게 구성하고 매핑 수행 및 전송 패턴을 결정&lt;/li&gt;
&lt;li&gt;input feature map 및 filter map은 external memory에서 PE로 로드되고 output feature map은 다시 external memory로 쓰여짐&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2d-convolution-to-1d-multiplication&#34;&gt;2D convolution to 1D multiplication&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;convolution을 수행할 때 2D feature/filter map을 1D로 바꾸어 수행해서 PE에 순차적으로 로딩한다는 이야기를 길게 써놓음 (궁금하면 책을 보자)
&lt;ul&gt;
&lt;li&gt;2D convolution을 1D vector 와 Toeplitz 행렬(대각선의 성분이 모두 같은 매트릭스)의 곱으로 변환된다&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;책에 어떤 순서로 feature/filter 1D vector가 PE에 로드/계산되는지 그림으로 있다.&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/02_1D_row_convolution.png&#34;
	width=&#34;807&#34;
	height=&#34;555&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/02_1D_row_convolution_hu821e8a0c54af7140bd12bc2289e267fd_105196_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/02_1D_row_convolution_hu821e8a0c54af7140bd12bc2289e267fd_105196_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;145&#34;
		data-flex-basis=&#34;348px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;stationary-dataflow&#34;&gt;Stationary Dataflow&lt;/h3&gt;
&lt;p&gt;칩에 대한 이야기는 아니고 이전의 stationary 전략에 대해 소개한다. (연산을 어떤 데이터를 고정, 이동 시킬지)&lt;/p&gt;
&lt;h4 id=&#34;output-stationary&#34;&gt;Output Stationary&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Patial Sum의 read/write를 local accumulation을 통해 최소화&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;weight-stationary&#34;&gt;Weight Stationary&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;filter map을 local buffer에 두고 계속 활용&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;input-stationary&#34;&gt;Input Stationary&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;input feature map을 local buffer에 두고 계속 활용&lt;/li&gt;
&lt;li&gt;다른 전략보다 효율이 안좋은데 약점은 다른 전략보다 convolution연산에 더 많은 cycle이 필요&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;row-stationary-rs-dataflow&#34;&gt;Row Stationary (RS) Dataflow&lt;/h3&gt;
&lt;p&gt;Eyeriss는 1D vector multiplication 수행하는데 RS dataflow 전략을 사용&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;filter map 행은 PE들에서 수평하게 재사용&lt;/li&gt;
&lt;li&gt;input feature map 행은 PE들에서 대각적으로 재사용&lt;/li&gt;
&lt;li&gt;partial sum 행은 PE들에서 수직적으로 재사용&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/03_Eyeriss_RS_dataflow.png&#34;
	width=&#34;889&#34;
	height=&#34;301&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/03_Eyeriss_RS_dataflow_hu83a06e14ef6cd6bea9052c996e8c4779_80929_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/03_Eyeriss_RS_dataflow_hu83a06e14ef6cd6bea9052c996e8c4779_80929_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Eyeriss RS dataflow&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;295&#34;
		data-flex-basis=&#34;708px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;RS dataflow에서 데이터는 계산 동안 PE에 저장됨(데이터 이동 최소화)&lt;/li&gt;
&lt;li&gt;time-interleaved approach를 통해 fmap과 ifmap은 같은 clock cycle 내에서 재활용&lt;/li&gt;
&lt;li&gt;계산이 완료되면 Psum은 근접 PE들로 이동(다음 계산을 위해서)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;filter-reuse&#34;&gt;Filter Reuse&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;fmap이 spad에 로드 되고 고정된다. 다수의 ifmap도 spad에 로드되고 사슬처럼 연걸됨&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;input-feature-maps-reuse&#34;&gt;Input Feature Maps Reuse&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;ifmap이 먼저 PE에 로드 되고 2개의 fmap은 time-interleaved(연산?) 됨&lt;/li&gt;
&lt;li&gt;1개의 ifmap으로 2개의 fmap과 1D 연산 수행&lt;/li&gt;
&lt;li&gt;이 것은 전체적인 스피드를 올려주지만 fmap과 psum의 time-interleave 연산을 지원하기 위해 큰 spad가 필요&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;partial-sums-reuse&#34;&gt;Partial Sums Reuse&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;fmap/ifmap 둘 다 PE에 로드되며 둘 다 time-interleaved 함&lt;/li&gt;
&lt;li&gt;psum은 같은 채널 끼리 합쳐짐&lt;/li&gt;
&lt;li&gt;fmap/ifmap 둘 다 PE에 로드되어야 하므로 필요한 spad의 용량이 증가&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;run-length-compression-rlc&#34;&gt;Run-Length Compression (RLC)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;ReLU 연산 결과 0 값이 많아 지므로 이는 network의 sparsity가 도입됨&lt;/li&gt;
&lt;li&gt;zero computation을 피하기 위해 Eyeriss는 64 bit  RLC 포맷을 도입
&lt;ul&gt;
&lt;li&gt;([5bit]앞에 값이 0인 element 갯수 + [16bit]0이 아닌 값)*3 + [1bit]마지막 item인지 나타내는 flag&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/04_Eyeriss_RLC.png&#34;
	width=&#34;425&#34;
	height=&#34;200&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/04_Eyeriss_RLC_hub59b108cd57493ff3ac688d982967fe9_14291_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/04_Eyeriss_RLC_hub59b108cd57493ff3ac688d982967fe9_14291_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Eyeriss run-length compression&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;212&#34;
		data-flex-basis=&#34;510px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;첫번째 layer의 ifmap 값을 제회하고 모든 fmap/ifmap은 RLC 포맷으로 external memory에 저장&lt;/li&gt;
&lt;li&gt;External Memory에서 입출력 될 때, RLC encoder/decoder를 통과하게 됨&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;glabal-buffer-glb&#34;&gt;Glabal Buffer (GLB)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;external memory와 데이터 전송을 위해 GLB 채택&lt;/li&gt;
&lt;li&gt;GLB에는 fmap/ifmap/ofmap/psum 이 저장&lt;/li&gt;
&lt;li&gt;GLB는 PE가 연산하는 동안 다음 fmap을 preload&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;processing-element-pe-architecture&#34;&gt;Processing Element (PE) Architecture&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;PE는 fmap, ifmap, psum을 위한 3가지 타입의 spad를 가짐&lt;/li&gt;
&lt;li&gt;datapath는 3가지 pipeline stage에 의해 구성(spad access, fmap/ifmap multiplication, psum accumulation)&lt;/li&gt;
&lt;li&gt;16bit 연산을 사용하며 32bit 연산결과는 16bit로 절삭&lt;/li&gt;
&lt;li&gt;값이 O인 ifmap이 발견되면 spad에서 fmap 값을 읽는 것과 연산 로직을 끔(전력소모를 줄이기 위해)&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/05_Eyeriss_PE_archi.png&#34;
	width=&#34;876&#34;
	height=&#34;471&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/05_Eyeriss_PE_archi_hu6d4af46b5849dcef0bf48d3b94639878_43237_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/05_Eyeriss_PE_archi_hu6d4af46b5849dcef0bf48d3b94639878_43237_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Eyeriss processing element architecture&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;185&#34;
		data-flex-basis=&#34;446px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;network-on-chip-noc&#34;&gt;Network-on-Chip (NoC)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;NoC는 GLB와 PE 사이의 데이터 이동을 관리, 하기 2개로 구분
&lt;ul&gt;
&lt;li&gt;Global Input Network (GIN) : GLB &amp;lt;-&amp;gt; PE 간 single cycle multicast 이용 데이터 전송
&lt;ul&gt;
&lt;li&gt;Y-Bus는 12개의 X-bus와 연결되며 X-bus는 14개의 PE가 연결&lt;/li&gt;
&lt;li&gt;top level controller는 &amp;lt;row,col&amp;gt; 태그를 생성하고 Y-bus / PE의 Multicast controller가 tag를 비교하여 데이터 전송 결정&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/06_Eyeriss_GIN.png&#34;
	width=&#34;885&#34;
	height=&#34;454&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/06_Eyeriss_GIN_hudd45dfb58898f938211550fa285202e2_35533_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/06_Eyeriss_GIN_hudd45dfb58898f938211550fa285202e2_35533_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Eyeriss global input network&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;194&#34;
		data-flex-basis=&#34;467px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;책에 AlexNet의 예시 있음&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Global Output Network (GON) : 별다른 설명 없음&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        
    </channel>
</rss>
