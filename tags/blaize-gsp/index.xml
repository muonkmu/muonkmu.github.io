<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Blaize GSP on MW Devlog</title>
        <link>https://muonkmu.github.io/tags/blaize-gsp/</link>
        <description>Recent content in Blaize GSP on MW Devlog</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Fri, 27 Jan 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://muonkmu.github.io/tags/blaize-gsp/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>[AI HW Design] Chap04 Streaming Graph Theory (1/2)</title>
        <link>https://muonkmu.github.io/p/ai-hw-design-chap04-streaming-graph-theory-1/2/</link>
        <pubDate>Fri, 27 Jan 2023 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/ai-hw-design-chap04-streaming-graph-theory-1/2/</guid>
        <description>&lt;p&gt;본 챕터에서는 graph-based deep-learnig accelerator에 대해 공부한다 (Blaize GSP, Graphcore IPU).
이들은 Mutiple Instructions Multiple Data(MIMD) 처럼 동작한다.&lt;/p&gt;
&lt;h2 id=&#34;blaize-graph-streaming-processorgsp&#34;&gt;Blaize Graph Streaming Processor(GSP)&lt;/h2&gt;
&lt;p&gt;무언가 칩에 대한 설명보단 Graph Streaming 기본 이론에 대한 내용이 주를 이룬다.&lt;/p&gt;
&lt;h3 id=&#34;stream-graph-model&#34;&gt;Stream Graph Model&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Stream Graph는 네트워크 트래픽, 데이터베이스 등에 널리 쓰이는 모델로 dynamic stream data를 처리하기 위해 data stream model(TCS)을 사용
&lt;ul&gt;
&lt;li&gt;거대 그래프 스트리밍 Transit(T), 큰 데이터 처리 Compute(C), 일시/롱텀 데이터 저장 Store(S)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Turnstile 모델이 TCS모델 중에서 데이터 출발/도착과 같은 data behavior을 가장 잘 표현하며 task scheduling에 사용.&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap04-streaming-graph-theory-1/2/01_Data_streaming_TCS_Model.png&#34;
	width=&#34;317&#34;
	height=&#34;483&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap04-streaming-graph-theory-1/2/01_Data_streaming_TCS_Model_hud047163813c097f2344ae308b4f685e4_77661_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap04-streaming-graph-theory-1/2/01_Data_streaming_TCS_Model_hud047163813c097f2344ae308b4f685e4_77661_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Data streaming TCS Model&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;65&#34;
		data-flex-basis=&#34;157px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;depth-first-scheduling-approach&#34;&gt;Depth First Scheduling Approach&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Blaize GSP는 뉴럴넷모델을 Direct Acyclic Graph(DAG) format (V,E)로 변환
&lt;ul&gt;
&lt;li&gt;V는 PE vertex, E는 PE간 weighted connection을 위한 edge&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;scheduling을 위해 Depth First Scheduling (DFS)를 사용하며 dynamic graph excution을 가능하게 하고 sparse/conditional graph를 지원한다. (dfs 설명은 유명하니 생략)&lt;/li&gt;
&lt;li&gt;GSP는 4가지 Parallelism을 달성했다. 자세한 설명은 책 참조
&lt;ul&gt;
&lt;li&gt;Task parallelism, Thread parallelism, Data parallelism, Instructon parallelism&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;graph-streaming-processor-architecture&#34;&gt;Graph Streaming Processor Architecture&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;GSP는 다음 그림과 같은 구조로 되어 있음&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap04-streaming-graph-theory-1/2/02_Blaize_GSP_architecture.png&#34;
	width=&#34;617&#34;
	height=&#34;183&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap04-streaming-graph-theory-1/2/02_Blaize_GSP_architecture_hub0e573f6ff23a6411796e6d052794dc5_16408_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap04-streaming-graph-theory-1/2/02_Blaize_GSP_architecture_hub0e573f6ff23a6411796e6d052794dc5_16408_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Blaize GSP architecture&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;337&#34;
		data-flex-basis=&#34;809px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;Streaming Processing은 Sequential Processing에 비해 하기와 같은 장점이 있음 (책에 두가지 방법에 대해 비교 그림있음)
&lt;ul&gt;
&lt;li&gt;Small intermediate buffer for local processing&lt;/li&gt;
&lt;li&gt;Cached data is easily supported&lt;/li&gt;
&lt;li&gt;Memory bandwidth is reduced to improve the performance with less power&lt;/li&gt;
&lt;li&gt;Support both task and data-parallel processing&lt;/li&gt;
&lt;li&gt;Data is sent to the next node when it is ready&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;GSP는 opeartion을 데이터가 준비되는 즉시 기다리지 않고 수행하도록 스케줄링 함으로써 성능을 향상시키고 메모리 access를 감소시킴&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        
    </channel>
</rss>
