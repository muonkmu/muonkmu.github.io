<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on MW Devlog</title>
        <link>https://muonkmu.github.io/post/</link>
        <description>Recent content in Posts on MW Devlog</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Wed, 01 Mar 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://muonkmu.github.io/post/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>[AI HW Design] Chap08 Network Sparsity (2/2)</title>
        <link>https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-2/2/</link>
        <pubDate>Wed, 01 Mar 2023 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-2/2/</guid>
        <description>&lt;h2 id=&#34;scnn-accelerator&#34;&gt;SCNN Accelerator&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;SCNN은 sparse encoding scheme을 이용해서 activation / weight sparsity 지원&lt;/li&gt;
&lt;li&gt;Planar Tiled-Input Stationary-Cartesian Product-sparse (PT-IS-CP-sparse)라 부르는 새로운 Cartesian product flow를 제안 (activation / weight reuse)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;scnn-pt-is-cp-dense-dataflow&#34;&gt;SCNN PT-IS-CP-Dense Dataflow&lt;/h3&gt;
&lt;p&gt;PT-IS-CP-Dense dataflow는 convolution nested loop를 어떻게 분해할 것인가에 관한 것&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;C X R X S 형태의 K개 filter, batch size N인 C X W X H 형태의 input activation 일 때&lt;/li&gt;
&lt;li&gt;Input Stationary (IS) 가 적용되면 loop order는 C→W→H→K→R→S 가 됨&lt;/li&gt;
&lt;li&gt;성능향상을 위해 blocking strategy 적용 (K output channel은 $K_c$ 사이즈의 K/$K_c$ output channel group으로 분리)&lt;/li&gt;
&lt;li&gt;K/$K_c$→C→W→H→$K_c$→R→S&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;intra-PE parallelism을 위해 PE 내부에서 spatial reuse 활용&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;filter weight(F)와 input activation(I)가 각 buffer에서 fetch되고 이는 F X I array 곱셈기로 전송&lt;/li&gt;
&lt;li&gt;filter weight와 input activation은 재활용 되며 partial sum은 향후 연산을 위해 메모리 접근 없이 저장됨&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;intra-PE parallelism을 위해 Spartial tiling 전략이 사용됨&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;W X H input activation는 $W_t$ X $H_t$ Planar Tiles(PT)로 나눠져서 PE로 분배됨&lt;/li&gt;
&lt;li&gt;또한 mutiple channel processing 지원 (C X $W_t$ X $H_t$이 PE에 할당됨)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;sliding window operation에서 edge에서 cross-tile dependency가 생기는데 data halo를 이용해 해결&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Input Halos : PE input buffer는 halo을 수용하기 위해 C x Wt x Ht보다 약간 큰 크기로 조정&lt;/li&gt;
&lt;li&gt;Output Halos : PE accumulation buffer도 halo을 수용하기 위해 Kc x Wt x Ht보다 약간 큰 크기로 조정. Halo에는 출력 채널 계산이 끝날 때 누적을 완료하기 위해 인접 PE와 통신하는 불완전한 부분 합계가 포함.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;PT-IS-CP-Dense Dataflow의 최종 수식은 다음과 같다
&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-2/2/01_PT-IS-CP-dense_dataflow.png&#34;
	width=&#34;1060&#34;
	height=&#34;1140&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-2/2/01_PT-IS-CP-dense_dataflow_hu3c650d0832d33928f21fb381fc9933f6_155844_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-2/2/01_PT-IS-CP-dense_dataflow_hu3c650d0832d33928f21fb381fc9933f6_155844_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;PT-IS-CP- dense dataflow&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;92&#34;
		data-flex-basis=&#34;223px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;scnn-pt-is-cp-sparse-dataflow&#34;&gt;SCNN PT-IS-CP-Sparse Dataflow&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;PT-IS-CP-Sparse는 PT-IS-CP-Dense dataflow에서 파생되었고 filter weight와 input activation의 sparsity를 지원&lt;/li&gt;
&lt;li&gt;filter weight는 Kc X R X S sparse block으로 압축, input activation은 Wt X Ht 사이즈 블럭으로 엔코딩&lt;/li&gt;
&lt;li&gt;PE는 nonzero F 와 nonzero I를 곱해서 partial sum은 accumulator buffer에 output index와 저장됨&lt;/li&gt;
&lt;li&gt;PT-IS-CP-Sparse는 compressed sparse index input activation / filter weigth / accumulator buffer를 패치 할 수 있도록 수정됨&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;scnn-tiled-architecture&#34;&gt;SCNN Tiled Architecture&lt;/h3&gt;
&lt;p&gt;SCNN은 Tiled architecture로 PT-IS-CP-Sparse를 지원&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PE는 halo를 교환 하기 위해 인접 PE와 연결되며 Layer Sequencer는 PE와 DRAM의 데이터 이동을 제어&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-2/2/02_SCNN_archi.png&#34;
	width=&#34;592&#34;
	height=&#34;368&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-2/2/02_SCNN_archi_hu22a2dcceaf27a062ad40ebc660eff001_51694_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-2/2/02_SCNN_archi_hu22a2dcceaf27a062ad40ebc660eff001_51694_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;SCNN architecture&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;386px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;processing-element-architecture&#34;&gt;Processing Element Architecture&lt;/h3&gt;
&lt;p&gt;PE는 weight buffer, input/output activation RAM (IARAM/OARAM), multiplier array, scatter crossbar, accumulation buffer, Post-Processing Unit (PPU)으로 구성&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-2/2/03_SCNN_dataflow.png&#34;
	width=&#34;875&#34;
	height=&#34;528&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-2/2/03_SCNN_dataflow_huacf189784cbd8dae2aef41d93c8518bf_46478_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-2/2/03_SCNN_dataflow_huacf189784cbd8dae2aef41d93c8518bf_46478_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;SCNN dataflow&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;165&#34;
		data-flex-basis=&#34;397px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;input activation과 filter weight가 PE로 로드되고 multiplier array가 partial sum을 계산 후 acculumlation buffer에 저장&lt;/li&gt;
&lt;li&gt;acculumlation buffer는 adder와 output channel entry를 가지고 있으며 double buffers 전략 사용
&lt;ul&gt;
&lt;li&gt;1개 버퍼는 partial sum을 계산 하고 다른 것은 output을 후처리를 위해 PPU로 전송&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;PPU는 몇 가지 다른 task를 수행
&lt;ul&gt;
&lt;li&gt;halo 영역을 위해 인접 PE와 partial sum을 교환&lt;/li&gt;
&lt;li&gt;nonlinear activation, pooling, dropout 수행&lt;/li&gt;
&lt;li&gt;output activation을 압축하고 ORAM에 씀&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;data-compression&#34;&gt;Data Compression&lt;/h3&gt;
&lt;p&gt;filter weight와 input/output activation을 압축하기 위해 다른 것과 약간 수정된 엔코딩 방식 사용(책의 그림 참조)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data vector : 0이 아닌 element 저장&lt;/li&gt;
&lt;li&gt;index vector : 0이 아닌 element의 갯수와 이전에 0인 element의 갯수를 저장&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;seernet-accelerator&#34;&gt;SeerNet Accelerator&lt;/h2&gt;
&lt;p&gt;Microsoft SeerNet은 quantizaition convolution을 이용해서 feature map sparsity를 예상하는 방법을 제안&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Feature Map(F)와 filter weight(W)는 Fq와 Wq로 양자화 되고 이를 이용해 quantized low bit inference를 수행하여 binary sparsity mask(M)을 생성&lt;/li&gt;
&lt;li&gt;그리고 full precision sparse inference를 수행(앞의 M을 이용하는 듯)&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-2/2/04_SeerNet_archi.png&#34;
	width=&#34;647&#34;
	height=&#34;619&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-2/2/04_SeerNet_archi_hub8d99cee4d0eb9f82ddd1d04851c9f13_43764_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-2/2/04_SeerNet_archi_hub8d99cee4d0eb9f82ddd1d04851c9f13_43764_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;SeerNet architecture&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;104&#34;
		data-flex-basis=&#34;250px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;low-bit-quantization&#34;&gt;Low-Bit Quantization&lt;/h3&gt;
&lt;p&gt;Low-Bit Quantization은 online/offline에서 filter weight를 양자화&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;output feature map의 dimenstion이 H*W 일 때 양자화 복잡도는 1/(HW)&lt;/li&gt;
&lt;li&gt;online 동작은 낮은 연산 복잡도와 오버헤드로 병렬처리를 제공하고 offline 동작은 추가 저장공간으로 양자화 오버헤드를 제거함&lt;/li&gt;
&lt;li&gt;online quantization동안 binary mask 생성을 위한 quantized convolution이 수행되고 이 마스크를 가지고 spase convolution이 수행 됨&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;efficient-quantization&#34;&gt;Efficient Quantization&lt;/h3&gt;
&lt;p&gt;Full quantization 대신에 layer-by-layer quantization에 집중하고 output feature map을 예측하기 위한 low-bit quantization 적용&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ReLU의 경우 output feature map의부호를 찾고 음수을 0으로 출력 시킴&lt;/li&gt;
&lt;li&gt;Max pooling의 경우 정확도 없이 output feature map의 가장 큰 값만 찾음&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Quantization flow 하기와 같음&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;n-1이 양/음의 범위를 모두 커버하는 양자화 레벨 2n-1을 정의&lt;/li&gt;
&lt;li&gt;최대 절대값 M을 찾음&lt;/li&gt;
&lt;li&gt;양자화 값 x&amp;rsquo; = floor(X/M*2^(n-1))
&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-2/2/05_SeerNet_quntization.png&#34;
	width=&#34;554&#34;
	height=&#34;460&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-2/2/05_SeerNet_quntization_hucc3c7253dfa6848e984e714af7a258ce_78014_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-2/2/05_SeerNet_quntization_hucc3c7253dfa6848e984e714af7a258ce_78014_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;SeerNet Quntization&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;120&#34;
		data-flex-basis=&#34;289px&#34;
	
&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;quantized-convolution&#34;&gt;Quantized Convolution&lt;/h3&gt;
&lt;p&gt;책에 Quantized Convolution, Quantized ReLU activation, Quantized batch normalization 수식 있음&lt;/p&gt;
&lt;h3 id=&#34;inference-acceleration&#34;&gt;Inference Acceleration&lt;/h3&gt;
&lt;p&gt;Inference 성능향상을 위해 Intel AVX2 vector 연산 사용&lt;/p&gt;
&lt;h3 id=&#34;sparsity-mask-encoding&#34;&gt;Sparsity-Mask Encoding&lt;/h3&gt;
&lt;p&gt;sparse convolution 성능 향상을 위해 row/column index vector를 이용해 sparsity mask를 엔코딩&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;feature map을 vector format으로 변환(다수의 feature map은 matrix 형태가 됨)&lt;/li&gt;
&lt;li&gt;column index에는 sparse bit의 column 위치 row index 에는 각 row column의 시작위치가 있음(책에 그림 볼 것)&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Xilinx IDE installation based on Docker</title>
        <link>https://muonkmu.github.io/p/xilinx-ide-installation-based-on-docker/</link>
        <pubDate>Tue, 28 Feb 2023 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/xilinx-ide-installation-based-on-docker/</guid>
        <description>&lt;p&gt;개인 프로젝트를 진행하는데 Xilinx에서 제공하는 레퍼런스의 개발환경이 제각각이다.
우선 기본적으로 IDE 2019.2 버전이 필요한데 현재 데스크탑에 설치되어 있는 개발환경은 2022.1이다.
재 설치를 하기 보다는 Docker로 가상화 공간에 별도의 개발환경을 설치해 보자&lt;/p&gt;
&lt;h2 id=&#34;docker-gui&#34;&gt;Docker GUI&lt;/h2&gt;
&lt;h3 id=&#34;how-to-use-a-gui-on-the-docker&#34;&gt;How to use a GUI on the docker&lt;/h3&gt;
&lt;p&gt;Docker에서 개발환경을 가상화 하는 것은 좋은데 Docker는 기본적으로 CLI 환경만 제공한다. 그러나 많은 임베디드 개발환경은 설치 및 실행에서 GUI를 필요로 하기에 Docker에서 GUI를 구성하는 방법은 아래와 같다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;desktop 환경이 설치된 Docker에서 VNC 이용&lt;/li&gt;
&lt;li&gt;SSH 기반에서 X11 Forwarding을 이용해 HOST에서 GUI를 띄운다.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;1번째 방법은 GUI docker image를 다운받아 설정하고 여기에 ssh의 ForwardX11 옵션을 활성화 하면 2번째 방법도 지원이 된다.&lt;/p&gt;
&lt;h3 id=&#34;docker-image-다운-및-실행&#34;&gt;Docker image 다운 및 실행&lt;/h3&gt;
&lt;p&gt;선구자가 LXDE 환경의 Docker를 개발하였다. 하기 사이트에서 사용법을 읽어보자.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://hub.docker.com/r/dorowu/ubuntu-desktop-lxde-vnc/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://hub.docker.com/r/dorowu/ubuntu-desktop-lxde-vnc/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;다음과 같은 순서로 도커 이미지를 설치하고 실행하자(약 100GB의 용량이 필요하다)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;도커 이미지 다운&lt;/li&gt;
&lt;li&gt;필요시 이미지 이름 변경 및 기존 이미지 삭제&lt;/li&gt;
&lt;li&gt;해당 이미지의 설명을 참조하여 도커를 실행&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo docker pull dorowu/ubuntu-desktop-lxde-vnc
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo docker image tag dorowu/ubuntu-desktop-lxde-vnc:lastest &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;이미지이름&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;:&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;이미지tag&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo docker rmi dorowu/ubuntu-desktop-lxde-vnc
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo docker run -d -p &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;HTTP_PORT&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;:80 -p &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;VNC_PORT&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;:5900 -p &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;SSH_PORT&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;:22 -e &lt;span class=&#34;nv&#34;&gt;RESOLUTION&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;1920x1080 -e &lt;span class=&#34;nv&#34;&gt;VNC_PASSWORD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;xilinx -e &lt;span class=&#34;nv&#34;&gt;USER&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;xilinx -e &lt;span class=&#34;nv&#34;&gt;PASSWORD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;xilinx -v /dev/shm:/dev/shm -v &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;작업 디렉토리 마운팅&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;:/home/xilinx/Workspace --name xilinx-dev &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;이미지이름&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;:&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;이미지tag&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;이후 Docker의 VNC에 연결하여 진행한다.
기본적으로 필요한 패키지들을 설치하고 만약 &lt;code&gt;.bashrc&lt;/code&gt;가 없어서 터미널의 색깔이 없다면 해당파일을 복사한다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt-get install openssh-server
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cp /etc/skel/.bashrc &lt;span class=&#34;nv&#34;&gt;$HOME&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;petalinux-install&#34;&gt;Petalinux Install&lt;/h2&gt;
&lt;h3 id=&#34;사전준비&#34;&gt;사전준비&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;필요 패키지들을 설치한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.xilinx.com/v/u/2019.2-English/ug1144-petalinux-tools-reference-guide&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://docs.xilinx.com/v/u/2019.2-English/ug1144-petalinux-tools-reference-guide&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo dpkg --add-architecture i386
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt update
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;gawk make net-tools libncurses5-dev tftpd zlib1g:i386 libssl-dev flex bison libselinux1 gnupg wget diffstat chrpath socat xterm autoconf libtool tar unzip texinfo zlib1g-dev gcc-multilib build-essential screen pax gzip python2.7 cpio
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol&gt;
&lt;li&gt;locale에 en_US.utf8을 추가한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt-get install -y locales
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo locale-gen en_US.utf8
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;install&#34;&gt;Install&lt;/h3&gt;
&lt;p&gt;Petalinux 설치파일을 다운로드 하고 설치한다. sudo 권한 없이 설치해야하므로 설치폴더의 소유자는 현재 user로 한다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo mkdir /tools/Xilinx/Petalinux/2019.2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo chown -R xilinx:xilinx /tools/Xilinx/Petalinux
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;chmod +x &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;설치파일&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;./&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;설치파일&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt; /tools/Xilinx/Petalinux/2019.2
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;vivado-install&#34;&gt;Vivado Install&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;설치파일을 다운로드 하고 설치를 진행한다.(sudo 권한으로 설치?)&lt;/li&gt;
&lt;li&gt;필요 시 libtinfo5f를 설치한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;chmod +x &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;설치파일&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo ./&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;설치파일&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt-get install libtinfo5
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        <item>
        <title>[AI HW Design] Chap08 Network Sparsity (1/2)</title>
        <link>https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-1/2/</link>
        <pubDate>Sat, 25 Feb 2023 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-1/2/</guid>
        <description>&lt;p&gt;8장은 시스템 throughput을 높이기 위해 ineffectual zoro operation을 스킵하는 다양한 구조에 대해 알아본다. (feature map encoding/indexing, weight sharing/pruning, quantized prediction)&lt;/p&gt;
&lt;h2 id=&#34;energy-efficient-inference-engine-eie&#34;&gt;Energy Efficient Inference Engine (EIE)&lt;/h2&gt;
&lt;p&gt;스탠포드 대학에서 나온 유명한 논문, 알고리즘(SW) + 가속기(SW) 양쪽에 대해 최적화한 논문으로 알고 있다. 중요도에 비해 설명이 부실한 듯&amp;hellip;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;EIE는 sparse matrix-vector mutiplication을 위한 compressed network model을 지원하고 weight sharing을 다룸&lt;/li&gt;
&lt;li&gt;Leading Non-Zero Detection Network, Central Conrol Unit, Processing Element 로 구성&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;leading-non-zero-detection-network-lnzd&#34;&gt;Leading Non-Zero Detection Network (LNZD)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;LNZD는 input activation으로 부터 nonzero element를 찾아내고 이를 LNZD node로 먹임&lt;/li&gt;
&lt;li&gt;node는 nonzero value와 index를 PE로 브로드캐스팅 함&lt;/li&gt;
&lt;li&gt;LNZD에 PE는 4개가 연결&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-1/2/01_EIE_PE_LNZD.png&#34;
	width=&#34;432&#34;
	height=&#34;300&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-1/2/01_EIE_PE_LNZD_huc96f5c73e9317af5fcbb4d0b7427ae06_21530_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-1/2/01_EIE_PE_LNZD_huc96f5c73e9317af5fcbb4d0b7427ae06_21530_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;EIE leading nonzero detection network&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;144&#34;
		data-flex-basis=&#34;345px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;central-control-unit-ccu&#34;&gt;Central Control Unit (CCU)&lt;/h3&gt;
&lt;p&gt;CCU는 network segment computation을 제어&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;host와 커뮤니케이션 하고 PE state를 모니터링 함&lt;/li&gt;
&lt;li&gt;두가지 동작모드로 나뉨
&lt;ul&gt;
&lt;li&gt;computing mode : CCU는 LNZD로 부터 nonzero input activation을 받고 이를 PE로 브로드캐스팅, 모든 input channel이 스캔될때 까지 반복됨&lt;/li&gt;
&lt;li&gt;I/O mode : PE는 idle, activation과 weight가 DMA에 의해 접근 됨&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;processing-element-pe&#34;&gt;Processing Element (PE)&lt;/h3&gt;
&lt;p&gt;요약하면 ifmap 값을 읽어와서 여기 포인터를 이용하여 해당 weight 값과 효율적으로 곱한다는 이야기인듯..&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PE는 activation queue, pointer read unit, sparse matrix unit, arithmetic unit, activation R/W unit으로 구성&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-1/2/02_EIE_PE_archi.png&#34;
	width=&#34;1339&#34;
	height=&#34;371&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-1/2/02_EIE_PE_archi_hu4a8254844eadbc3e86f6c2cae8627339_197913_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-1/2/02_EIE_PE_archi_hu4a8254844eadbc3e86f6c2cae8627339_197913_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;EIE PE architecture&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;360&#34;
		data-flex-basis=&#34;866px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;computation 동안 CCU는 nonzero input element와 index를 activation queue에 브로드캐스팅 함, PE는 큐가 다차면 input element를 처리(브로드캐스트는 중지)&lt;/li&gt;
&lt;li&gt;activation queue는 PE가 work backlog를 구축할 수 있도록 해줌(load balancing 문제 해결)&lt;/li&gt;
&lt;li&gt;pointer read unit은 activation queue의 인덱스를 이용하여 nonzero element의 시작/종료 포인터를 찾음&lt;/li&gt;
&lt;li&gt;싱글 사이클에 이를 처리하기 위해 포인터는 LSB와 함께 odd/even SRAM에 저장(의미를 잘 모르겠음)&lt;/li&gt;
&lt;li&gt;sparse matrix read unit은 sparse matrix memory로 부터 포인터를 이용하여 0이 아닌 값을 읽음(fmap?)&lt;/li&gt;
&lt;li&gt;arithmetic unit은 activation queue와 sparse matrix memory의 0이 아닌 값 MAC 연산&lt;/li&gt;
&lt;li&gt;연속적으로 가산기 사용되는 경우를 위한 bypass 경로 존재 (그림 보자)&lt;/li&gt;
&lt;li&gt;activation read/write unit의 경우 fully connected layrer를 위한 source/destination activation register를 가지고 있으며 이는 다음 레이어 연산시 교체됨&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;deep-compression&#34;&gt;Deep Compression&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;EIE는 pruning과 weight sharing을 통해 네트워크 압축하기위해 Deep Commpression을 적용, 적용 예는 다음과 같음 (책에 그림 예시를 보자)
&lt;ul&gt;
&lt;li&gt;4X4 weight matrix라면 16개의 값을 4개의 index(code book)로 만듬&lt;/li&gt;
&lt;li&gt;index에 해당하는 weight는 Gradient를 가지고 fine-tunnig됨&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;MAC 연산은 weight와 input activation vector가 0이 아닌 값에 대해서 수행&lt;/li&gt;
&lt;li&gt;EIE는 interleaved Commpressed Sparse Column(CSC) 적용 (Eyeriss와 약간 다르므로 책참조)
&lt;ul&gt;
&lt;li&gt;v는 0이 아닌 값, z는 0이 아닌 값 해당 v 값 앞에 0의 개수&lt;/li&gt;
&lt;li&gt;v,z는 하나의 large array pair에 $p_j$(벡터의 시작 포인터), $p_{j+1}$(마지막 항목 다음 번 포인터)와 함께 저장됨&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;sparse-matrix-computation&#34;&gt;Sparse Matrix Computation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;4개의 PE에서 input activation vector(a)는 weight matrix(w)와 곱해짐&lt;/li&gt;
&lt;li&gt;a를 스캔해서 0이 아닌 $a_j$는 인덱스 값과 함께 브로드캐스팅 됨&lt;/li&gt;
&lt;li&gt;PE는 index에 대응하는 0이 아닌 $w_j$를 곱합&lt;/li&gt;
&lt;li&gt;PE는 벡터 v를 $p_j$에서 $p_j+_1$까지만 스캔
(책에 예시 그림 있으니 참조)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;cambricon-x-accelerator&#34;&gt;Cambricon-X Accelerator&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;병렬연산에서 Nonzero neuron을 선택하기 위해 indexing scheme을 적용&lt;/li&gt;
&lt;li&gt;Control Processor (CP), Buffer Controller (BC), Input Neural Buffer (NBin), Output Neural Buffer (NBout), Direct Memory Access (DMA) Module, Computation Unit (CU)으로 구성&lt;/li&gt;
&lt;li&gt;중요 element는 BC Tn indexing unit(nonzero neuron을 인덱싱하는 유닛이며 PE와 수가 같다)&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-1/2/03_Cambricon-X_archi.png&#34;
	width=&#34;660&#34;
	height=&#34;588&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-1/2/03_Cambricon-X_archi_huabb91cf32cb2211099253a3648178d82_23226_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-1/2/03_Cambricon-X_archi_huabb91cf32cb2211099253a3648178d82_23226_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Cambricon-X architecture&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;112&#34;
		data-flex-basis=&#34;269px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;computation-unit-cu&#34;&gt;Computation Unit (CU)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;CU는 Tn개 PE로 구성되며 모든 PE는 fat tree 형태로 연결&lt;/li&gt;
&lt;li&gt;PE는 PE Functional Unit(PEFU)와 Synapse Buffer(SB)로 구성&lt;/li&gt;
&lt;li&gt;BC로 부터 neuron을, local BC로 부터 synaps를 읽어서 PEFU에 제공하며 output neuron은 BC에 다시 씀&lt;/li&gt;
&lt;li&gt;Tn개 PEFU는 Tm개 곱셈기와 가산기를 가져서 TnXTm 곱셈이 가능&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-1/2/04_Cambricon-X_PE_archi.png&#34;
	width=&#34;709&#34;
	height=&#34;666&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-1/2/04_Cambricon-X_PE_archi_hu87e93c84bfbce09b528c0e6429ef2f43_40459_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-1/2/04_Cambricon-X_PE_archi_hu87e93c84bfbce09b528c0e6429ef2f43_40459_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Cambricon-X PE architecture&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;106&#34;
		data-flex-basis=&#34;255px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;SB는 synapse를 저장하고 메모리 access를 최소화 하기 위해 디자인, 책에서는 하기 예시를 듬(책그림 참조)
&lt;ul&gt;
&lt;li&gt;PE는 4개이고 output neuron 0이 input neruon 2개 연결, output neuron 1이 input neruon 5개 연결&lt;/li&gt;
&lt;li&gt;output neuron 0의 weight는 address 0에 output neuron 1의 weight는 address 1/2의 SB에 저장&lt;/li&gt;
&lt;li&gt;output neuron 0 계산 시 SB를 1번 읽고 output neuron 1은 두 번 읽음&lt;/li&gt;
&lt;li&gt;synapse의 수는 output neuron마다 다를 수 있기 때문에 SB가 비동기적으로 데이터를 로드하여 전체 성능을 향상&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;buffer-controller&#34;&gt;Buffer Controller&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;BC는 Indexing Module (IM)과 BC Functional Unit (BCFU) 로 구성
&lt;ul&gt;
&lt;li&gt;BCFU는 인덱싱을 위해 neuron을 저장&lt;/li&gt;
&lt;li&gt;IM은 BC의 nonzero nueron을 구분하고 nonzero indexed nueron만 전송&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;BC는 input neurons을 NBin에서 PE로 보내거나 BCFU로 제공, PE의 계산결과는 BCFU에 저장 또는 NBout에 쓰여짐&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-1/2/05_Cambricon-X_BC_archi.png&#34;
	width=&#34;982&#34;
	height=&#34;694&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-1/2/05_Cambricon-X_BC_archi_hu608d04ea44a57a3b368d80bb229fbc9d_35431_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap08-network-sparsity-1/2/05_Cambricon-X_BC_archi_hu608d04ea44a57a3b368d80bb229fbc9d_35431_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Cambricon-X BC architecture&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;141&#34;
		data-flex-basis=&#34;339px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;IM에는 두가지 하기 두가지 옵션이 있음 (책에 그림에 잘 나와 있음)
&lt;ul&gt;
&lt;li&gt;direct indexing : nonzero nueron의 여부를 0/1로 표현한 binary string 사용&lt;/li&gt;
&lt;li&gt;step indexing : nonzero nueron의 거리를 사용&lt;/li&gt;
&lt;li&gt;step indexing이 area와 power를 적게 소모함&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>[AI HW Design] Chap06 &amp; 07 In/Near Memory Computation</title>
        <link>https://muonkmu.github.io/p/ai-hw-design-chap06-07-in/near-memory-computation/</link>
        <pubDate>Tue, 21 Feb 2023 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/ai-hw-design-chap06-07-in/near-memory-computation/</guid>
        <description>&lt;p&gt;6장은 In-Memory Computation, 7장은 Near-Memory Computation 에 대한 내용이다. 현재 개발하고자 하는 가속기와 동떨어지는 내용이라 판단해서 개요만 보고 스킵할 예정이다.
삼성이나 하이닉스를 다녀야 쓸모있지 않을까 싶다.&lt;/p&gt;
&lt;h2 id=&#34;in-memory-computation&#34;&gt;In-Memory Computation&lt;/h2&gt;
&lt;p&gt;여기서는 메모리와 로직을 stacking 하는 방식의 Processor-In-Memory(PIM)에 대해 설명한다. 다른 방식의 PIM도 있는 걸로 아는데&amp;hellip;&lt;/p&gt;
&lt;h3 id=&#34;neurocube-architecture&#34;&gt;Neurocube Architecture&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Nerocube는 parallel neural processing unit과 High Bandwidth Memory(HBM)을 스택한 Hybrid Memory Cube(HMC)를 이용&lt;/li&gt;
&lt;li&gt;이는 stacked memrory에서 PE로 직접 데이터 로드가 가능함(레이턴시 감소)&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap06-07-in/near-memory-computation/01_Neurocube_archi.png&#34;
	width=&#34;850&#34;
	height=&#34;484&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap06-07-in/near-memory-computation/01_Neurocube_archi_hu7e3ac3480d8fffeef819172836ca0123_89087_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap06-07-in/near-memory-computation/01_Neurocube_archi_hu7e3ac3480d8fffeef819172836ca0123_89087_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Neurocube architecture&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;175&#34;
		data-flex-basis=&#34;421px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;teris-accelerator&#34;&gt;Teris Accelerator&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Teris는 Eyeriss의 3D Memory와 함께 Row Stationary(RS) dataflow 채택&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap06-07-in/near-memory-computation/02_Tetris_archi.png&#34;
	width=&#34;1200&#34;
	height=&#34;814&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap06-07-in/near-memory-computation/02_Tetris_archi_hue0cec8dafc2424a6cf3e0101670db0cd_520795_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap06-07-in/near-memory-computation/02_Tetris_archi_hue0cec8dafc2424a6cf3e0101670db0cd_520795_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Tetris system architecture&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;147&#34;
		data-flex-basis=&#34;353px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;neurostream-accelerator&#34;&gt;NeuroStream Accelerator&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;NeuroStream은 HMC의 modular extension인 Smart Memory Cube(SMC)를 이용&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap06-07-in/near-memory-computation/03_NeuroStream_arch.png&#34;
	width=&#34;1226&#34;
	height=&#34;1306&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap06-07-in/near-memory-computation/03_NeuroStream_arch_hucb12ff9120ba45e699b7649d69b4155b_231205_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap06-07-in/near-memory-computation/03_NeuroStream_arch_hucb12ff9120ba45e699b7649d69b4155b_231205_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;NeuroStream and NeuroCluster architecture&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;93&#34;
		data-flex-basis=&#34;225px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;near-memory-computation&#34;&gt;Near-Memory Computation&lt;/h2&gt;
&lt;h3 id=&#34;didiannao-supercomputer&#34;&gt;DiDianNao Supercomputer&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;대용량 eDRAM을 통해 DianNao의 memory bottleneck을 해결하고자 함&lt;/li&gt;
&lt;li&gt;모든 synapse를 수용할 후 있는 거대 storage를 제공하는 Neural Function Unit(NFU)를 지닌 16개의 tile로 구성&lt;/li&gt;
&lt;li&gt;NFU는 4개의 eDRAM bank와 time-interleaved 통신(?) 함 (eDRAM의 레이턴시가 크기 때문)&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap06-07-in/near-memory-computation/04_DaDianNao_archi.png&#34;
	width=&#34;1214&#34;
	height=&#34;622&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap06-07-in/near-memory-computation/04_DaDianNao_archi_hu3dc4a4aa5e68fb351920261bd2859b52_93958_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap06-07-in/near-memory-computation/04_DaDianNao_archi_hu3dc4a4aa5e68fb351920261bd2859b52_93958_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;DaDianNao system architecture&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;195&#34;
		data-flex-basis=&#34;468px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cnvlutin-accelerator&#34;&gt;Cnvlutin Accelerator&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;DiDianNao에서 파생되었으며 다수의 DiDianNao를 고속 인터페이스로 연결, 거대 parallel mutiplication lane 구조 채택&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>[AI HW Design] Chap05 Convolution Optimization (3/3)</title>
        <link>https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-3/3/</link>
        <pubDate>Sun, 19 Feb 2023 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-3/3/</guid>
        <description>&lt;p&gt;앞의 포스트가 너무 길어져서 Eyeriss version2 부분은 현 포스트로 나눔&lt;/p&gt;
&lt;h2 id=&#34;eyeriss-accelerator-ver2&#34;&gt;Eyeriss Accelerator Ver.2&lt;/h2&gt;
&lt;p&gt;irregular data pattern 과 network sparsity 지원을 위한 Eyeriss V2 공개&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;새로운 NoC 구조 : data reuse가 적을 땐 external memory에서 더 많은 데이터를 PE로 가져오고  data reuse가 많을 땐 spartial Data를 sharing&lt;/li&gt;
&lt;li&gt;CSC 엔코딩 적용&lt;/li&gt;
&lt;li&gt;RS+ 적용&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Eyeriss V1이 GLB&amp;lt;-&amp;gt;PE 연결을 위해 flat multicast NoC를 사용했지만 V2에서는 flexible and mesh NoC 사용,
이 hierarchical mesh는 GLB cluster, Router Cluster, PE cluster로 구성되며 하기 3가지 타입의 데이터 이동 지원&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ifmap은 GLB cluster에 로드됨, 이는 GLB 메모리에 저장되고 Router Cluster로 전송&lt;/li&gt;
&lt;li&gt;psum은 GLB 메모리에 저장 되고, ofmap은 external memory에 바로 저장 됨&lt;/li&gt;
&lt;li&gt;fmap은 Router Cluster로 전송되고 PE spad에 저장&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-3/3/01_Eyeriss_v2_system_archi.png&#34;
	width=&#34;1090&#34;
	height=&#34;622&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-3/3/01_Eyeriss_v2_system_archi_hu72a2311e75580f2efbca22981e0f948c_86395_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-3/3/01_Eyeriss_v2_system_archi_hu72a2311e75580f2efbca22981e0f948c_86395_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Eyeriss v2 system architecture&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;175&#34;
		data-flex-basis=&#34;420px&#34;
	
&gt;
(책에 v1 과 v2 구조에 대한 비교 그림이 있으니 찾아보자)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;hierarchical-mesh-network-hm-noc&#34;&gt;Hierarchical Mesh Network (HM-NoC)&lt;/h3&gt;
&lt;p&gt;전통적인 Network-on-Chip 구조는 하기와 같으며 장단점을 가지고 있음 (책 그림 참조)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Broadcast Network : high reuse / low bandwidth&lt;/li&gt;
&lt;li&gt;Unicast Network : high bandwidth / low reuse&lt;/li&gt;
&lt;li&gt;All-to-All Network : high reuse, high bandwidth / scale difficulty&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Eyeriss V2는 RS+를 지원하기 위해 HM-NoC 구조를 제안, all-to-all network에서 파생되었으나 4가지 모드를 가짐&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Broadcast: single input and single weight&lt;/li&gt;
&lt;li&gt;Unicast: multiple inputs and multiple weights&lt;/li&gt;
&lt;li&gt;Grouped multicast: shared weights&lt;/li&gt;
&lt;li&gt;Interleaved multicast: shared inputs&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-3/3/02_Mesh_network_config.png&#34;
	width=&#34;1095&#34;
	height=&#34;270&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-3/3/02_Mesh_network_config_hu7c65497e49921880cc047795eaed4cf9_175240_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-3/3/02_Mesh_network_config_hu7c65497e49921880cc047795eaed4cf9_175240_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Mesh network configuration&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;405&#34;
		data-flex-basis=&#34;973px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;HM-NoC는 source, destination, router로 구성되며 design phase에서 cluster로 그룹핑되고 operation mode에서는 고정됨.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Router cluster가 다른 cluster와 one-to-one, many-to-many, source/destination 구조로 연결&lt;/li&gt;
&lt;li&gt;Router cluster는 4개의 source/destination port를 가지며 4가지 routing mode (broadcast, unicate, grouped/interleaved multicast)를 가짐&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;책에서는 다음과 같이 예시를 듬&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Convolution layer : ifmap과 fmap이 reuse 되며 grouped multicast 또는 interleaved mode 로 구성&lt;/li&gt;
&lt;li&gt;Depth-wise Convolution layer : fmap만 reuse 되며 fmap이 PE로 broadcast, ifmap은 GLB에서 로드&lt;/li&gt;
&lt;li&gt;Fully connected layer : ifmap이 모든 PE로 broadcast, fmap은 unicast mode로 로드&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;input-activation-hm-noc&#34;&gt;Input Activation HM-NoC&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Router Cluster 안의 3개 ifmap router는 GLB cluster의 ifmap SRAM과 연결&lt;/li&gt;
&lt;li&gt;ifmap routerd의 3개의 source/destination port 다른 클러스터와 연결, 1개는 메모리에서 데이터로드, 1개는 PE 연결&lt;/li&gt;
&lt;li&gt;책에 그림과 상세 설명이 있으니 참조하자&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;filter-weight-hm-noc&#34;&gt;Filter Weight HM-NoC&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Router Cluster 안의 각 fmap router는 PE cluster 안의 PE row와 연결&lt;/li&gt;
&lt;li&gt;vertical mesh는 사라지고 horizontal mesh 만 데이터 reuse를 위해 남음&lt;/li&gt;
&lt;li&gt;책에 그림과 상세 설명이 있으니 참조하자&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;partial-sum-hm-noc&#34;&gt;Partial Sum HM-NoC&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Router Cluster 안의 4개의 psum router는 GLB cluster의 psum SRAM과 PE cluster의 PE column과 연결됨&lt;/li&gt;
&lt;li&gt;horizontal mesh는 사라지고  vertical mesh만 psum accumulation을 위해 남음&lt;/li&gt;
&lt;li&gt;책에 그림과 상세 설명이 있으니 참조하자&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;compressed--sparse-column-csc-format&#34;&gt;Compressed  Sparse Column (CSC) Format&lt;/h3&gt;
&lt;p&gt;Eyeriss V2는 ifmap과 fmap 둘 다에 CSC 포맷 적용 (zero operation skipping), CSC 포맷의 구조는 다음과 같다&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data vector : 0이 아닌 값&lt;/li&gt;
&lt;li&gt;Counter vector : Data vector의 item 기준, 해당 열에서 앞에 있는 0의 값의 갯수&lt;/li&gt;
&lt;li&gt;Address vector : 각 열을 기준으로 이전 열까지 0이 아닌 item의 누적 갯수&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-3/3/03_CSC_format.png&#34;
	width=&#34;988&#34;
	height=&#34;683&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-3/3/03_CSC_format_hub1bb5f53114ac8ca37a38a301b9de523_189171_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-3/3/03_CSC_format_hub1bb5f53114ac8ca37a38a301b9de523_189171_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Compressed sparse column format&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;144&#34;
		data-flex-basis=&#34;347px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Eyeriss V2는 PE는 zero operation skip을 위해 7 pipeline stage와 5 spad (ifmap, fmap, psum 저장)로 수정&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;첫째로 non-zero data인지 확인하기 위해 address를 검사하고 fmap 로드 전 먼저 ifmap을 로드(zero ifmap skip을 위해)&lt;/li&gt;
&lt;li&gt;ifmap/fmap이 0이 아니면 계산 pipeline 수행, fmap이 0이면 pipeline disable&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-3/3/04_Eyeriss_v2_PE_archi.png&#34;
	width=&#34;1098&#34;
	height=&#34;520&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-3/3/04_Eyeriss_v2_PE_archi_hu6538d1528bc1b96b882dcb94c7cd426f_43122_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-3/3/04_Eyeriss_v2_PE_archi_hu6538d1528bc1b96b882dcb94c7cd426f_43122_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Eyeriss v2 PE architecture&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;211&#34;
		data-flex-basis=&#34;506px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;row-stationary-plus-rs-dataflow&#34;&gt;Row Stationary Plus (RS+) Dataflow&lt;/h3&gt;
&lt;p&gt;PE utilization을 높이기 위해 RS+ dataflow 적용&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;model dimension을 다른 PE dimension에 매핑하기 위해 데이터를 tiling, spatial fragmentation 함&lt;/li&gt;
&lt;li&gt;depth-wise convolution 시 PE utilization이 낮은 문제점 해결&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-3/3/05_RS&amp;#43;_dataflow.png&#34;
	width=&#34;978&#34;
	height=&#34;348&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-3/3/05_RS&amp;#43;_dataflow_hud8aa43c1c4159e4637e897eeb4c09dc1_22311_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-3/3/05_RS&amp;#43;_dataflow_hud8aa43c1c4159e4637e897eeb4c09dc1_22311_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;row stationary plus dataflow&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;281&#34;
		data-flex-basis=&#34;674px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>[AI HW Design] Chap05 Convolution Optimization (2/3)</title>
        <link>https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/</link>
        <pubDate>Sat, 18 Feb 2023 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/</guid>
        <description>&lt;p&gt;유명한 MIT의 Eyeriss Accelerator 논문이다. 아직까지 관련 프로젝트가 진행 중인 것으로 보이며 찾아보면 관련 논문에 대하여 리뷰해논 자료가 꽤 많다.
잘 소개된 곳 한 곳 (허락없는 링크..)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&amp;amp;blogId=kangdonghyun&amp;amp;logNo=220990374125&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&amp;blogId=kangdonghyun&amp;logNo=220990374125&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;eyeriss-accelerator&#34;&gt;Eyeriss Accelerator&lt;/h2&gt;
&lt;p&gt;Eyeriss Accelerator는 data access를 최소화하기 위한 Row Stationary (RS) Dataflow를 제안하며 다음과 같은 특징을 지님&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spartial architecture with sequential processing configuration
&lt;ul&gt;
&lt;li&gt;Spartial architecture can exploit high compute parallelism using direct communication between an array of relatively simple processing engines (PEs).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Row Stationary (RS) Dataflow 구현&lt;/li&gt;
&lt;li&gt;Four level memory hierarchy : PE scratch pad와 inter-PE 통신을 최대한 이용하고 Global Buffer와 외부 메모리의 data transfer를 최소화&lt;/li&gt;
&lt;li&gt;point-to-point &amp;amp; multicast Network-on-Chip(NoC) 아키텍쳐 지원&lt;/li&gt;
&lt;li&gt;Run-Length Compression (RLC) 포맷 지원 : zero operation 제거&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;eyeriss-system-architecture&#34;&gt;Eyeriss System Architecture&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Eyeriss는 과 communication link clock 두가지 clock domain을 가짐
&lt;ul&gt;
&lt;li&gt;data processing core clock : 12X14 PE array, Global Buffer(GLB), RLC codec, ReLu 배치, PE가 local scratchpad를 이용하여 연산하거나 PE가 인접 PE 또는 GLB와 통신 하는것을 가능하게 함&lt;/li&gt;
&lt;li&gt;communication link clock&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Four level memory hierarchy
&lt;ul&gt;
&lt;li&gt;GLB &amp;lt;-&amp;gt; external memory : asynchronous FIFO 이용&lt;/li&gt;
&lt;li&gt;PE &amp;lt;-&amp;gt; GLB : NoC 이용&lt;/li&gt;
&lt;li&gt;ReLU &amp;lt;-&amp;gt; RLC codec&lt;/li&gt;
&lt;li&gt;local temporary data storage using scratchpad&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;분리된 clock으로 PE는 다른 PE와 같은 클럭 시간에 독립적으로 동작가능하고 link clock은 external memory와 64bit 양방향 버스로 data 전송을 제어&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/01_Eyeriss_system_archi.png&#34;
	width=&#34;882&#34;
	height=&#34;311&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/01_Eyeriss_system_archi_huf1524314c1b2ba265b52bb1365fc6338_34365_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/01_Eyeriss_system_archi_huf1524314c1b2ba265b52bb1365fc6338_34365_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Eyeriss system architecture&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;283&#34;
		data-flex-basis=&#34;680px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;Eyeriss Acc는 Convolution network를 레이어 단위로 진행
&lt;ul&gt;
&lt;li&gt;첫째로 PE array를 레이어 function/size에 맞게 구성하고 매핑 수행 및 전송 패턴을 결정&lt;/li&gt;
&lt;li&gt;input feature map 및 filter map은 external memory에서 PE로 로드되고 output feature map은 다시 external memory로 쓰여짐&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2d-convolution-to-1d-multiplication&#34;&gt;2D convolution to 1D multiplication&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;convolution을 수행할 때 2D feature/filter map을 1D로 바꾸어 수행해서 PE에 순차적으로 로딩한다는 이야기를 길게 써놓음 (궁금하면 책을 보자)
&lt;ul&gt;
&lt;li&gt;2D convolution을 1D vector 와 Toeplitz 행렬(대각선의 성분이 모두 같은 매트릭스)의 곱으로 변환된다&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;책에 어떤 순서로 feature/filter 1D vector가 PE에 로드/계산되는지 그림으로 있다.&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/02_1D_row_convolution.png&#34;
	width=&#34;807&#34;
	height=&#34;555&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/02_1D_row_convolution_hu821e8a0c54af7140bd12bc2289e267fd_105196_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/02_1D_row_convolution_hu821e8a0c54af7140bd12bc2289e267fd_105196_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;145&#34;
		data-flex-basis=&#34;348px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;stationary-dataflow&#34;&gt;Stationary Dataflow&lt;/h3&gt;
&lt;p&gt;칩에 대한 이야기는 아니고 이전의 stationary 전략에 대해 소개한다. (연산을 어떤 데이터를 고정, 이동 시킬지)&lt;/p&gt;
&lt;h4 id=&#34;output-stationary&#34;&gt;Output Stationary&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Patial Sum의 read/write를 local accumulation을 통해 최소화&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;weight-stationary&#34;&gt;Weight Stationary&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;filter map을 local buffer에 두고 계속 활용&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;input-stationary&#34;&gt;Input Stationary&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;input feature map을 local buffer에 두고 계속 활용&lt;/li&gt;
&lt;li&gt;다른 전략보다 효율이 안좋은데 약점은 다른 전략보다 convolution연산에 더 많은 cycle이 필요&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;row-stationary-rs-dataflow&#34;&gt;Row Stationary (RS) Dataflow&lt;/h3&gt;
&lt;p&gt;Eyeriss는 1D vector multiplication 수행하는데 RS dataflow 전략을 사용&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;filter map 행은 PE들에서 수평하게 재사용&lt;/li&gt;
&lt;li&gt;input feature map 행은 PE들에서 대각적으로 재사용&lt;/li&gt;
&lt;li&gt;partial sum 행은 PE들에서 수직적으로 재사용&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/03_Eyeriss_RS_dataflow.png&#34;
	width=&#34;889&#34;
	height=&#34;301&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/03_Eyeriss_RS_dataflow_hu83a06e14ef6cd6bea9052c996e8c4779_80929_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/03_Eyeriss_RS_dataflow_hu83a06e14ef6cd6bea9052c996e8c4779_80929_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Eyeriss RS dataflow&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;295&#34;
		data-flex-basis=&#34;708px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;RS dataflow에서 데이터는 계산 동안 PE에 저장됨(데이터 이동 최소화)&lt;/li&gt;
&lt;li&gt;time-interleaved approach를 통해 fmap과 ifmap은 같은 clock cycle 내에서 재활용&lt;/li&gt;
&lt;li&gt;계산이 완료되면 Psum은 근접 PE들로 이동(다음 계산을 위해서)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;filter-reuse&#34;&gt;Filter Reuse&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;fmap이 spad에 로드 되고 고정된다. 다수의 ifmap도 spad에 로드되고 사슬처럼 연걸됨&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;input-feature-maps-reuse&#34;&gt;Input Feature Maps Reuse&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;ifmap이 먼저 PE에 로드 되고 2개의 fmap은 time-interleaved(연산?) 됨&lt;/li&gt;
&lt;li&gt;1개의 ifmap으로 2개의 fmap과 1D 연산 수행&lt;/li&gt;
&lt;li&gt;이 것은 전체적인 스피드를 올려주지만 fmap과 psum의 time-interleave 연산을 지원하기 위해 큰 spad가 필요&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;partial-sums-reuse&#34;&gt;Partial Sums Reuse&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;fmap/ifmap 둘 다 PE에 로드되며 둘 다 time-interleaved 함&lt;/li&gt;
&lt;li&gt;psum은 같은 채널 끼리 합쳐짐&lt;/li&gt;
&lt;li&gt;fmap/ifmap 둘 다 PE에 로드되어야 하므로 필요한 spad의 용량이 증가&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;run-length-compression-rlc&#34;&gt;Run-Length Compression (RLC)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;ReLU 연산 결과 0 값이 많아 지므로 이는 network의 sparsity가 도입됨&lt;/li&gt;
&lt;li&gt;zero computation을 피하기 위해 Eyeriss는 64 bit  RLC 포맷을 도입
&lt;ul&gt;
&lt;li&gt;([5bit]앞에 값이 0인 element 갯수 + [16bit]0이 아닌 값)*3 + [1bit]마지막 item인지 나타내는 flag&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/04_Eyeriss_RLC.png&#34;
	width=&#34;425&#34;
	height=&#34;200&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/04_Eyeriss_RLC_hub59b108cd57493ff3ac688d982967fe9_14291_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/04_Eyeriss_RLC_hub59b108cd57493ff3ac688d982967fe9_14291_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Eyeriss run-length compression&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;212&#34;
		data-flex-basis=&#34;510px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;첫번째 layer의 ifmap 값을 제회하고 모든 fmap/ifmap은 RLC 포맷으로 external memory에 저장&lt;/li&gt;
&lt;li&gt;External Memory에서 입출력 될 때, RLC encoder/decoder를 통과하게 됨&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;glabal-buffer-glb&#34;&gt;Glabal Buffer (GLB)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;external memory와 데이터 전송을 위해 GLB 채택&lt;/li&gt;
&lt;li&gt;GLB에는 fmap/ifmap/ofmap/psum 이 저장&lt;/li&gt;
&lt;li&gt;GLB는 PE가 연산하는 동안 다음 fmap을 preload&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;processing-element-pe-architecture&#34;&gt;Processing Element (PE) Architecture&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;PE는 fmap, ifmap, psum을 위한 3가지 타입의 spad를 가짐&lt;/li&gt;
&lt;li&gt;datapath는 3가지 pipeline stage에 의해 구성(spad access, fmap/ifmap multiplication, psum accumulation)&lt;/li&gt;
&lt;li&gt;16bit 연산을 사용하며 32bit 연산결과는 16bit로 절삭&lt;/li&gt;
&lt;li&gt;값이 O인 ifmap이 발견되면 spad에서 fmap 값을 읽는 것과 연산 로직을 끔(전력소모를 줄이기 위해)&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/05_Eyeriss_PE_archi.png&#34;
	width=&#34;876&#34;
	height=&#34;471&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/05_Eyeriss_PE_archi_hu6d4af46b5849dcef0bf48d3b94639878_43237_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/05_Eyeriss_PE_archi_hu6d4af46b5849dcef0bf48d3b94639878_43237_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Eyeriss processing element architecture&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;185&#34;
		data-flex-basis=&#34;446px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;network-on-chip-noc&#34;&gt;Network-on-Chip (NoC)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;NoC는 GLB와 PE 사이의 데이터 이동을 관리, 하기 2개로 구분
&lt;ul&gt;
&lt;li&gt;Global Input Network (GIN) : GLB &amp;lt;-&amp;gt; PE 간 single cycle multicast 이용 데이터 전송
&lt;ul&gt;
&lt;li&gt;Y-Bus는 12개의 X-bus와 연결되며 X-bus는 14개의 PE가 연결&lt;/li&gt;
&lt;li&gt;top level controller는 &amp;lt;row,col&amp;gt; 태그를 생성하고 Y-bus / PE의 Multicast controller가 tag를 비교하여 데이터 전송 결정&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/06_Eyeriss_GIN.png&#34;
	width=&#34;885&#34;
	height=&#34;454&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/06_Eyeriss_GIN_hudd45dfb58898f938211550fa285202e2_35533_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-2/3/06_Eyeriss_GIN_hudd45dfb58898f938211550fa285202e2_35533_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Eyeriss global input network&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;194&#34;
		data-flex-basis=&#34;467px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;책에 AlexNet의 예시 있음&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Global Output Network (GON) : 별다른 설명 없음&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>[AI HW Design] Chap05 Convolution Optimization (1/3)</title>
        <link>https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-1/3/</link>
        <pubDate>Sun, 12 Feb 2023 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-1/3/</guid>
        <description>&lt;p&gt;Convolution은 90% 이상의 Computing resource를 사용하며, data access를 줄이기 위해 feature maps reuse / filter weights reuse / partial sum reuse 같은 전략이 사용된다.
이번 챕터에서는 filter decomposition과 Row Stationary(RS) flow를 설명한다.&lt;/p&gt;
&lt;h2 id=&#34;deep-convolution-neural-network-accelerator-dcnn&#34;&gt;Deep Convolution Neural Network Accelerator (DCNN)&lt;/h2&gt;
&lt;p&gt;DCNN은 클라우드 타겟이 아닌 엣지 디바이스 타겟으로 UCLA에서 개발, 다음과 같은 특징을 지님&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Streaming data flow minimizes data access&lt;/li&gt;
&lt;li&gt;병렬 컴퓨팅을 위해 bandwidth  향상이 아닌 Interleaving architecture&lt;/li&gt;
&lt;li&gt;Large-size filter decomposition supports arbitrary convolution window&lt;/li&gt;
&lt;li&gt;추가적인 pooling functional unit을 통한 Convolution Unit(CU)의 workload 감소&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;system-architecture&#34;&gt;System Architecture&lt;/h3&gt;
&lt;p&gt;DCNN의 구성은 다음과 같다&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Buffer Bank
&lt;ul&gt;
&lt;li&gt;중간 데이터 저장 및 외부 메모리와 데이터 교환 목적&lt;/li&gt;
&lt;li&gt;Layer Input 용, Layer Output 용 2가지 셋으로 나누어짐&lt;/li&gt;
&lt;li&gt;또한 odd/even channel/feature를 위한 Bank A와 Bank B로 나누어짐(Interleaved)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Column Buffer
&lt;ul&gt;
&lt;li&gt;Buffer banck의 데이터를 CU engine의 input data type으로 remap&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Convolution Unint(CU) engine
&lt;ul&gt;
&lt;li&gt;CU engin은 kernel size 3X3까지 지원하는 16개의 Convolution unit으로 구성&lt;/li&gt;
&lt;li&gt;16bit fixed-point 연산&lt;/li&gt;
&lt;li&gt;local Prefetch unit이 DMA로 부터 weight/bias 값을 주기적으로 업데이트 함&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Accumulation (ACCU) buffer
&lt;ul&gt;
&lt;li&gt;convolution 동안 partial sum 연산 또는 Max pooling 연산 수행&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-1/3/01_DCNN_HW_Archi.png&#34;
	width=&#34;751&#34;
	height=&#34;463&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-1/3/01_DCNN_HW_Archi_hu3c580145d215e702491efc9736215254_29901_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-1/3/01_DCNN_HW_Archi_hu3c580145d215e702491efc9736215254_29901_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;DCNN hardware architecture&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;162&#34;
		data-flex-basis=&#34;389px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;Control Command는 외부 메모리에서 128-depth FIFO로 로드 되며 하기 2가지로 분류됨
&lt;ul&gt;
&lt;li&gt;configure command : network layer를 구성하고 pooling/ReLU function 활성화&lt;/li&gt;
&lt;li&gt;excution command : convolution/pooing 초기화 및 필터 decompose 기술&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;filter-decomposition&#34;&gt;Filter Decomposition&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;다양한 필터 커널 사이즈 대응을 위해 3X3 CU engine을 이용하여 filter decomposition 기술 이용&lt;/li&gt;
&lt;li&gt;커널 사이즈가 3의 배수가 아니면 zero-padding 이용&lt;/li&gt;
&lt;li&gt;convolution 후 결과는 one output feature map으로 재결합 됨&lt;/li&gt;
&lt;li&gt;상세 사항은 책 참조&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;streaming-architecture&#34;&gt;Streaming Architecture&lt;/h3&gt;
&lt;p&gt;데이터의 이동을 최소화하기위해 Filter Weights Reuse와 Input Channel Reuse 사용&lt;/p&gt;
&lt;h4 id=&#34;filter-weights-reuse&#34;&gt;Filter Weights Reuse&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;3X3 convolution : filter weight는 CU engine에 저장되고 input feature map이 CU engine으로 공급되며 연산이 완료 될 때까지 filter weight는 업데이트 되지 않음&lt;/li&gt;
&lt;li&gt;1X1 convolution : CU unit의 9개 곱셈기 중 7개는 off 되고 2개만 odd/even 채널의 partial sum 계산을 위해 사용&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-1/3/02_Data_streaming_archi_data_flow.png&#34;
	width=&#34;934&#34;
	height=&#34;693&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-1/3/02_Data_streaming_archi_data_flow_hu44efc47054aa1ffce71cbf0d622070e8_154287_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-1/3/02_Data_streaming_archi_data_flow_hu44efc47054aa1ffce71cbf0d622070e8_154287_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Data streaming architecture with the data flow&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;134&#34;
		data-flex-basis=&#34;323px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;Buffer Bank의 output bandwidth를 최대화하기 위해 구조는 하기와 같다(input cannel 및 Column buffer 구조 이야기 같은데)
&lt;ul&gt;
&lt;li&gt;16개의 row 데이터는 odd/even data set으로 나뉨&lt;/li&gt;
&lt;li&gt;2개의 FIFO는 각 데이터 셋에 페어링 됨 (8개의 row 데이터)&lt;/li&gt;
&lt;li&gt;8개의 input row data는 10개의 overlapped data로 매핑&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;input-channel-reuse&#34;&gt;Input Channel Reuse&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;1X1 convolution을 위해 interleaved architecture 사용 (16개 데이터 셋이 odd/even 채널로 2개 데이터셋 구분됨)&lt;/li&gt;
&lt;li&gt;2개의 데이터 셋은 다른 filter weight와 곱해져 32개 output이 나옴&lt;/li&gt;
&lt;li&gt;출력은 같은 odd/even 채널 끼리 더해짐&lt;/li&gt;
&lt;li&gt;위의 내용과 비슷한 것 같은데 filter weight가 이동하고 input 값이 고정이라는 걸 다시 설명한 듯&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pooling&#34;&gt;Pooling&lt;/h3&gt;
&lt;p&gt;pooling function은 average pooling과 max pooing 이 다른 구조로 분리되어 있음&lt;/p&gt;
&lt;h4 id=&#34;average-pooling&#34;&gt;Average Pooling&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Average Pooling function은 Convolution layer에서 Inpu/Output 채널이 같은 사이즈인 CU엔진에 의해 구현
&lt;ul&gt;
&lt;li&gt;kernel의 사이즈가 pooling window와 일치하는&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;대응되는 filter weight는 1/K^2으로 되고 나머지는 0으로 된 후 convolution 수행&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;max-pooling&#34;&gt;Max Pooling&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Max pooling은 ACCU에서 별도 모듈로 구현&lt;/li&gt;
&lt;li&gt;Max pooling 모듈은 scratch pad에 있는 8개의 output 값과 연결되며 이는 다른 stride를 지원하기 위해 MUX와 연결&lt;/li&gt;
&lt;li&gt;MUX의 출력은 MAX Pooling 계산기로 가는데 이는 3개의 입력과 1개의 output feedback 입력을 받아 계산하며 인풋이 없어질때까지 연산 반복&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-1/3/03_Max_pooling_archi.png&#34;
	width=&#34;924&#34;
	height=&#34;652&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-1/3/03_Max_pooling_archi_hud451dc32710866902d390d177efeafc4_54340_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap05-convolution-optimization-1/3/03_Max_pooling_archi_hud451dc32710866902d390d177efeafc4_54340_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Max pooling architecture&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;141&#34;
		data-flex-basis=&#34;340px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;convolution-unitcu-engine&#34;&gt;Convolution Unit(CU) Engine&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;3X3 CU engine은 9개의 PE(input feature와 filter weight를 곱함)와 1개의 ADDER로 구성&lt;/li&gt;
&lt;li&gt;다른 커널 사이즈 지원을 위해 PE는 On/Off 기능을 가짐&lt;/li&gt;
&lt;li&gt;상세 내용은 책 참조 (그림과 3X3일 때, 1X1일때 예시 있음)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;accumulation-accu-buffer&#34;&gt;Accumulation (ACCU) Buffer&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;ACCU는 scratch pad에 partial sums 과 stores output feature maps을 저장&lt;/li&gt;
&lt;li&gt;ACCU는 partial product accumulation을 위한 Ping-pong buffer, Max pooling을 위한 temporary storage, readout block으로 구성 (책에 그림 참조)&lt;/li&gt;
&lt;li&gt;Convolution이 진행되는 동안 1개 버퍼는 덧셈만 하고 다른 하나의 버퍼는 Max pooling을 진행, convolution이 완료된후 각 버퍼의 연결이 switch 됨&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;model-compression&#34;&gt;Model Compression&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Model Compression을 하기 위해 training 과정에서 모델을 pruning하고 filter weights를 codebook으로 quantization 함.&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>[MW_project] Camera 입력 및 DP 출력 구성</title>
        <link>https://muonkmu.github.io/p/mw_project-camera-%EC%9E%85%EB%A0%A5-%EB%B0%8F-dp-%EC%B6%9C%EB%A0%A5-%EA%B5%AC%EC%84%B1/</link>
        <pubDate>Wed, 08 Feb 2023 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/mw_project-camera-%EC%9E%85%EB%A0%A5-%EB%B0%8F-dp-%EC%B6%9C%EB%A0%A5-%EA%B5%AC%EC%84%B1/</guid>
        <description>&lt;p&gt;Target Board는 현재 소유하고 있는 ZCU104를 사용하기로 하고 EVB의 번들 카메라인 See3CAM_CU30를 사용하기로 하였다.
출력은 보드에 DP/HDMI가 있는데 DP는 PS 영역이며 HDMI는 사용자가 PL영역에 구성해야 한다. 그래서 DP로 결정.
선정 사유는 역시 Reference를 구하기 쉽다는것에 있다.
상기 ZCU104 + See3CAM_CU30의 reference design은 xilinx의 Embedded-Reference-Platforms 또는 Zynq-UltraScale-MPSoC-VCU-TRD-2022.1에서 확인할 수 있으나 필자는 봐도 어떻게 구성되어 있는지 잘 모르겠다&amp;hellip;&lt;/p&gt;
&lt;h2 id=&#34;기본-지식&#34;&gt;기본 지식&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;See3CAM_CU30은 USB3.0 카메라이므로 리눅스에서 &lt;code&gt;Usb Video Clss (UVC)&lt;/code&gt;를 gadget을 사용하여 연결한다.
&lt;ul&gt;
&lt;li&gt;UVC : 웹캠이나 캠코더 같은 비디오 스트리밍이 가능한 장치를 기술하는 USB device class&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Video4Linux2(v4l2) 비디오 캡쳐 시스템을 위한 디바이스 드라이버의 모음이자 표준 API
&lt;ul&gt;
&lt;li&gt;MIPI/USB camera 카메라등을 지원하는 것으로 봐선 UVC 위에서 표준 추상화 계층을 제공하는 것 같다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;출력은 기본적으로 Frame buffer 및 X11 + DRM KMS 구조를 지닌다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;petalinux-config&#34;&gt;petalinux config&lt;/h2&gt;
&lt;p&gt;이전 포스트인 &lt;code&gt;zcu104 개발환경 설정&lt;/code&gt;에서 다음 드라이버 및 프로그램을 설치한다.&lt;/p&gt;
&lt;h3 id=&#34;kernel&#34;&gt;kernel&lt;/h3&gt;
&lt;p&gt;커널은 하기 모듈이 필요하다. BSP를 사용했다면 거의 바꿀 것 없지만 &lt;code&gt;petalinux-config -c kernel&lt;/code&gt;로 다음 기능을 확인하자.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;카메라 입력 : USB gadget driver, web camera/video driver&lt;/li&gt;
&lt;li&gt;모니터 출력 : xilinx DRM KMS driver, frame buffer driver&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CONFIG_MEDIA_CAMERA_SUPPORT
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CONFIG_MEDIA_CONTROLLER
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CONFIG_VIDEO_V4L2_SUBDEV_API
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CONFIG_VIDEO_ADV_DEBUG
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CONFIG_MEDIA_USB_SUPPORT
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CONFIG_USB_VIDEO_CLASS
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CONFIG_USB_VIDEO_CLASS_INPUT_EVDEV
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CONFIG_V4L_PLATFORM_DRIVERS
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CONFIG_VIDEO_XILINX 및 그 외
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CONFIG_DRM_XLNX 및 그 외 (필요한지??)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CONFIG_USB 및 기타 가젯 필요한거
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CONFIG_USB_GADGET_XILINX
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CONFIG_USB_CONFIGFS 및 그외 (필요한지 잘 모르겠음)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;rootfs&#34;&gt;RootFS&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;petalinux-config -c rootfs&lt;/code&gt; RootFS에는 gstreamer/opencv/x11/v4lutil/gcc 패키지그룹, gstreamer 라이브러리, vim, python3 등을 설치한다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CONFIG_packagegroup-petalinux-gstreamer
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CONFIG_packagegroup-petalinux-opencv
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CONFIG_packagegroup-petalinux-x11
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CONFIG_packagegroup-petalinux-v4lutils
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CONFIG_packagegroup-core-buildessential
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CONFIG_vim
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CONFIG_python3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CONFIG_python3-shell (?)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CONFIG_python3-threading (?)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CONFIG_python3-multiprocessing (?)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CONFIG_gstreamer1.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CONFIG_gstreamer1.0-plugins-base
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CONFIG_gstreamer1.0-plugins-good
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;카메라-및-프래임-버퍼-테스트&#34;&gt;카메라 및 프래임 버퍼 테스트&lt;/h2&gt;
&lt;p&gt;상기 설정으로 빌드 및 부팅 후 USB 캠을 연결한다. 그 후 아래 명령어로 카메라의 정보를 확인 할 수 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;v4l2-ctl --list-devices&lt;/code&gt; : 연결된 디바이스 확인&lt;/li&gt;
&lt;li&gt;&lt;code&gt;v4l2-ctl -d ${디바이스번호} --all&lt;/code&gt; : 카메라 capability 등 모든 정보의 출력&lt;/li&gt;
&lt;li&gt;&lt;code&gt;v4l2-ctl -d ${디바이스번호} --list-formats-ext&lt;/code&gt; : 지원하는 포멧 확인.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;DP 포트와 모니터를 연결하면 Frame buffer &lt;code&gt;/dev/fb#&lt;/code&gt; 이 생성됨을 확인할 수 있다. &lt;code&gt;fbset&lt;/code&gt;명령으로 정보를 조해할 수 있다.&lt;/p&gt;
&lt;p&gt;python기반으로 opencv를 이용해서 카메라의 영상을 캡쳐 및 Framebuffer로 출력해 보자.
하기 코드는 테스트 용으로 카메라 및 프레임 버퍼의 설정 부분은 제외했으므로 출력이 이상할 수 있으니 필요하면 자신의 환경에 맞게 고쳐야 한다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;os&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;cv2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;time&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;capture&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cv2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;VideoCapture&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;time&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sleep&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# (success, reference) = capture.read()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# cv2.imwrite(&amp;#39;${이미지 저장 경로}/${저장 이름}&amp;#39;,reference)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;while&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ret&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;capFrame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;capture&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;frame16&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cv2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cvtColor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;capFrame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cv2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;COLOR_BGR2BGR565&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;fbframe&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cv2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;resize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;frame16&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1920&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1080&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;/dev/fb0&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;rb+&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;buf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;buf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;write&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fbframe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;capture&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;release&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;cv2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;destroyAllWindows&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;참고-자료&#34;&gt;참고 자료&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/Xilinx/Embedded-Reference-Platforms-User-Guide/tree/2019.2&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/Xilinx/Embedded-Reference-Platforms-User-Guide/tree/2019.2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://xilinx-wiki.atlassian.net/wiki/spaces/A/pages/2322268161/Zynq&amp;#43;UltraScale&amp;#43;MPSoC&amp;#43;VCU&amp;#43;TRD&amp;#43;2022.1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://xilinx-wiki.atlassian.net/wiki/spaces/A/pages/2322268161/Zynq+UltraScale+MPSoC+VCU+TRD+2022.1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.hackster.io/whitney-knitter/using-a-usb-web-camera-with-the-minized-5783b1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.hackster.io/whitney-knitter/using-a-usb-web-camera-with-the-minized-5783b1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.e-consystems.com/blog/camera/products/getting-started-with-xilinx-zynq-ultrascale-mpsoc-zcu104-evaluation-kit-and-see3cam_cu30_chl_tc_bx/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.e-consystems.com/blog/camera/products/getting-started-with-xilinx-zynq-ultrascale-mpsoc-zcu104-evaluation-kit-and-see3cam_cu30_chl_tc_bx/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://m.blog.naver.com/overcrash3/120105061216?referrerCode=1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://m.blog.naver.com/overcrash3/120105061216?referrerCode=1&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>[MW_project] zcu104 개발환경 설정</title>
        <link>https://muonkmu.github.io/p/mw_project-zcu104-%EA%B0%9C%EB%B0%9C%ED%99%98%EA%B2%BD-%EC%84%A4%EC%A0%95/</link>
        <pubDate>Fri, 03 Feb 2023 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/mw_project-zcu104-%EA%B0%9C%EB%B0%9C%ED%99%98%EA%B2%BD-%EC%84%A4%EC%A0%95/</guid>
        <description>&lt;p&gt;zcu104 petalinux를 포팅하기 위한 일주일 간 삽질의 기록이다.
xilinx에서 제공하는 training reference를 따라하면 간단하지만 이는 SD카드에 커널과 루트파일 시스템을 삽입하는 방법이다.
실제 개발의 편의성을 위해 TFTP 및 NFS를 이용하여 부팅하는 방법을 다룬다.&lt;/p&gt;
&lt;h2 id=&#34;목표&#34;&gt;목표&lt;/h2&gt;
&lt;p&gt;하기 boot config를 지원하는 petalinux의 포팅 방법 설명 (vivado/petalinux 2022.1 기반)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;jtag로 u-boot까지 다운로드 및 부팅 -&amp;gt; u-boot에서 tftp/pxe로 리눅스 kernel 및 device-tree 로드 명령-&amp;gt; 커널에 의한 NFS로 RootFS 로드&lt;/li&gt;
&lt;li&gt;SD카드로 u-boot까지 다운로드 및 부팅 -&amp;gt; u-boot에서 tftp/pxe로 리눅스 kernel 및 device-tree 로드 명령-&amp;gt; 커널에 의한 NFS로 RootFS 로드&lt;/li&gt;
&lt;li&gt;SD카드로 u-boot, 리눅스 kernel, device-tree 로드 -&amp;gt; 커널에 의한 NFS로 RootFS 로드&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;hardware-description-config&#34;&gt;Hardware description config&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;우선 베이스 프로젝트는 리눅스 포팅이 목적이므로 PS영역만 셋업한다.&lt;/li&gt;
&lt;li&gt;xilinx에서 제공하는 training reference를 그대로 따라해도 무방하다.
(&lt;a class=&#34;link&#34; href=&#34;https://xilinx.github.io/Embedded-Design-Tutorials/docs/2022.2/build/html/docs/Introduction/ZynqMPSoC-EDT/3-system-configuration.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://xilinx.github.io/Embedded-Design-Tutorials/docs/2022.2/build/html/docs/Introduction/ZynqMPSoC-EDT/3-system-configuration.html&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;zcu104_bsp에 사용되는 hw config을 보고 싶다면 후에 기술할 bsp에 기반한 petalinux 프로젝트 hardware 폴더에 관련 프로젝트가 들어있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;vivado-project-follow&#34;&gt;vivado project follow&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;vivado에서 zcu104보드 프로젝트를 만든다.
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Project is an extensible Vitis platform&lt;/code&gt; 은 vitis에서 xrt 라이브러리 등을 사용할 때 필요하다. 현 프로젝트에서는 미선택&lt;/li&gt;
&lt;li&gt;board 세팅에서 ZCU104를 선택&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;create block design&lt;/code&gt;을 선택하여 디자인 블럭 생성&lt;/li&gt;
&lt;li&gt;zynq_mpsoc ip 를 추가하고 borad preset을 적용한다.&lt;/li&gt;
&lt;li&gt;지금은 PL 영역이 필요없으로 AXI_HPM/HP 포트를 미사용으로 설정&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Validate Design&lt;/code&gt; 으로 디자인 검증 후 &lt;code&gt;Create HDL Wrapper&lt;/code&gt; 로 래퍼를 생성한다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Generate Block Design&lt;/code&gt;을 실행 후 &lt;code&gt;bit stream (*.bit)&lt;/code&gt; 을 생성한다.
&lt;ul&gt;
&lt;li&gt;현재는 pl 영역의 디자인이 없으므로 bit-stream을 생성하지 않아도 무관한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Export Hardware&lt;/code&gt;로 xsa 파일을 생성한다.
&lt;ul&gt;
&lt;li&gt;현재는 pl부분의 디자인이 없으므로 bit-stream을 포함하지 않아도 되며 포함하여도 상관없다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;petalinux-porting&#34;&gt;Petalinux porting&lt;/h2&gt;
&lt;h3 id=&#34;project-create&#34;&gt;project create&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;처음에는 기초부터 시작하고자 base template 프로젝트로 시작하였지만 포팅 시 부팅이 잘 안되었다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;petalinux-create -t project --name &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;프로젝트 이름&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt; --template zynqMP
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;petalinux-config --get-hw-description&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;xsa&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;파일&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt; --silentconfig
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;그래서 xilinx에서 제공하는 bsp 기반으로 프로젝트를 만들었다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;petalinux-create -t project --name &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;프로젝트 이름&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt; -s &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;bsp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;파일&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;petalinux-config --get-hw-description&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;xsa&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;파일&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt; --silentconfig
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;위의 두 프로젝트의 폴더/파일을 비교해보면 BSP를 위해 커널등이 어떻게 설정되어 있는지 알 수 있다.&lt;/li&gt;
&lt;li&gt;bsp 기반으로 만들어진 프로젝트의 경우 &lt;code&gt;README&lt;/code&gt;에 BSP가 어떤 설정을 가지고 만들어져 있는지 나와 있다. 위의 기본 템플릿 프로젝트와 파일과 비교해서 보면 몇가지 설정에 대한 설명이 누락되었음을 알 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;tftp-boot-config&#34;&gt;tftp boot config&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;이전 post인 ubuntu 환경 설정을 내용을 참고하여 host에 tftp 서버를 설정한다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;petalinux-config&lt;/code&gt; 명령을 실행하여 &lt;code&gt;Image Packaging Configuration &amp;gt; Copy final images to tftpboot&lt;/code&gt;에 host tftp서버 폴더를 지정한다.&lt;/li&gt;
&lt;li&gt;만약 향후에 RootFS를 INITRAMFS으로 할려고 할 시 built-in FIT image를 위한 임시 ram 사이즈가 작아서 부팅 시 &amp;ldquo;There&amp;rsquo;s no &amp;lsquo;/dev&amp;rsquo; on rootfs&amp;rdquo; 에러가 난다. 이럴 경우 &lt;code&gt;petalinux-config&lt;/code&gt;의  &lt;code&gt;Image packaging configuration &amp;gt; INITRAMFS/INITRD Image name&lt;/code&gt; 을 &lt;code&gt;petalinux-image-minimal&lt;/code&gt;로 변경 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;nfs-rootfs-config&#34;&gt;NFS rootFS config&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;이전 post인 ubuntu 환경 설정을 내용을 참고하여 host에 NFS 서버를 설정한다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;petalinux-config&lt;/code&gt; 명령을 실행하여 &lt;code&gt;Image Packaging Configuration&lt;/code&gt; 에서 하기 내역을 설정
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Root File System Type&lt;/code&gt;에서 NFS를 선택&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Location of NFS root directory&lt;/code&gt;에 host nfs 폴더를 지정&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NFS Server IP address&lt;/code&gt; 에서 host ip를 지정&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;petalinux-config -c kernel&lt;/code&gt;에서 하기 내역이 설정 되어 있는지 확인
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Networking support &amp;gt; IP: kernel level configuration&lt;/code&gt; 의 IP:DHCP support, IP:BOOTP support, IP:RARP support&lt;/li&gt;
&lt;li&gt;&lt;code&gt;File systems &amp;gt; Network file systems &amp;gt; Root file systems&lt;/code&gt;의 NFS 체크&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;상기 내역까지가 매뉴얼의 내용인데 적용해보면 nfs 버전 문제로 nfs RootFS가 마운트 되지 않는다. &lt;code&gt;bootargs&lt;/code&gt;에서 nfs version을 3으로 변경한다.
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;petalinux-config&lt;/code&gt;에서 &lt;code&gt;DTG Setting &amp;gt; Kernel Bootargs &amp;gt; generate boot args automatically&lt;/code&gt;를 해제 (해제하기전에 설정되어 있는 bootargs를 copy)&lt;/li&gt;
&lt;li&gt;위에 복사한 것을 bootargs를 작성하는 란에 붙여넣고 nfsroot부분에 nfsvers=3 추가&lt;/li&gt;
&lt;li&gt;ex) &lt;code&gt; earlycon console=ttyPS0,115200 clk_ignore_unused root=/dev/nfs nfsroot=192.168.1.30:/home/minwook/xlx_nfsrfs,tcp,nfsvers=3 ip=dhcp rw&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;mac-설정&#34;&gt;MAC 설정&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;u-boot 부팅 시 마다 아이피가 달라지지 않도록 MAC를 설정한다.
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;petalinux-config&lt;/code&gt; 명령의 &lt;code&gt;Subsystem AUTO Hardware Setting &amp;gt; Ethernet Setting &amp;gt; Ethernet MAC address&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;사실 zcu104의 맥 주소는 부팅 시 eeprom에서 읽어 온다는데 u-boot에서는 안되는 것 같다(사실 잘 모르겠다.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;build-및-부팅-준비&#34;&gt;build 및 부팅 준비&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;u-boot 및 커널 등을 빌드한다.&lt;/li&gt;
&lt;li&gt;jtag로 부팅 시키기 위해서는 pre-built 폴더에 이미지들이 준비되어 있어야 한다. &lt;code&gt;petalinux-package&lt;/code&gt;를 이용해 준비하자.&lt;/li&gt;
&lt;li&gt;host의 NFS 서버 폴더에 RootFS를 압축 해제 시켜 NFS 부팅을 준비한다.&lt;/li&gt;
&lt;li&gt;향후 SD 카드 등에 부트로더/부트 스크립트를 복사할 경우를 대비하여 부팅이미지를 생성하자.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;petalinux-build
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;petalinux-package --prebuilt
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; images/linux
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;tar -xzf rootfs.tar.gz -C &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;NFS&lt;/span&gt;&lt;span class=&#34;p&#34;&gt; 서버 폴더&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;petalinux-package --boot --fsbl zynqmp_fsbl.elf --fpga system.bit --pmufw pmufw.elf --atf bl31.elf --u-boot u-boot.elf
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;빌드가 정상적으로 완료되면 이전에 지정한 host의 tftp 폴더에 build된 image들이 자동으로 복사된다.
&lt;ul&gt;
&lt;li&gt;향후 u-boot에서 tftp로 커널 등을 로드할 때 tftp 서버의 &lt;code&gt;pxelinux.cfg&lt;/code&gt; 폴더 내 어떤 이미지를 로드할 것인지에 대한 설정을 파일에서 읽어온다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pxelinux.cfg&lt;/code&gt; 폴더의 &lt;code&gt;default&lt;/code&gt; 파일을 보면 tftp 서버에서 kernel, dtb, RootFS를 로드한다는 것을 알 수 있다.&lt;/li&gt;
&lt;li&gt;우리는 NFS에서 RootFS를 로드 할 예정이므로 &lt;code&gt;default&lt;/code&gt; 파일의 RootFS 로딩 스크립트 부분을 삭제한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;크로스-컴파일-환경-설정&#34;&gt;크로스 컴파일 환경 설정&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;향후 application의 개발 시 host에서 크로스 컴파일을 진행하고 싶다면 sdk를 만들어 sysroot를 설정하면 된다.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;petalinux-build --sdk
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;petalinux-package --sysroot -d &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;SDK_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;설치_폴더&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;unset&lt;/span&gt; LD_LIBRARY_PATH
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt; &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;SDK_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;설치_폴더&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;/environment-setup-cortexa72-cortexa53-xilinx-linux
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;petalinux-booting&#34;&gt;Petalinux Booting&lt;/h2&gt;
&lt;h3 id=&#34;jtag-boot&#34;&gt;jtag boot&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;jtag로 u-boot까지 로딩한다. 보드의 boot-cfg 스위치를 jtag로 맞춘다. SD카드 등이 필요없지만 속도가 느리다.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;petalinux-boot --jtag --prebuilt &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt; --hw_server-url tcp:127.0.0.1:3121
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;host에 USB를 연결하고 터미널을 오픈 후 하기 명령을 수행하면 부팅이 시작된다.부트 스크립트 로딩 전 대기 카운터에서 엔터를 누르면 u-boot 커맨드 입력이 가능하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;u-boot에서-커널-로딩&#34;&gt;u-boot에서 커널 로딩&lt;/h3&gt;
&lt;p&gt;u-boot에서 command를 이용하여 tftp서버에서 커널과 dtb를 로드한다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;dhcp로 target ip 획득&lt;/li&gt;
&lt;li&gt;tftp 서버의 ip 및 target의 ip의 환경변수 설정
&lt;ul&gt;
&lt;li&gt;이부분은 petalinux-config의 &lt;code&gt;u-boot Configuration &amp;gt; u-boot script configuration &amp;gt; Pre bootenv&lt;/code&gt; 에서 설정이 가능할 것이라 생각되는데 해보지 않음&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;tftp 서버에서 설정파일 로드 (&lt;code&gt;pxelinux.cfg/default&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;tftp 부팅 (이후 RootFS의 로드는 세팅에 따른다.)&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;dhcp
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;setenv serverip &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;host_ip&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;setenv ipaddr &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;target_ip&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pxe get
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pxe boot
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;sd카드--nfs-rootfs&#34;&gt;SD카드 + NFS RootFS&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;jtag로 부팅하면 편하긴 하지만 느리고 매번 리셋이 필요할 때마다 부팅명령을 다시 넣어줘야 한다. 이를 SD카드로 부팅시켜 해결할 수 있다.&lt;/li&gt;
&lt;li&gt;보드의 boot-cfg 스위치를 SD 카드로 변경한다.&lt;/li&gt;
&lt;li&gt;SD카드가 준비되어 있지 않다면 SD카드를 파티션 설정을 해야 한다.
&lt;ul&gt;
&lt;li&gt;첫번째 파티션은 부트로더, 부팅스크립트 등을 위한 파티션이며 최소 500MB이며 FAT 파일 형식&lt;/li&gt;
&lt;li&gt;두번째 파티션은 RootFS용으로 EXT4 형식이어야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;SD카드에 FSBL, U-boot, bitstream인 &lt;code&gt;BOOT.bin&lt;/code&gt; 를 넣어 놓고 u-boot 까지 부팅 시킨 후 이후 커널 및 RootFS를 로딩할 수 있다.&lt;/li&gt;
&lt;li&gt;SD카드에 커널의 내용이 변경되지 않은 경우 부팅스크립트 &lt;code&gt;boot.scr&lt;/code&gt;와 커널/디바이스트리 &lt;code&gt;image.ub&lt;/code&gt;를 넣어 놓고 자동으로 NFS에서 RootFS를 로딩하게 하는 방법도 가능하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;참고-자료&#34;&gt;참고 자료&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://xilinx.github.io/Embedded-Design-Tutorials/docs/2022.2/build/html/index.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://xilinx.github.io/Embedded-Design-Tutorials/docs/2022.2/build/html/index.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/Xilinx/Vitis-Tutorials&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/Xilinx/Vitis-Tutorials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.xilinx.com/r/2021.1-English/ug1144-petalinux-tools-reference-guide/Configure-TFTP-Boot&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://docs.xilinx.com/r/2021.1-English/ug1144-petalinux-tools-reference-guide/Configure-TFTP-Boot&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>[AI HW Design] Chap04 Streaming Graph Theory (2/2)</title>
        <link>https://muonkmu.github.io/p/ai-hw-design-chap04-streaming-graph-theory-2/2/</link>
        <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/ai-hw-design-chap04-streaming-graph-theory-2/2/</guid>
        <description>&lt;p&gt;본 챕터에서는 graph-based deep-learnig accelerator 중 Graphcore IPU에 대해 알아본다.
Graphcore IPU는 Microsoft와 Dell의 차세대 데이터 센터 딥러닝 가속기로 선정되었다.&lt;/p&gt;
&lt;h2 id=&#34;graphcore-intelligence-processing-unitipu&#34;&gt;Graphcore Intelligence Processing Unit(IPU)&lt;/h2&gt;
&lt;p&gt;Graphcore IPU는 fine-grained operation을 수행하기 위하여 graph theory를 적용하며 MIMD paralleism을 제공&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fine-Grained : 하나의 작업을 작은 단위의 프로세스로 나눈 뒤 다수의 호출을 통해, 작업 결과를 생성해내는 방식, 반대말은 Coarse-Grained.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;intelligence-processor-unit-architecture&#34;&gt;Intelligence Processor Unit Architecture&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;IPU는 tiles라 불리는 1216 PE로 구성&lt;/li&gt;
&lt;li&gt;PE는 256kb local memory를 가지며 레지스터 파일을 제외한 추가 memory storage를 가지지 않음&lt;/li&gt;
&lt;li&gt;tiles 간 IPU Exchange라 불리는 on-chip interconnect로 연결되어 있으며 IPU간 연결을 위한 IPU link를 제공&lt;/li&gt;
&lt;li&gt;IPU는 6개의 개별 processing thread를 제공하며 각 thread는 별개의 instruction과 excution flow를 제공&lt;/li&gt;
&lt;li&gt;각 tile은 static round-robin schedule에 따라 thread 들을 순환한다.&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap04-streaming-graph-theory-2/2/01_IPU_architecture.png&#34;
	width=&#34;617&#34;
	height=&#34;989&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap04-streaming-graph-theory-2/2/01_IPU_architecture_huc029ac9d4313a641df7f4585440b0aa8_991509_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap04-streaming-graph-theory-2/2/01_IPU_architecture_huc029ac9d4313a641df7f4585440b0aa8_991509_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Intelligence processing unit architecture&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;62&#34;
		data-flex-basis=&#34;149px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;accumulating-matrix-product-amp-unit&#34;&gt;Accumulating Matrix Product (AMP) Unit&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;IPU는 pipelined structure AMP를 채택, AMP는 64bit mix-precison 또는 16bit single-point 연산을 클럭 사이클 마다 수행 가능
&lt;ul&gt;
&lt;li&gt;mix-precison : 훈련 중에 모델에서 16-bit 및 32-bit 부동 소수점 유형을 모두 사용하여 더 빠르게 실행하고 메모리를 적게 사용하는 것, 모델의 특정 부분을 32-bit 유형으로 유지&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;memory-architecture&#34;&gt;Memory Architecture&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;PE 당 256kb local memory를 가지며 IPU는 총 304Mb 메모리를 가짐&lt;/li&gt;
&lt;li&gt;각 tile은 21bit address space를 가지며 6개의 execution unit과 이를 공유함&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;interconnect-architecture&#34;&gt;Interconnect Architecture&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;IPU 간 연결은 IPU link를 사용하며 2개 IPU 연결은 3개의 IPU link를 사용 (65Gb/s)&lt;/li&gt;
&lt;li&gt;Host완s PCIE-4로 연결&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bulk-synchronous-parallel-bsp-model&#34;&gt;Bulk Synchronous Parallel (BSP) Model&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;IPU operation은 BSP 모델을 기반으로 하며, BSP 모델은 아래 3개의 Phase Operation으로 구분된다.
&lt;ul&gt;
&lt;li&gt;Computation Phase : 모든 프로세서가 로컬 메모리로 computation을 수행하며 프로세서간 어떤 통신도 없다.&lt;/li&gt;
&lt;li&gt;Communication Phase : 각 프로세서는 정보를 교환하며 어떤 computation도 없다.&lt;/li&gt;
&lt;li&gt;Barrier Synchronization : 모든 프로세서는 computation이나 communication 없이 모든 프로세서가 barrier에 도달할 때까지 대기한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;IPU는 computation이 시작되기 전에 instruction이 코어로 전송되는 BSP 모델을 실행한다. core는 computation을 수행하고 이가 끝난 뒤 다른 코어와 communication을 수행한다. 그후 모든 코어는 동기화를 수행한다.&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap04-streaming-graph-theory-2/2/02_IPU_BSP_model.png&#34;
	width=&#34;611&#34;
	height=&#34;307&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap04-streaming-graph-theory-2/2/02_IPU_BSP_model_hu0e2373d75f221ade042503bd4543a98b_34792_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap04-streaming-graph-theory-2/2/02_IPU_BSP_model_hu0e2373d75f221ade042503bd4543a98b_34792_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;IPU BSP model&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;199&#34;
		data-flex-basis=&#34;477px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;결론&#34;&gt;결론&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Blaize GSP와 Graphcore IPU는 분산 프로세서를 통해 거대 parallel operation을 처리할 수 있기에 Cloud-base application에 좋은 솔루션이다.&lt;/li&gt;
&lt;li&gt;그러나 이들은 power/area 문제로 임베디드 추론 application에는 적합하지 않다.&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>[AI HW Design] Chap04 Streaming Graph Theory (1/2)</title>
        <link>https://muonkmu.github.io/p/ai-hw-design-chap04-streaming-graph-theory-1/2/</link>
        <pubDate>Fri, 27 Jan 2023 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/ai-hw-design-chap04-streaming-graph-theory-1/2/</guid>
        <description>&lt;p&gt;본 챕터에서는 graph-based deep-learnig accelerator에 대해 공부한다 (Blaize GSP, Graphcore IPU).
이들은 Mutiple Instructions Multiple Data(MIMD) 처럼 동작한다.&lt;/p&gt;
&lt;h2 id=&#34;blaize-graph-streaming-processorgsp&#34;&gt;Blaize Graph Streaming Processor(GSP)&lt;/h2&gt;
&lt;p&gt;무언가 칩에 대한 설명보단 Graph Streaming 기본 이론에 대한 내용이 주를 이룬다.&lt;/p&gt;
&lt;h3 id=&#34;stream-graph-model&#34;&gt;Stream Graph Model&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Stream Graph는 네트워크 트래픽, 데이터베이스 등에 널리 쓰이는 모델로 dynamic stream data를 처리하기 위해 data stream model(TCS)을 사용
&lt;ul&gt;
&lt;li&gt;거대 그래프 스트리밍 Transit(T), 큰 데이터 처리 Compute(C), 일시/롱텀 데이터 저장 Store(S)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Turnstile 모델이 TCS모델 중에서 데이터 출발/도착과 같은 data behavior을 가장 잘 표현하며 task scheduling에 사용.&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap04-streaming-graph-theory-1/2/01_Data_streaming_TCS_Model.png&#34;
	width=&#34;317&#34;
	height=&#34;483&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap04-streaming-graph-theory-1/2/01_Data_streaming_TCS_Model_hud047163813c097f2344ae308b4f685e4_77661_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap04-streaming-graph-theory-1/2/01_Data_streaming_TCS_Model_hud047163813c097f2344ae308b4f685e4_77661_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Data streaming TCS Model&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;65&#34;
		data-flex-basis=&#34;157px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;depth-first-scheduling-approach&#34;&gt;Depth First Scheduling Approach&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Blaize GSP는 뉴럴넷모델을 Direct Acyclic Graph(DAG) format (V,E)로 변환
&lt;ul&gt;
&lt;li&gt;V는 PE vertex, E는 PE간 weighted connection을 위한 edge&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;scheduling을 위해 Depth First Scheduling (DFS)를 사용하며 dynamic graph excution을 가능하게 하고 sparse/conditional graph를 지원한다. (dfs 설명은 유명하니 생략)&lt;/li&gt;
&lt;li&gt;GSP는 4가지 Parallelism을 달성했다. 자세한 설명은 책 참조
&lt;ul&gt;
&lt;li&gt;Task parallelism, Thread parallelism, Data parallelism, Instructon parallelism&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;graph-streaming-processor-architecture&#34;&gt;Graph Streaming Processor Architecture&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;GSP는 다음 그림과 같은 구조로 되어 있음&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap04-streaming-graph-theory-1/2/02_Blaize_GSP_architecture.png&#34;
	width=&#34;617&#34;
	height=&#34;183&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap04-streaming-graph-theory-1/2/02_Blaize_GSP_architecture_hub0e573f6ff23a6411796e6d052794dc5_16408_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap04-streaming-graph-theory-1/2/02_Blaize_GSP_architecture_hub0e573f6ff23a6411796e6d052794dc5_16408_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Blaize GSP architecture&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;337&#34;
		data-flex-basis=&#34;809px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;Streaming Processing은 Sequential Processing에 비해 하기와 같은 장점이 있음 (책에 두가지 방법에 대해 비교 그림있음)
&lt;ul&gt;
&lt;li&gt;Small intermediate buffer for local processing&lt;/li&gt;
&lt;li&gt;Cached data is easily supported&lt;/li&gt;
&lt;li&gt;Memory bandwidth is reduced to improve the performance with less power&lt;/li&gt;
&lt;li&gt;Support both task and data-parallel processing&lt;/li&gt;
&lt;li&gt;Data is sent to the next node when it is ready&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;GSP는 opeartion을 데이터가 준비되는 즉시 기다리지 않고 수행하도록 스케줄링 함으로써 성능을 향상시키고 메모리 access를 감소시킴&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>git 사용 tip 정리</title>
        <link>https://muonkmu.github.io/p/git-%EC%82%AC%EC%9A%A9-tip-%EC%A0%95%EB%A6%AC/</link>
        <pubDate>Fri, 20 Jan 2023 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/git-%EC%82%AC%EC%9A%A9-tip-%EC%A0%95%EB%A6%AC/</guid>
        <description>&lt;p&gt;Git을 사용하다보면 막히는 부분이 항상 생긴다. 이런 부분에 대해 간단히 정리 해 놓는다.&lt;/p&gt;
&lt;h2 id=&#34;git-remote-branch-가져오기&#34;&gt;Git remote branch 가져오기&lt;/h2&gt;
&lt;p&gt;Git을 사용하다보면 원격저장소에 있는 branch를 local로 가져와야 경우가 있다. 이럴 때  &lt;code&gt;git checkout -t {저장소 이름}&lt;/code&gt; 을 사용하면 된다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;필요 시 git remote를 갱신&lt;/li&gt;
&lt;li&gt;필요 시 remote  브랜치 확인&lt;/li&gt;
&lt;li&gt;remote 브랜치 가져오기&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git remote update
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git branch -r
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git checkout -t &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;origin/저장소 이름&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;만약 브랜치의 이름을 변경하여 가져오고 싶다면 &lt;code&gt;git checkout -b {생성할 branch 이름} {원격 저장소의 branch 이름}&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;만약 checkout 시 &lt;code&gt;-t&lt;/code&gt; 옵션을 제외하면 ‘detached HEAD’ 상태로 소스를 보고 변경 해볼 수도 있지만 변경사항들은 commit, push 할 수 없으며 다른 branch로 checkout하면 사라진다.&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>[MW_project] YOLO v3 tiny 분석</title>
        <link>https://muonkmu.github.io/p/mw_project-yolo-v3-tiny-%EB%B6%84%EC%84%9D/</link>
        <pubDate>Mon, 16 Jan 2023 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/mw_project-yolo-v3-tiny-%EB%B6%84%EC%84%9D/</guid>
        <description>&lt;p&gt;Target Model을 YOLOv3_tiny로 정한 것은 다른 이유가 있는 것은 아니고 간단하고 레퍼런스가 쉽게 구할 수 있어서이다.
사실 프로젝트가 YOLOv3 tini의 경우 매우 가볍기 때문에 가속기로의 의미는 크게 없다고 생각한다.
그러나 YOLO-X 모델 같은 가속기를 구현하기 위해서는 Sparse Matrix operation 등이 적용 가능한 NPU와 같은 구조를 잡는 것이 필요할 것이라 생각되어 미루어 두기로 한다.
우선 간단한 가속기를 구현하는 것에 의미를 둔다.&lt;/p&gt;
&lt;h2 id=&#34;yolo-reference&#34;&gt;YOLO reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;YOLO v3 tiny은 YOLO v3에서 FPN 을 덜어내고 경량화 시킨 구조이다. 라즈베리 파이 CPU에서도 돌릴 수 있다고 한다.
( 실제로 돌려보니 정확도가 좀 떨어지는 것 같다. 바운딩 박스도 이상하게 쳐지고)&lt;/li&gt;
&lt;li&gt;기본적인 코드는 darknet git에서 구할 수 있다. 사용법 및 설명은 홈페이지에서 볼 수 있다.
(&lt;a class=&#34;link&#34; href=&#34;https://pjreddie.com/darknet/yolo/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://pjreddie.com/darknet/yolo/&lt;/a&gt;)
&lt;ol&gt;
&lt;li&gt;darknet repo pull&lt;/li&gt;
&lt;li&gt;make(GPU 사용 예정이라면 Makefile 수정)&lt;/li&gt;
&lt;li&gt;pre-trained 된 weights 다운&lt;/li&gt;
&lt;li&gt;test&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://github.com/pjreddie/darknet
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; darknet
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;make
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wget https://pjreddie.com/media/files/yolov3-tiny.weights
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;./darknet detect cfg/yolov3-tiny.cfg yolov3-tiny.weights data/dog.jpg
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;yolov3-tiny.cfg&lt;/code&gt; 파일을 보면 Model의 구조를 알 수 있다.&lt;/li&gt;
&lt;li&gt;각 layer에 대한 설명은 누군가 Darknet을 pytorch로 변환하면서 분석해 놓은 것이 있으니 이를 참조한다.
(&lt;a class=&#34;link&#34; href=&#34;https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;yolo-v3-structure&#34;&gt;YOLO v3 Structure&lt;/h2&gt;
&lt;p&gt;Model을 도식화하면 다음과 같다.
&lt;img src=&#34;https://muonkmu.github.io/p/mw_project-yolo-v3-tiny-%EB%B6%84%EC%84%9D/YOLOv3Tiny.drawio.svg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;참고-자료&#34;&gt;참고 자료&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://wikidocs.net/181704&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://wikidocs.net/181704&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://deep-learning-study.tistory.com/411&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://deep-learning-study.tistory.com/411&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>[AI HW Design] Chap03 Parallel Architecture (3/3)</title>
        <link>https://muonkmu.github.io/p/ai-hw-design-chap03-parallel-architecture-3/3/</link>
        <pubDate>Fri, 13 Jan 2023 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/ai-hw-design-chap03-parallel-architecture-3/3/</guid>
        <description>&lt;p&gt;본 챕터에서는 몇가지 주요한 Paralle Architecture에 대하여 소개한다.
이 페이지에서는 Microsoft Catapult Fabric Accelerator에 대해서 기술한다.&lt;/p&gt;
&lt;h2 id=&#34;microsoft-catapult-fabric-accelerator&#34;&gt;Microsoft Catapult Fabric Accelerator&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;마이크로소프트는 Brainwave Project를 CPU와 FPGA를 쓰는 형태로 변경&lt;/li&gt;
&lt;li&gt;48개의 FPGA가 2개의 Half rack (pod)에 그룹화되고 네트워크로 연결&lt;/li&gt;
&lt;li&gt;Brainwave는 train된 DNN 모델을 Catapult Fabric이라 불리는 synthesized softcore에 컴파일 후 narrow precision approach를 적용&lt;/li&gt;
&lt;li&gt;모델의 파라메터는 softcore 내 상주&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap03-parallel-architecture-3/3/01_Microsoft_brainwave_cloud_architect.png&#34;
	width=&#34;951&#34;
	height=&#34;528&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap03-parallel-architecture-3/3/01_Microsoft_brainwave_cloud_architect_hu5005c84237c5c0d108925d87f29946ce_123068_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap03-parallel-architecture-3/3/01_Microsoft_brainwave_cloud_architect_hu5005c84237c5c0d108925d87f29946ce_123068_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;180&#34;
		data-flex-basis=&#34;432px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;system-configuration&#34;&gt;System Configuration&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Catapult Fabric은 synthesized softcore이며 이는 RTL의 recompilation 없이 low level SW library를 통해 reconfigure 될 수 있다.&lt;/li&gt;
&lt;li&gt;Catapult Fabric은 Shell과 Role 두 파트로 나눌 수 있음 (상세사항은 책을 참조)
&lt;ul&gt;
&lt;li&gt;Shell : 모든 application에서 재사용 가능한 programmable logic (통신/off-chip 등의 인터페이스를 말하는 듯)&lt;/li&gt;
&lt;li&gt;Roll : Application logic (그림을 보면 Softcore를 지칭하는 듯)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;catapult-fabric-architecture&#34;&gt;Catapult Fabric Architecture&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Catapult Fabric은 Matrix-Vector Multiplier(MVM), MultiFunction Uint(MFU), Vector Arbitration Network로 구성
&lt;ul&gt;
&lt;li&gt;MVM : Matrix-Vector 및 Vector-Vector 연산 수행, PRF/VRF/MRF에 ifmap/fmap 저장&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;VAN : PRF/DRAM/IO-queue 간 데이터 전송 담당&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap03-parallel-architecture-3/3/02_The_Catapult_fabric_microarchitecture.png&#34;
	width=&#34;568&#34;
	height=&#34;543&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap03-parallel-architecture-3/3/02_The_Catapult_fabric_microarchitecture_hub0253fb48da88283ddf54bccb7267131_45778_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap03-parallel-architecture-3/3/02_The_Catapult_fabric_microarchitecture_hub0253fb48da88283ddf54bccb7267131_45778_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;104&#34;
		data-flex-basis=&#34;251px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;matrix-vector-multiplier&#34;&gt;Matrix-Vector Multiplier&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;FP16을 MS-FP8/MS-FP-9으로 변환하여 연산(mantissa가 2~3bit)&lt;/li&gt;
&lt;li&gt;input data는 VRF, filter weight는 MFR에 저장&lt;/li&gt;
&lt;li&gt;3개의 tile engine과 3개의 accumulator에서 병렬 연산을 지원(상세내용을 책을 참조)&lt;/li&gt;
&lt;li&gt;MVM의 출력은 MFU로 연결, MFU는 vector-vector operation, activation등을 수행&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;hierarchical-decode-and-dispatch-hdd&#34;&gt;Hierarchical Decode and Dispatch (HDD)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Catapult Fabric은 전통적인 scalar processor(Single Instruction Single Data)를 채택&lt;/li&gt;
&lt;li&gt;scheduler는 6개의 Decoder가 4-layer구조로 배치 (상세 내용은 책 참조)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;sparse-matrix-vector-multiplication-smvm&#34;&gt;Sparse Matrix-Vector Multiplication (SMVM)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;SMVM을 위해 Condensed Interleaved Sparse Representation (CISR) encoding 사용
&lt;ul&gt;
&lt;li&gt;Compressed Sparse Raw (CSR) 포맷이 가변 row 길이로 인해 Parallel contorl이 어려움을 극복&lt;/li&gt;
&lt;li&gt;첫 번째 0이 아닌 요소가 첫 번째 슬롯에 배치, 해당 열 인덱스는 인덱스 배열에서 동일한 순서로 배치, 행 요소가 모두 사용되면 다음 두 행 요소가 빈 슬롯에 할당, 이를 반복
(상세 내용은 책 참조,사실 이해가 잘 안감)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>[MW_project] Personal project propsal</title>
        <link>https://muonkmu.github.io/p/mw_project-personal-project-propsal/</link>
        <pubDate>Fri, 13 Jan 2023 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/mw_project-personal-project-propsal/</guid>
        <description>&lt;p&gt;현재까지 DL에 대해 공부한 것과 현업에서 배운 것을 섞어보고자 개인 프로젝트를 진행할 예정이다.
실력이 미천하여 성능, 효율성은 미뤄두고 가장 빠르고 쉽게 구현하는 것을 목표로 한다.
생각보다 오래 걸릴 듯 하다.&lt;/p&gt;
&lt;h2 id=&#34;goal&#34;&gt;GOAL&lt;/h2&gt;
&lt;p&gt;카메라의 입력을 받아 Real-time으로 Object detection을 수행하는 FPGA 기반 ECU 개발
현재 개발되어 있는 기반 설계 및 IP가 전무하기에 PPA 보다는 빠른 구현에 목표를 둔다.&lt;/p&gt;
&lt;h2 id=&#34;spec-tbd&#34;&gt;SPEC (TBD)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;target B/D : ZCU104&lt;/li&gt;
&lt;li&gt;input : Full HD camera (interface MIPI or USB 중 쉬운거)&lt;/li&gt;
&lt;li&gt;output : real time image showing a bounding box (interface HDMI)&lt;/li&gt;
&lt;li&gt;Algorithm : YOLO v3 Tiny (이를 선택한 특별한 이유는 없고 reference 구하기 쉽고 간단해서 이다)&lt;/li&gt;
&lt;li&gt;miniaml 20 fps&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;design-flow-tbd&#34;&gt;Design Flow (TBD)&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;architecture design and spec fix&lt;/li&gt;
&lt;li&gt;camera interface design&lt;/li&gt;
&lt;li&gt;output interface design&lt;/li&gt;
&lt;li&gt;YOLO Core design (HLS + verilog)&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>DL 개발환경 설정 (cuda, cudnn, conda, pytorch)</title>
        <link>https://muonkmu.github.io/p/dl-%EA%B0%9C%EB%B0%9C%ED%99%98%EA%B2%BD-%EC%84%A4%EC%A0%95-cuda-cudnn-conda-pytorch/</link>
        <pubDate>Fri, 13 Jan 2023 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/dl-%EA%B0%9C%EB%B0%9C%ED%99%98%EA%B2%BD-%EC%84%A4%EC%A0%95-cuda-cudnn-conda-pytorch/</guid>
        <description>&lt;p&gt;GPU를 이용하여 Deep learning 모델을 구성하고자 하였으나 다른 기술 블로그에서 기술한대로 수행하여도 동작이 되지 않는다.
해당 공식 문서들을 참고하여 설치하는 법을 기술한다.&lt;/p&gt;
&lt;h2 id=&#34;목적&#34;&gt;목적&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;GPU 및 pytorch 기반 개발을 위한 PC 개발 환경 구성&lt;/li&gt;
&lt;li&gt;GPU 활용을 위해 nvidia driver, cuda, cudnn 설치와 conda 환경에서 pytorch를 설치하는 방법을 다룬다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;환경&#34;&gt;환경&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;OS : ubuntu 20.04 LTS&lt;/li&gt;
&lt;li&gt;GPU : nvidia 1080ti&lt;/li&gt;
&lt;li&gt;python 3.8.10 and GCC 9.4.0&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;설치-절차&#34;&gt;설치 절차&lt;/h2&gt;
&lt;p&gt;우선 모듈의 dependency를 확인해야 한다. 현재 pytorch에서 우분투 20.04를 지원하는 플랫폼은 CUDA 11.7이므로 CUDA 11.7 버전과 이에 적합한 nvidia driver를 설치 해야한다.
필요한 nvidia driver는 사실 cuda를 설치 해보면 dependency 체크를 하면서 필요한 버전을 알려준다.(더 좋은 방법이 있을지도)&lt;/p&gt;
&lt;h3 id=&#34;nvidia-driver-설치&#34;&gt;Nvidia Driver 설치&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;nvidia driver 설치 여부 및 현재 설치된 버전을 확인한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;nvidia-smi
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;필요 시 기존의 nvidia driver를 삭제한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt-get remove --purge &lt;span class=&#34;s1&#34;&gt;&amp;#39;nvidia-.*&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt-get autoremove
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt-get autoclean
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;설치가능한 드라이버를 확인한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ubuntu-drivers devices
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;만약 필요한 드라이버 목록에서 없다면 저장소를 추가한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo add-apt-repository ppa:graphics-drivers/ppa
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt update
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;원하는 드라이버를 설치 후 재부팅 한다. 현재 저자의 환경에서는 5.25가 필요하므로 이 버전을 예로 설명한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt install nvidia-driver-525
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo reboot
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;cuda-설치&#34;&gt;cuda 설치&lt;/h3&gt;
&lt;p&gt;cuda 홈페이지에서 현재 내 설정에 맞는 runfile을 다운 가능하나 저자는 이상하게 설치가 안되었다.
하기 페이지를 활용하여 네트워크 Repo에서 설치하자
(&lt;a class=&#34;link&#34; href=&#34;https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#prepare-ubuntu&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#prepare-ubuntu&lt;/a&gt;)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Remove outdated signing key&lt;/li&gt;
&lt;li&gt;Install the new cuda-keyring package&lt;/li&gt;
&lt;li&gt;Install CUDA SDK&lt;/li&gt;
&lt;li&gt;reboot&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt-key del 7fa2af80
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.0-1_all.deb
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo dpkg -i cuda-keyring_1.0-1_all.deb
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt update
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt-get install cuda-11-7
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo reboot
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;환경변수를 등록한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;PATH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;/usr/local/cuda-11.7/bin&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;PATH&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:+:&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;PATH&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;LD_LIBRARY_PATH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;/usr/local/cuda-11.7/lib64&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;LD_LIBRARY_PATH&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:+:&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;LD_LIBRARY_PATH&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;cudnn-설치&#34;&gt;cudnn 설치&lt;/h3&gt;
&lt;p&gt;cudnn 역시 package 파일로 설치가 잘 안되서 tar 파일로 설치하였다.
(&lt;a class=&#34;link&#34; href=&#34;https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html&lt;/a&gt;)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;필요한 cudnn 라이브러리 tar를 cudnn 홈페이지에서 다운받는다.&lt;/li&gt;
&lt;li&gt;파일의 압축을 풀고 cuda 라이브러리에 파일을 복사한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;tar -xvf cudnn-linux-x86_64-8.x.x.x_cudaX.Y-archive.tar.xz
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo cp cudnn-*-archive/include/cudnn*.h /usr/local/cuda/include
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo cp -P cudnn-*-archive/lib/libcudnn* /usr/local/cuda/lib64
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo chmod a+r /usr/local/cuda/include/cudnn*.h /usr/local/cuda/lib64/libcudnn*
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;conda-설치&#34;&gt;conda 설치&lt;/h3&gt;
&lt;p&gt;모듈들의 dependency 및 버전 관리를 위해 가상환경인 conda를 사용하기로 하였다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;자신의 파이썬 환경에 맡는 miniconda 설치 파일을 받고 이를 실행한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Miniconda3-latest-Linux-x86_64.sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;자신이 사용할 가상환경을 만들고 이를 실행한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda create -n &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;my_env&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda activate &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;my_env&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;터미널 실행 시 자동으로 conda 환경이 실행되는 것을 막을려면 다음을 수행한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda config --set auto_activate_base &lt;span class=&#34;nb&#34;&gt;false&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;pytorch-설치&#34;&gt;pytorch 설치&lt;/h3&gt;
&lt;p&gt;conda 환경에서 pytorch 홈페이지를 참고하여 pytorch를 설치한다. 자신이 원하는 구성을 고르면 Run command를 알려준다.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda install pytorch torchvision torchaudio pytorch-cuda&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;11.7 -c pytorch -c nvidia
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;설치-확인&#34;&gt;설치 확인&lt;/h2&gt;
&lt;p&gt;conda 환경에서 python을 터미널을 실행한 후 pytorch cuda 설정 사용 가능 여부가 &lt;code&gt;True&lt;/code&gt;로 출력되면 정상&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cuda&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;is_available&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        <item>
        <title>[CNN] week 03 Object detection</title>
        <link>https://muonkmu.github.io/p/cnn-week-03-object-detection/</link>
        <pubDate>Tue, 10 Jan 2023 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/cnn-week-03-object-detection/</guid>
        <description>&lt;p&gt;본 강좌에서는 Object Detection의 개념과 이를 위한 YOLO알고리즘의 기초에 대하여 정리한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.coursera.org/learn/convolutional-neural-networks&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.coursera.org/learn/convolutional-neural-networks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;하기 블로그에 더 잘 정리되어 있다..(누군지 존경스럽다.)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://junstar92.tistory.com/140&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://junstar92.tistory.com/140&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;object-localization&#34;&gt;Object Localization&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Classification with localization : object class 뿐 아니라, 알고리즘이 object를 대상으로 bounding box를 표시하는 것을 의미&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이를 위해 이미지를 CNN에 입력 출력으로 class 뿐만 아니라 이미지에 object가 존재할 확률($p_c$), Bounding box의 위치 및 크기를 같이 출력(Bx, By, Bh, Bw)
&lt;img src=&#34;https://muonkmu.github.io/p/cnn-week-03-object-detection/01_Classification_with_localization.png&#34;
	width=&#34;1878&#34;
	height=&#34;1039&#34;
	srcset=&#34;https://muonkmu.github.io/p/cnn-week-03-object-detection/01_Classification_with_localization_hu1b4c480e106770584b9477109ed0b1e5_771244_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/cnn-week-03-object-detection/01_Classification_with_localization_hu1b4c480e106770584b9477109ed0b1e5_771244_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;180&#34;
		data-flex-basis=&#34;433px&#34;
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Loss function은 MSE(mean squared error)를 사용한다면 Y 각 요소의 에러의 합과 같다. Pc가 0일 경우 Pc의 에러만 사용한다.
$$
L(\hat{y},y) =
\begin{cases}
(\hat{y}_1-y_1)^2+(\hat{y}_2-y_2)^2+\cdots+(\hat{y}_8-y_8)^2 &amp;amp; \text{if } y_1=1 \\
(\hat{y}_1-y_1)^2 &amp;amp; \text{if } y_1=0
\end{cases}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MSE를 예시로 설명했지만, $c_1$, $c_2$, $c_3$에는 log-likelihood loss와 softmax를 사용하고, bounding box 정보에는 MSE를, 그리고 $p_c$ 에는 Logistic Regression Loss를 사용할 수도 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;landmark-detection&#34;&gt;Landmark Detection&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Bounding box가 아닌 일반적인 Face recognition이나 pose detection의 같은 일반적인 경우 이미지의 주요 포인트(landmark)를 X와 Y의 좌표로 나타낼 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;object-detection&#34;&gt;Object Detection&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Sliding Windows Detection 알고리즘을 사용해서 Object Detection을 위해 ConvNet을 사용하는 방법 알아본다. (CS231n 강의에서는 Sliding window는 하지말라던데 아마 이해를 위해 넣어놓은 것 같다.)&lt;/li&gt;
&lt;li&gt;방법은 하기와 같다.
&lt;ol&gt;
&lt;li&gt;object의 클래스를 구분할 수 있는 모델 생성&lt;/li&gt;
&lt;li&gt;전체 이미지 중 특정 size의 window를 골라 탐색&lt;/li&gt;
&lt;li&gt;window 살짝 옮겨서 반복&lt;/li&gt;
&lt;li&gt;더 큰 박스를 이용하여 반복&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/cnn-week-03-object-detection/02_Sliding_window_detection.png&#34;
	width=&#34;1870&#34;
	height=&#34;1058&#34;
	srcset=&#34;https://muonkmu.github.io/p/cnn-week-03-object-detection/02_Sliding_window_detection_hudd543c51e828e81c148386df06f5a486_1113646_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/cnn-week-03-object-detection/02_Sliding_window_detection_hudd543c51e828e81c148386df06f5a486_1113646_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;176&#34;
		data-flex-basis=&#34;424px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;그러나 이 방법은 computing cost가 높다. 다음 절에서 이를 줄일 수 있는 방법을 알아본다&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;convolutional-implementation-of-sliding-windows&#34;&gt;Convolutional Implementation of Sliding Windows&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Sliding window 방법은 매우 느린데 이를 해결하기 위해  FC(Full connected) layer를 Convolutional Layer로 튜닝하는 것을 알아보자. 절차는 하기와 같다
&lt;ol&gt;
&lt;li&gt;FC layer를 이와 같은 output을 낼 수 있는 Filter로 변환&lt;/li&gt;
&lt;li&gt;sliding window 시 각각 수행이 아닌 convolution처럼 한번에 연산. 이렇게 하면 중복되는 연산은 공유가 가능하다.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/cnn-week-03-object-detection/03_Convolution_implementation.png&#34;
	width=&#34;1882&#34;
	height=&#34;1056&#34;
	srcset=&#34;https://muonkmu.github.io/p/cnn-week-03-object-detection/03_Convolution_implementation_hue985ef7ef91917e1e9326f3408e09893_1926090_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/cnn-week-03-object-detection/03_Convolution_implementation_hue985ef7ef91917e1e9326f3408e09893_1926090_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;178&#34;
		data-flex-basis=&#34;427px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;그러나 이 방법은 bounding box의 위치가 정확하지 않다는 단점이 있는데 이를 아래 방법으르 해결한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;bounding-box-predictions&#34;&gt;Bounding Box Predictions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Sliding window 방법은 object가 그 위치에 있지 않거나 일부분만 걸칠 수 있는데 이를 YOLO 알고리즘으로 극복 가능하다.
&lt;ol&gt;
&lt;li&gt;전체 이미지에 3x3 grid 를 설정(보통은 19x19 사용)&lt;/li&gt;
&lt;li&gt;위에서 배운 object localization을 각각의 grid에 적용, 즉 이해한바로는 test set에서 각각의 그리드에 localization방법으로 labeling하고 학습&lt;/li&gt;
&lt;li&gt;각 grid에 object가 존재한다면 object의 중간점을 위해서 object를 할당한다. 이때 object의 크기는 1이 넘어갈 수 있다.(gird를 넘어가거나 클 수 있으므로)&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/cnn-week-03-object-detection/04_YOLO.png&#34;
	width=&#34;1882&#34;
	height=&#34;1048&#34;
	srcset=&#34;https://muonkmu.github.io/p/cnn-week-03-object-detection/04_YOLO_hua8cf6c3b9e393dfa3b60c548de6a60b1_1529394_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/cnn-week-03-object-detection/04_YOLO_hua8cf6c3b9e393dfa3b60c548de6a60b1_1529394_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;179&#34;
		data-flex-basis=&#34;430px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;Bounding box를 설정하는 방법은 여러가지가 있지만(ex. PCA 이용), YOLO논문을 살펴보면 잘 동작할 수 있도록 파라미터화 된 것들이 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;intersection-over-union&#34;&gt;Intersection Over Union&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Intersection over union(IoU)은 Object Detection이 잘 동작하는지 판단하기 위한 함수&lt;/li&gt;
&lt;li&gt;labeling 된 bounding box와 예측한 bounding box의 전체 넓이와 겹치는 부분 넓이의 비율을 계산&lt;/li&gt;
&lt;li&gt;보통 0.5 이상이면 예측한 bounding box의 결과가 옳다고 판단&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;non-max-suppression&#34;&gt;Non-max Suppression&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;현재까지 알아본 Object detection의 문제점은 한 Object를 여러번 탐지할 수 있다는 것이다. 즉 한 object가 한 그리드 이상에의 면적을 차지할 경우 이 object의 중심점이 여러 Cell에서 탐지 될 수 있다.&lt;/li&gt;
&lt;li&gt;이 경우에 Non-max suppression을 사용하면 알고리즘이 하나의 object를 하나의 cell에서 한번만 탐지할 수 있다.
&lt;ol&gt;
&lt;li&gt;만약 분류 class 가 1개여서 $p_c$가 class의 확률이라 가정한다. (실제로는 클래스는 여러개)&lt;/li&gt;
&lt;li&gt;$p_c$를 조사하여 가장 큰 것만 취함&lt;/li&gt;
&lt;li&gt;나머지 box와 $p_c$값이 가장 큰 박스와 IoU 조사&lt;/li&gt;
&lt;li&gt;IoU가 높은 박스는 제거&lt;/li&gt;
&lt;li&gt;만약 class가 여러개라면 class 당 non-max suppression을 수행한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/cnn-week-03-object-detection/05_Non_max_suppression.png&#34;
	width=&#34;1587&#34;
	height=&#34;885&#34;
	srcset=&#34;https://muonkmu.github.io/p/cnn-week-03-object-detection/05_Non_max_suppression_huedc5f8134a13b617c9f19aedddcb8781_982730_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/cnn-week-03-object-detection/05_Non_max_suppression_huedc5f8134a13b617c9f19aedddcb8781_982730_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;179&#34;
		data-flex-basis=&#34;430px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;anchor-boxes&#34;&gt;Anchor Boxes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;현재까지 소개한 알고리즘의 문제점 중 하나는 각 grid cell이 오직 하나의 object만 감지할 수 있다는 것이며 이를 anchor box라는 아이디어를 가지고 해결할 수 있다.
&lt;ol&gt;
&lt;li&gt;anchor 박스의 모양을 미리 정의&lt;/li&gt;
&lt;li&gt;각각의 anchor box는 각 output을 가지게 한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;anchor box의 선택은 manual로 선택을 할 수도 있고, K-mean알고리즘을 통해서 얻고자하는 유형의 object모양 끼리 그룹화 할 수도 있다.&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://muonkmu.github.io/p/cnn-week-03-object-detection/06_Anchor_box.png&#34;
	width=&#34;1589&#34;
	height=&#34;888&#34;
	srcset=&#34;https://muonkmu.github.io/p/cnn-week-03-object-detection/06_Anchor_box_hua1f3e86034f4b492ff393673bee5b63f_813705_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/cnn-week-03-object-detection/06_Anchor_box_hua1f3e86034f4b492ff393673bee5b63f_813705_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;178&#34;
		data-flex-basis=&#34;429px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;yolo-algorithm&#34;&gt;YOLO Algorithm&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;위의 내용을 모두 종합하여 YOLO object detection algorithm을 정리해보자
&lt;ol&gt;
&lt;li&gt;이미지의 anchor box와 grid 수를 정하고 이와 같이 labeling된 데이터 셋으로 모델을 학습&lt;/li&gt;
&lt;li&gt;상기 모델로 추론을 수행하게 되면 각 grid cell은 anchor box 수만큼의 bounding box를 가질 수 있다. 여기서 낮은 확률을 가지는 예측결과는 제거하고 각 class에 non-max suppression을 적용하여 최종 예측 결과를 얻는다.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;YOLO 알고리즘은 가장 효과적인 Object Detection 알고리즘 중 하나&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>[AI HW Design] Chap03 Parallel Architecture (2/3)</title>
        <link>https://muonkmu.github.io/p/ai-hw-design-chap03-parallel-architecture-2/3/</link>
        <pubDate>Fri, 30 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/ai-hw-design-chap03-parallel-architecture-2/3/</guid>
        <description>&lt;p&gt;본 챕터에서는 몇가지 주요한 Paralle Architecture에 대하여 소개한다.
이 페이지에서는 NVDLA와 Google TPU에 대해서 기술한다.&lt;/p&gt;
&lt;h2 id=&#34;nvidia-deep-learning-accelerator-nvdla&#34;&gt;NVIDIA Deep Learning Accelerator (NVDLA)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;NVDLA는 FPGA로 구성 가능한 추론을 위한 오픈소스 아키텍쳐 (&lt;a class=&#34;link&#34; href=&#34;http://nvdla.org&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://nvdla.org&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Primitive functional blocks으로 CNN을 지원 (convolution, activation, pooling, normalization)&lt;/li&gt;
&lt;li&gt;각 블럭은 next layer의 active와 configuration을 위한 double buffer를 가짐&lt;/li&gt;
&lt;li&gt;next layer의 operation은 active operation이 완료되어야 시작&lt;/li&gt;
&lt;li&gt;independent mode와 pipeline을 사용하는 fused mode가 있음
&lt;img src=&#34;https://muonkmu.github.io/p/ai-hw-design-chap03-parallel-architecture-2/3/NVDLA_core_architecture.png&#34;
	width=&#34;1142&#34;
	height=&#34;950&#34;
	srcset=&#34;https://muonkmu.github.io/p/ai-hw-design-chap03-parallel-architecture-2/3/NVDLA_core_architecture_hu2cca1af52d961361ac30bee8eb97a9b7_113988_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/ai-hw-design-chap03-parallel-architecture-2/3/NVDLA_core_architecture_hu2cca1af52d961361ac30bee8eb97a9b7_113988_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;NVDLA core architecture&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;120&#34;
		data-flex-basis=&#34;288px&#34;
	
&gt;
&lt;em&gt;Figure. NVDLA core architecture&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;convolution-operation&#34;&gt;Convolution Operation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Direct convolution, Image input convolution, winograd convolution, Batch convolution 지원 (상세내역은 책 참조)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;single-data-point-operationsdp&#34;&gt;Single Data Point Operation(SDP)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;SDP는 linear functions와 Look-up Table nonlinear functions을 통해 activation과 normalizatin을 지원 (상세내역은 책 참조)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;planar-data-operationpdp&#34;&gt;Planar Data Operation(PDP)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;PDP는 maximum/minimum/average pooling을 지원&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;multiplane-operation&#34;&gt;Multiplane Operation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Cross Channel Data Processor(CPD)은 Local Response Normalization(LRN)을 수행&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;data-memory-and-reshape-operations&#34;&gt;Data Memory and Reshape Operations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;bridge DMA는 외부 메모리와 메모리 인터페이스간 데이터 전송을 담당&lt;/li&gt;
&lt;li&gt;data reshape engine은 data trasnformations, splitting, slicing, merging, contraction, reshape transpose 를 담당&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;system-configuration&#34;&gt;System Configuration&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;NVDLA는 small/large system model로 구현할 수 있음
&lt;ul&gt;
&lt;li&gt;small system model : IoT 기기와 같이 작은 모델을 위한 모델, 복잡도와 storage를 낮추고 single task를 수행&lt;/li&gt;
&lt;li&gt;large system model : mutiple task를 위한 coprocessor와 메모리 인터페이스 추가&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;external-interface&#34;&gt;External Interface&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;NVDLA는 외부와 통신을 위한 Configuration Space Bus(CSB), Data backbone(DBB), SRAM interface, Interrupt interface를 가짐 (상세내용은 책 참조)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;software-design&#34;&gt;Software Design&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;NVDLA SW는 Trained model을 parser/compiler/optimizer를 통해 loadable로 변환&lt;/li&gt;
&lt;li&gt;User Mode Driver(UMD)에 의해 Loadalbe이 로딩 되고 Job이 Kernel Mode Driver(KMD)로 제출됨, KMD는 스케줄링 수행&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;google-tensor-processing-unittpu&#34;&gt;Google Tensor Processing Unit(TPU)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;구글은 speech recognition 수요 해결을 위해 TPU v1(stand alone)과 v2/v3(cloud)를 개발&lt;/li&gt;
&lt;li&gt;TPU v1은 하기 스펙으로 MLP 0/1, CNN 0/1, RNN 0/1 6가지 neural network application을 수행 가능
&lt;ul&gt;
&lt;li&gt;256 × 256 eight bits MAC unit&lt;/li&gt;
&lt;li&gt;4 Mb on-chip Accumulator Memory (AM)&lt;/li&gt;
&lt;li&gt;24 Mb Unified Buffer (UB) – activation memory&lt;/li&gt;
&lt;li&gt;8 Gb off-chip weight DRAM memory&lt;/li&gt;
&lt;li&gt;Two 2133 MHz DDR3 channels&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;TPU는 6가지 neural network application을 수행할 수 있음
&lt;ul&gt;
&lt;li&gt;Multi-layer perceptron(MLP) 0/1, Convolution Neural Network(CNN) 0/1, Recurrent Neural Network(RNN) 0/1&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;system-architecture&#34;&gt;System Architecture&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;TPU v1은 매트릭스 연산을 Matrix Multiply Unit(MMU)에서 수행&lt;/li&gt;
&lt;li&gt;MMU는 256 × 256 eight bits MAC unit이며 16bit 연산을 수행할 경우 성능은 8bit 대비 절반(Sparse matrix 연산을 지원하지 않음)&lt;/li&gt;
&lt;li&gt;Weight FIFO는 matrix weight를 8Gb DRAM에서 읽어오며 activation, pooling, normalization 후 중간 연산 결과를 24Mb Unified Buffer에 저장&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://storage.googleapis.com/gweb-cloudblog-publish/images/tpu-15dly1.max-500x500.PNG&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;TPU System Architecture&#34;
	
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;multipy-accumulatemac-systolic-array&#34;&gt;Multipy-Accumulate(MAC) Systolic Array&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Systolic array는 TPU의 핵심이자 High throughput / low latency를 가진 SIMD pipeline.&lt;/li&gt;
&lt;li&gt;책에 별 설명이 없으므로 이에 대한 내용은 더 찾아보는 것이 좋다(다른 많은 곳에 잘 나와 있음)&lt;/li&gt;
&lt;li&gt;단점은 전력 소모가 많다는 것(데이터 센터 등에 적합)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;new-brain-floating-point-format&#34;&gt;New Brain Floating-point Format&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;TPU v1은 input data를 FP32에서 INT8로 quantization하여 연산하며 이에 따라 안정성/정확도 문제 발생&lt;/li&gt;
&lt;li&gt;이를 위해 IEEE FP16 대신 Brain Floating Point format (BFP16) 사용
&lt;ul&gt;
&lt;li&gt;BFP16 : Mantissa를 7bit으로 줄이고 exponent를 FP32와 같은 8bit으로 늘림&lt;/li&gt;
&lt;li&gt;Sign 1bit, Exponent 8bit, Mantissa 7bit&lt;/li&gt;
&lt;li&gt;multiplier area와 power를 줄이고 Scaling loss 없이 FP32와 동일한 정확도를 얻음&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;performance-comparision&#34;&gt;Performance Comparision&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;roof-line model의 관점에서 볼 때 TPU가 가장 높은 peak performance를 달성했다.&lt;/li&gt;
&lt;li&gt;roof-line model은 Y축이 성능을 나타내며(평평한 부분이 최고 성능), X축이 byte 당 operation intensity&lt;/li&gt;
&lt;li&gt;부가 설명을 하자면 한번에 얼마나 많은 연산을 수행하게 할 때 성능이 어디까지 올라가는지 지표, loof-line은 메모리 Bandwith 때문에 걸림&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cloud-tpu-configuration&#34;&gt;Cloud TPU configuration&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;TPU v2/v3는 v1에서 DDR을 HBM으로 바꾸고 v1을 Pod로 묶음&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cloud-software-architecture&#34;&gt;Cloud Software Architecture&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;구글은 cloud computation을 위해 새로운 SW 아키텍쳐를 개발&lt;/li&gt;
&lt;li&gt;Model을 TensorFlow를 통해 computational graph로 해석&lt;/li&gt;
&lt;li&gt;상세 내용은 책을 참조&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>[KiCad] Footprint and PCB</title>
        <link>https://muonkmu.github.io/p/kicad-footprint-and-pcb/</link>
        <pubDate>Wed, 28 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/kicad-footprint-and-pcb/</guid>
        <description>&lt;p&gt;IDEC에서 수강한 KiCad 강좌 요약 이다. 디자인 플로우 중 Footprint와 PCB에 대해 정리한다.&lt;/p&gt;
&lt;h2 id=&#34;footprint&#34;&gt;Footprint&lt;/h2&gt;
&lt;h3 id=&#34;footprint-design-flow&#34;&gt;Footprint design flow&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;footprint 편집기를 연다&lt;/li&gt;
&lt;li&gt;실부품 측정 또는 데이터 시트를 참조하여 부품 치수 확인&lt;/li&gt;
&lt;li&gt;필요 시 풋프린트 라이브러리 생성 (파일-&amp;gt;새라이브러리)&lt;/li&gt;
&lt;li&gt;라이브러리 선택 후 새 풋프린트 생성 하거나 유사한 부품 불러 온 후 다른 이름으로 저장&lt;/li&gt;
&lt;li&gt;십자선 커서 이용하여 원점에서 스페이스바를 눌러 원점 위치 선정&lt;/li&gt;
&lt;li&gt;실크 레이어에 부품 외형선 그리기&lt;/li&gt;
&lt;li&gt;패드와 홀 위치 시킨 후 사이즈 속성 편집
&lt;ul&gt;
&lt;li&gt;패드 위치에 맞게 번호 편집, 핀번호는 심볼과 일치하도록 할 것&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;저장
&lt;img src=&#34;https://muonkmu.github.io/p/kicad-footprint-and-pcb/footprint_edit_page.png&#34;
	width=&#34;2696&#34;
	height=&#34;1150&#34;
	srcset=&#34;https://muonkmu.github.io/p/kicad-footprint-and-pcb/footprint_edit_page_hu297452f323d034ce41b824c224ef8559_554183_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/kicad-footprint-and-pcb/footprint_edit_page_hu297452f323d034ce41b824c224ef8559_554183_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;234&#34;
		data-flex-basis=&#34;562px&#34;
	
&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;smd-component-footprint&#34;&gt;SMD Component Footprint&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;SMD 부품의 경우 패드의 속성을 SMD로 변경&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;뒷면-실장-component&#34;&gt;뒷면 실장 component&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;뒷면에 실장할 경우 레이어를 관련 레이어를 B.* 레이어로 변경해야 한다.
&lt;ul&gt;
&lt;li&gt;F.Cu, F.Silkscreen, F.Courtyard, F.Fab 내용을 B.* 레이어로 이동&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;pcb-design&#34;&gt;PCB design&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;프로젝트 매니저에서 PCB 편집기 열기&lt;/li&gt;
&lt;li&gt;회로도 PCB 전환(F8)을 이용하여 회로도에서 컴포넌트를 로딩&lt;/li&gt;
&lt;li&gt;Edge.Cuts layer에서 PCB 외형선을 그리기&lt;/li&gt;
&lt;li&gt;외형선 내부에 컴포넌트 배치 및 컴포넌트 레퍼런스/value 위치 조정&lt;/li&gt;
&lt;li&gt;필요한 텍스트를 Silkscreen에 부가&lt;/li&gt;
&lt;li&gt;트랙 설정 및 배선 (일반적으로 신호선 12mil, 전원선 30mil)&lt;/li&gt;
&lt;li&gt;동박면 씌우기 (GND와 연결)&lt;/li&gt;
&lt;li&gt;DRC 검사&lt;/li&gt;
&lt;li&gt;Plot을 통해 거버/드릴링/포지션 파일 생성 및 검사
&lt;img src=&#34;https://muonkmu.github.io/p/kicad-footprint-and-pcb/pcb_edit_page.png&#34;
	width=&#34;2172&#34;
	height=&#34;1292&#34;
	srcset=&#34;https://muonkmu.github.io/p/kicad-footprint-and-pcb/pcb_edit_page_hu69919b00588fcb87585efb993ecafd95_1463424_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/kicad-footprint-and-pcb/pcb_edit_page_hu69919b00588fcb87585efb993ecafd95_1463424_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;168&#34;
		data-flex-basis=&#34;403px&#34;
	
&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>[KiCad] Symbol and Schemetic</title>
        <link>https://muonkmu.github.io/p/kicad-symbol-and-schemetic/</link>
        <pubDate>Wed, 28 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/kicad-symbol-and-schemetic/</guid>
        <description>&lt;p&gt;IDEC에서 수강한 KiCad 강좌 요약 이다. 디자인 플로우 중 Symbol and Schemetic에 대해 정리한다.&lt;/p&gt;
&lt;h2 id=&#34;kicad-개요&#34;&gt;KiCad 개요&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;회로도 및 PCB가 함께 설계되는 오픈소스 통합 설계도구&lt;/li&gt;
&lt;li&gt;거버 /드릴/ 부품위치 파일 생성 및 PCB 계산기, 거버 뷰어, 3D 뷰어, SPICE 시뮬레이터 포함&lt;/li&gt;
&lt;li&gt;프로젝트 기반 관리로 한번에 하나의 프로젝트만 열 수 있음&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;파일구성&#34;&gt;파일구성&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;*.kicad_pro : 회로도와 pcb간 공유되는 설정이 포함된 프로젝트 파일&lt;/li&gt;
&lt;li&gt;*.kicad_sch : 모든 정보와 구성 요소 자체를 포함시키는 회로도 파일&lt;/li&gt;
&lt;li&gt;*.kicad_sym : 회로도 심볼 라이브러리 파일로 심볼 요소 설명을 포함&lt;/li&gt;
&lt;li&gt;*.kicad_pcb : pcb 보드 파일&lt;/li&gt;
&lt;li&gt;*.pretty    : 풋프린트 라이브러리 폴더&lt;/li&gt;
&lt;li&gt;*.kicad_dru : pcb 사용자 설계 규칙 파일&lt;/li&gt;
&lt;li&gt;*.net.      : 회로도에 의해 생성되는 넷리스트 파일&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;kicad-pcb-design-workflow&#34;&gt;KiCad PCB design workflow&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;프로젝트 생성&lt;/li&gt;
&lt;li&gt;회로도 그리기&lt;/li&gt;
&lt;li&gt;회로도 심볼을 심볼 라이브러리에서 찾아 지정된 선 연결, 심볼이 없을 경우 새로 심볼을 새로 만듬&lt;/li&gt;
&lt;li&gt;각 구성 요소에 대해 풋프린트를 배정하고 풋프린트가 없는 경우 풋프린트를 생성하여 반영&lt;/li&gt;
&lt;li&gt;회로도 완성 시 전기 규칙 점검(ERC 수행)&lt;/li&gt;
&lt;li&gt;pcb 편집기로 전송하여 레이아웃 시작(넷리스트 생성 및 부품 간 선 연결 일치 시킴)&lt;/li&gt;
&lt;li&gt;기판 크기(Edge.Cuts) 그리기 및 풋프린트 위치를 선정 배치&lt;/li&gt;
&lt;li&gt;배치 후 요소 사이 트랙 연결
&lt;ul&gt;
&lt;li&gt;트랙은 규정에 따라 전류 용량, 임피던스, 고전압 누화 등을 고려 선폭/선간 설정 (pcb계산기 참조)&lt;/li&gt;
&lt;li&gt;트랙은 신호선의 경우 보통 12mil, 6mil 이하로 하면 pcb 제작 단가 상승&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;레이아웃이 완료되고 설계 규칙 검사(DRC) 및 수정&lt;/li&gt;
&lt;li&gt;거버 파일 제작 출력 및 PCB 제작 의회&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;프로젝트-관리-창&#34;&gt;프로젝트 관리 창&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Tip 1 : 프로젝트 생성 시 템플릿을 지정하여 생성 가능 (큰 회사에서 기초 설정 등을 지정한 형식)&lt;/li&gt;
&lt;li&gt;Tip 2 : 환경 설정에서 텍스트 편집기를 등록하면 텍스트 편집기 사용이 가능하다.
&lt;img src=&#34;https://muonkmu.github.io/p/kicad-symbol-and-schemetic/project_manage_page.png&#34;
	width=&#34;2908&#34;
	height=&#34;1356&#34;
	srcset=&#34;https://muonkmu.github.io/p/kicad-symbol-and-schemetic/project_manage_page_hufdf11732201a6d094dfe0f0284e9b39a_662332_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/kicad-symbol-and-schemetic/project_manage_page_hufdf11732201a6d094dfe0f0284e9b39a_662332_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;214&#34;
		data-flex-basis=&#34;514px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;symbol-생성&#34;&gt;Symbol 생성&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;필요 시 심볼 라이브러리 생성 (파일-&amp;gt;새라이브러리)&lt;/li&gt;
&lt;li&gt;라이브러리 선택 후 새 심볼 생성&lt;/li&gt;
&lt;li&gt;생성된 심볼에서 레퍼런스, 심볼값을 원하는 위치로 이동&lt;/li&gt;
&lt;li&gt;외형선 그리기, 핀 부가, 핀 더블 클릭 하여 속성(이름, 번호, 유형 등) 설정&lt;/li&gt;
&lt;li&gt;필요 시 원점 설정 (단축키 space)(심볼 로딩 위치 및 로테이션 시 회전 점)&lt;/li&gt;
&lt;li&gt;저장
Tip) 편집 시 원하는 위치에 지정할 수 없을 때 그리드 속성을 편집하여 그리드 간격을 조절하자
&lt;img src=&#34;https://muonkmu.github.io/p/kicad-symbol-and-schemetic/symbol_edit_page.png&#34;
	width=&#34;2218&#34;
	height=&#34;1246&#34;
	srcset=&#34;https://muonkmu.github.io/p/kicad-symbol-and-schemetic/symbol_edit_page_hu818501ea25b8fb246a26a0c3f0a5736b_772973_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/kicad-symbol-and-schemetic/symbol_edit_page_hu818501ea25b8fb246a26a0c3f0a5736b_772973_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;178&#34;
		data-flex-basis=&#34;427px&#34;
	
&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;회로도-그리기&#34;&gt;회로도 그리기&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;프로젝트 매니저에서 {프로젝트 이름}.kicad_sch 파일을 연다&lt;/li&gt;
&lt;li&gt;심볼을 배치한다 (전원의 경우 pspice 라이브러리는 시뮬레이션 용이니 Power라이브러리 사용)&lt;/li&gt;
&lt;li&gt;선을 연결하고 텍스트 위치 조정한다.&lt;/li&gt;
&lt;li&gt;레퍼런스 (부품번호, ex. R100) 지정자 채우기 로 레퍼런스 설정&lt;/li&gt;
&lt;li&gt;PCB 풋 프린트 배정&lt;/li&gt;
&lt;li&gt;ERC 수행/수정 및 BOM 출력
&lt;img src=&#34;https://muonkmu.github.io/p/kicad-symbol-and-schemetic/schemetic_edit_page.png&#34;
	width=&#34;2710&#34;
	height=&#34;1402&#34;
	srcset=&#34;https://muonkmu.github.io/p/kicad-symbol-and-schemetic/schemetic_edit_page_hua6e34afde46f1c26994059153698c020_602015_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/kicad-symbol-and-schemetic/schemetic_edit_page_hua6e34afde46f1c26994059153698c020_602015_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;193&#34;
		data-flex-basis=&#34;463px&#34;
	
&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>[CS231n] Chap 14 Reinforcement Learning</title>
        <link>https://muonkmu.github.io/p/cs231n-chap-14-reinforcement-learning/</link>
        <pubDate>Fri, 23 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/cs231n-chap-14-reinforcement-learning/</guid>
        <description>&lt;p&gt;본 chapter에서는 Reinforcement Learning에 대해서 알아보자&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Video : &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=lvoHnicueoE&amp;amp;list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&amp;amp;index=15&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.youtube.com/watch?v=lvoHnicueoE&amp;list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&amp;index=15&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slide : &lt;a class=&#34;link&#34; href=&#34;http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture14.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture14.pdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(TODO: 귀차니즘의 압박으로 정리를 안했다.. 근데 강의가 무척 어려워서 잘 이해가 안된다.)&lt;/p&gt;
</description>
        </item>
        <item>
        <title>[Petalinux] Petalinux Advance</title>
        <link>https://muonkmu.github.io/p/petalinux-petalinux-advance/</link>
        <pubDate>Thu, 22 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/petalinux-petalinux-advance/</guid>
        <description>&lt;h2 id=&#34;petalinux-booting-and-packaging&#34;&gt;Petalinux Booting and Packaging&lt;/h2&gt;
&lt;h3 id=&#34;petalinux-packaging&#34;&gt;petalinux Packaging&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;petalinux-package&lt;/code&gt; 명령을 이용하여 하기 내역을 수행 할 수 있다.
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;.BIN&lt;/code&gt; 또는 &lt;code&gt;.MCS&lt;/code&gt;파일을 생성 (&amp;ndash;boot 옵션)&lt;/li&gt;
&lt;li&gt;BSP (&lt;code&gt;.BSP&lt;/code&gt; 파일) 또는 Package image 생성 (&amp;ndash;bsp, &amp;ndash;image 옵션)&lt;/li&gt;
&lt;li&gt;prebuilt 디렉토리 생성 (&amp;ndash;prebuilt 옵션)&lt;/li&gt;
&lt;li&gt;Vitis 를 위한 sysroot 설치 (&amp;ndash;sysroot 옵션)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;petalinux-booting&#34;&gt;petalinux booting&lt;/h3&gt;
&lt;p&gt;QEMU, SD card, Jtag, TFTP, QSPI에 의한 Booting을 지원한다. (jtag Boot는 속도가 느려 잘 사용안함)&lt;/p&gt;
&lt;h2 id=&#34;petalinux-debugging&#34;&gt;Petalinux Debugging&lt;/h2&gt;
&lt;p&gt;상세 내용은 교제의 &lt;code&gt;Petalinux Application Debugging&lt;/code&gt; 및 &lt;code&gt;LAB5&lt;/code&gt; 참조&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Petalinux는 Application Debugging 시 System Debugger(Vitis) 와 GNU Debugger를 지원한다.&lt;/li&gt;
&lt;li&gt;Vitis는 Target Communication Framework(TCF)와 Xilinx System DBugger(XSDB)를 이용한 Debugging 환경을 제공&lt;/li&gt;
&lt;li&gt;일반적인 Linux GNU Debugger 지원&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;system-debugger-방법&#34;&gt;System Debugger 방법&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://xilinx.github.io/Embedded-Design-Tutorials/docs/2022.2/build/html/docs/Introduction/ZynqMPSoC-EDT/ZynqMPSoC-EDT.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://xilinx.github.io/Embedded-Design-Tutorials/docs/2022.2/build/html/docs/Introduction/ZynqMPSoC-EDT/ZynqMPSoC-EDT.html&lt;/a&gt; 참조&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;petalinux-config -c rootfs&lt;/code&gt;를 이용하여 Root File system에 하기 내역을 포함 시킨다.
&lt;ul&gt;
&lt;li&gt;tcf-agent (default enable)&lt;/li&gt;
&lt;li&gt;openssh-sftp-server&lt;/li&gt;
&lt;li&gt;dropbear (default disable)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;이미지를 빌드 하고 디버깅하고자 하는 Application을 실행 시킨다.
&lt;ul&gt;
&lt;li&gt;QEMU의 경우 GEM0만 연결되어 있으므로 필요 시 GEM3 등의 Device Tree를 추가하여 빌드한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;vitis를 실행 시키고 &lt;code&gt;*.XSA&lt;/code&gt; 파일 등을 이용하여 platform project를 구성한다.&lt;/li&gt;
&lt;li&gt;platform project에 빈 linux Applicaiton domain을 추가한다.&lt;/li&gt;
&lt;li&gt;4)항의 항목내 Debug configuration을 이용하여 Single Application Debug를 추가한다.
&lt;ul&gt;
&lt;li&gt;target 보드의 debug IP/port를 설정하고 파일 패스를 설정한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;gnu-debuger&#34;&gt;GNU Debuger&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;GNU 디버거를 사용하기 위해서는 Root file System에 gdbserver를 포함하여야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;custom-hw-and-driver-development&#34;&gt;Custom HW and Driver Development&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Xilinx는 Custop IP에 대한 디바이스 제어를 위해 하기의 방법을 제안한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Linux Device Driver 제작&lt;/li&gt;
&lt;li&gt;mmap의 사용 (사용이 쉽다. 인터럽트 핸들링이 안됨)&lt;/li&gt;
&lt;li&gt;User space I/O (UIO 사용) (간단한 IRQ핸들링이 된다, Latency가 가변적이고 DMA가 지원되지 않는다)&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Petalinux는 빌드 시 Device Tree Generator가 DTSI/DTS파일을 생성하고 DTB를 만든다
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;*.XSA&lt;/code&gt; 파일을 분석하여 기본적인 DTSI/DTS 파일을 만든다&lt;/li&gt;
&lt;li&gt;&lt;code&gt;{project-root}/components/plnx_workspace/device-tree/device-tree&lt;/code&gt;에 생성되는 DTSI파일은 다음과 같다
&lt;ul&gt;
&lt;li&gt;pl.dtsi : memory-mapped PL IP node&lt;/li&gt;
&lt;li&gt;pcw.dtsi : Dynamic properties of the PS peripheral&lt;/li&gt;
&lt;li&gt;system-top.dts : boot argument 와 console, memory information&lt;/li&gt;
&lt;li&gt;zynqmp.dtsi : PS peri and CPU information&lt;/li&gt;
&lt;li&gt;zynqmp-clk-ccf.dtsi : IP peri를 위한 clock information&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Custop IP 추가 등 Device tree를 업데이트 하기 위해 하기 DTSI를 업데이트 한다.
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;{project-root}/project-spec/meta-user/recipes-bsp/device-tree/files/system-user.dtsi&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;custom-hw-and-petalinux-개발-절차&#34;&gt;Custom HW and Petalinux 개발 절차&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Custop IP를 개발(RTL 등) 후 Vivado IP Packer를 통하여 IP-XACT Standard Format으로 패키징 한다.&lt;/li&gt;
&lt;li&gt;Vivado를 이용하여 1)항의 IP와 기타 사용자 IP를 조합하여 &lt;code&gt;*.XSA&lt;/code&gt; 파일을 생성한다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;petalinux-creat -t project -n {project 이름}&lt;/code&gt;를 이용하여 project를 생성하고 &lt;code&gt;*.XSA&lt;/code&gt; 파일을 import한다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;petalinux-creat -t module -n {driver 이름}&lt;/code&gt;을 이용하여 모듈을 생성한다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;{project-root}/project-spec/meta-user/recipes-bsp/device-tree/files/system-user.dtsi&lt;/code&gt;에 Custom IP에 관련된 Device tree를 업데이트한다.
&lt;ul&gt;
&lt;li&gt;작성 시 &lt;code&gt;pl.dtsi&lt;/code&gt;를 확인하여 module name 및 address 등을 확인한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;모듈 내부 드라이버 파일을 작성하고 Yocto 레시피를 수정한다.&lt;/li&gt;
&lt;li&gt;커널에 로딩할 지 모듈로 rootfs에 등록할지 결정한 후 빌드한다.&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>[Petalinux] Petalinux Basic</title>
        <link>https://muonkmu.github.io/p/petalinux-petalinux-basic/</link>
        <pubDate>Mon, 19 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/petalinux-petalinux-basic/</guid>
        <description>&lt;h2 id=&#34;petalinux-basic&#34;&gt;Petalinux Basic&lt;/h2&gt;
&lt;h3 id=&#34;petalinux-정의&#34;&gt;petalinux 정의&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Petalinux는 xillinx FPGA를 위한 임베디드 리눅스 개발 툴로 YOCTO 프로젝트 Wrapper이다.&lt;/li&gt;
&lt;li&gt;Hardware description file(*.XSA) 또는 BSP 파일을 입력으로 리눅스 이미지 생성&lt;/li&gt;
&lt;li&gt;Petalinux 프로젝트의 레이아웃은 프로젝트 생성 시, XSA import 시, build 시 추가/달라짐 (교재 p66을 참조 및 &lt;a class=&#34;link&#34; href=&#34;https://docs.xilinx.com/r/2021.1-English/ug1144-petalinux-tools-reference-guide/Image-Selector?tocId=nfcK0XF5PXQyI2ebTdA8fA&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://docs.xilinx.com/r/2021.1-English/ug1144-petalinux-tools-reference-guide/Image-Selector?tocId=nfcK0XF5PXQyI2ebTdA8fA&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;기본-명령어-및-design-flow&#34;&gt;기본 명령어 및 Design Flow&lt;/h3&gt;
&lt;p&gt;상세 내용은 교제의 &lt;code&gt;Petalinux Tool : Design Flow&lt;/code&gt; 및 &lt;code&gt;LAB2&lt;/code&gt; 참조&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;프로젝트 생성&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;petalinux-create -t {type} -n {name} &amp;ndash;template {기초 템플릿}&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;petalinux-create -t project -n test_prj --template zynqMP
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;프로젝트 설정 : Hardware Description 및 boot, rootfs, kernel&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;petalinux-config 또는 petalinux-config -c {rootfs/kernel/device-tree/u-boot}&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; test_prj
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;petalinux-config --get-hw-description&lt;span class=&#34;o&#34;&gt;={&lt;/span&gt;xsa file&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt; --silentconfig
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;프로젝트 빌드&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;petalinux-build 또는 petalinux-build -c {rootfs/kernel/device-tree/u-boot}&lt;/li&gt;
&lt;li&gt;생성되는 파일은 하기와 같다
&lt;ul&gt;
&lt;li&gt;boot.scr: A u-boot boot script&lt;/li&gt;
&lt;li&gt;image.ub: U-boot wrapped Linux kernel image&lt;/li&gt;
&lt;li&gt;rootfs.tar.gz: Compressed root file system tar ball&lt;/li&gt;
&lt;li&gt;그외 Pakage를 위한 파일&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;petalinux-build
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;프로젝트 패키징&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;.BIN&lt;/code&gt; 또는 &lt;code&gt;.MCS&lt;/code&gt; 생성 ( = fsbl + ssbl + pmu + bitstream)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;.BIN&lt;/code&gt; 은 다음과 내용을 포함한다.&lt;/li&gt;
&lt;li&gt;Platform Loader and Manager (PLM)&lt;/li&gt;
&lt;li&gt;PS Management (PSM) firmware&lt;/li&gt;
&lt;li&gt;Platform Device Image (PDI)&lt;/li&gt;
&lt;li&gt;ARM trusted firmware&lt;/li&gt;
&lt;li&gt;u-boot&lt;/li&gt;
&lt;li&gt;Device tree blob&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;petalinux-package --boot --fsbl zynqmp_fsbl.elf --u-boot u-boot.elf --pmufw pmufw.elf --fpga system.bit
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;부트&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SD카드에 이미지 복사(BOOT.BIN, Image, rootfs.cpio.gz.u-boot, boot.scr) 후 보드 부팅&lt;/li&gt;
&lt;li&gt;qemu로 에뮬레이션 가능&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;petalinux-boot --qemu --kernel
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;TFTP를 위한 Jtag 부트&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;petalinux-boot --jtag --prebuilt &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt; --hw_server-url tcp:127.0.0.1:3121
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;application-development&#34;&gt;Application development&lt;/h3&gt;
&lt;p&gt;상세 내용은 교제의 p133 &lt;code&gt;Petalinux Application Development&lt;/code&gt; 및 &lt;code&gt;LAB3&lt;/code&gt; 참조&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Petalinux의 project가 생성된 상태에서 petalinux-create를 사용하여 app을 생성&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;project-spec/meta-user/recipes-apps/{app_name}&lt;/code&gt;에서 생성된 파일(bb 및 source) 확인 가능&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;petalinux-create -t apps --name helloworld --template c
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;source 및 makefile을 생성 또는 복사한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;project-spec/meta-user/recipes-apps/{app_name}/file&lt;/code&gt;에서 수정한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Yocto Recipe file를 수정한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;project-spec/meta-user/recipes-apps/{app_name}&lt;/code&gt;의 &lt;code&gt;{app_name}.bb&lt;/code&gt;파일에 관련파일을 등록한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;root filesystem에 등록한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;petalinux-config -c rootfs&lt;/code&gt; 수행 후 &lt;code&gt;apps&lt;/code&gt; 메뉴에서 등록&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;build 후 &lt;code&gt;/usr/bin&lt;/code&gt;에서 app을 확인 가능하다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;프로젝트-설정&#34;&gt;프로젝트 설정&lt;/h2&gt;
&lt;p&gt;상세 내용은 교제의 p150 &lt;code&gt;Customizing the project&lt;/code&gt; 참조
&lt;code&gt;petalinux-config&lt;/code&gt;를 이용하여 하기 설정이 가능하다&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;firmware version 정보&lt;/li&gt;
&lt;li&gt;root filesystem 종류 : INITRD, INITRAMFS JFFS2, UBI/UBIFS, NFS, EXT4(SD/eMMC&amp;hellip;)&lt;/li&gt;
&lt;li&gt;U-boot 이미지 저장 위치 : bootenv 조절을 통해 Jtag/DDR, QSPI, NAND의 image offset을 조정할 수 있다.&lt;/li&gt;
&lt;li&gt;Primary Flash(QSPI?)의 파티션 조절 가능&lt;/li&gt;
&lt;li&gt;File system package를 조절하여 Kernel image size 및 Root file system 이미지 사이즈를 줄일 수 있다.&lt;/li&gt;
&lt;li&gt;TFTP 부팅을 위한 pre-built 이미지 위치를 설정할 수 있다&lt;/li&gt;
&lt;li&gt;NFS 또는 SD card를 통한 Root file system 로딩을 설정 할 수 있다.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;root-file-system-customize&#34;&gt;Root file system customize&lt;/h2&gt;
&lt;p&gt;상세 내용은 교제의 p212 &lt;code&gt;Customizing the Root File System&lt;/code&gt; 참조&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;custom applications, libraries, module을 추가하거나 생성 가능&lt;/li&gt;
&lt;li&gt;pre-compiled applications, libraries, module을 추가하거나 생성 가능&lt;/li&gt;
&lt;li&gt;YOCTO layer, recipes 또는 package 추가 가능&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>Github blog 만들기</title>
        <link>https://muonkmu.github.io/p/github-blog-%EB%A7%8C%EB%93%A4%EA%B8%B0/</link>
        <pubDate>Tue, 13 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/github-blog-%EB%A7%8C%EB%93%A4%EA%B8%B0/</guid>
        <description>&lt;h2 id=&#34;목표&#34;&gt;목표&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;개인 기술 정리를 위한 블로그의 생성&lt;/li&gt;
&lt;li&gt;markdown 사용이 편리한 github.io를 이용하기로 결정&lt;/li&gt;
&lt;li&gt;빌드가 빠른 HUGO framework을 사용 (github에서는 Jekyll framework가 기본이나 컨텐츠가 쌓이면 빌드가 느려지는 단점이 있음)&lt;/li&gt;
&lt;li&gt;Hugo theme는 STACK을 사용&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;개발-환경&#34;&gt;개발 환경&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Oracle Cloud Arm server&lt;/li&gt;
&lt;li&gt;Ubuntu 20.40&lt;/li&gt;
&lt;li&gt;code-server&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;사전-준비&#34;&gt;사전 준비&lt;/h2&gt;
&lt;h3 id=&#34;go-설치&#34;&gt;GO 설치&lt;/h3&gt;
&lt;p&gt;Hugo는 GO로 작성되 있으므로 GO를 설치한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ref : &lt;a class=&#34;link&#34; href=&#34;https://go.dev/doc/install&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://go.dev/doc/install&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;필요 시 GO의 설치 경로를 &lt;code&gt;PATH&lt;/code&gt;에 등록한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;hugo-설치&#34;&gt;Hugo 설치&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;리눅스의 경우 패키지 관리자를 이용하여 설치가 가능하나 이 경우 old 버전이 설치된다.&lt;/li&gt;
&lt;li&gt;STACK 테마의 경우 최신버전과 hugo extension이 필요하므로 Go를 이용하여 설치한다.&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://gohugo.io/installation/linux/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://gohugo.io/installation/linux/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; go install -tags extended github.com/gohugoio/hugo@latest
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;필요 시 Hugo의 설치 경로를 &lt;code&gt;PATH&lt;/code&gt;에 등록한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;git-repo-생성&#34;&gt;git repo 생성&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;hosting을 위한 repo를 생성한다.
&lt;ul&gt;
&lt;li&gt;repo의 이름은 &lt;code&gt;{git ID}.github.io&lt;/code&gt; 형식 ex) muonkmu.github.io&lt;/li&gt;
&lt;li&gt;호스팅 목적이므로 repo는 public&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;hugo 빌드 전 소스를 보관할 repo를 생성한다.
&lt;ul&gt;
&lt;li&gt;이름은 상관 없음 ex) blog&lt;/li&gt;
&lt;li&gt;소스 보관용이므로 public/private은 개인 취향&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;블로그-작성-및-배포&#34;&gt;블로그 작성 및 배포&lt;/h2&gt;
&lt;h3 id=&#34;hugo-프로젝트-생성-및-테마-설정&#34;&gt;hugo 프로젝트 생성 및 테마 설정&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;프로젝트를 생성 후 폴더 이동, 하기 예제의 이름은 hugoBlog로 가정&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hugo new site hugoBlog
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; hugoBlog
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;git 초기화 및 테마 설정
&lt;ul&gt;
&lt;li&gt;하기 예제에서는 Stack 테마 사용&lt;/li&gt;
&lt;li&gt;clone으로 테마 소스를  &lt;code&gt;themes&lt;/code&gt;폴더에 넣을 수도 있으나 submodule을 추천&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; git init
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; git submodule add https://github.com/CaiJimmy/hugo-theme-stack.git themes/hugo-theme-stack
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;config파일 설정
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;config.toml&lt;/code&gt;을 수정, 하기 예제에서는  stack 테마의 예제 파일을 복사/수정 한다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;config.yaml&lt;/code&gt;의 baseurl, theme, title 등을 수정한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;rm config.toml
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cp themes/hugo-theme-stack/exampleSite/config.yaml ./
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cp themes/hugo-theme-stack/exampleSite/content ./
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;baseurl&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https://muonkmu.github.io/&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;languageCode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;en-us&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;theme&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;hugo-theme-stack&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;paginate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;MW Devlog&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;컨텐츠-작성-및-테스트&#34;&gt;컨텐츠 작성 및 테스트&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;categories, post, page 등을 작성한다.
&lt;ul&gt;
&lt;li&gt;하기 예제에서는 stack 테마의 예제 파일을 복사/수정 한다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;content/post&lt;/code&gt; 내 예제 파일을 참조하여 post를 작성한다(예제포스트는 지워도 된다.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;rm -r content
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cp themes/hugo-theme-stack/exampleSite/content ./
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;테스트 서버를 구동하여 동작을 확인한다.
&lt;ul&gt;
&lt;li&gt;하기 예제에는 orcle 서버에서 개발하는 것을 가정, 내부 바인딩과 포트를 별도로 할당였다(오라클 서버에서 방화벽에 우선적으로 포트을 열어둬야 함)&lt;/li&gt;
&lt;li&gt;웹 브라우저로 테스트 서버에 접속해 동작을 확인한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; hugo server -D --bind&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;0.0.0.0 -p &lt;span class=&#34;m&#34;&gt;8070&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;빌드-및-배포&#34;&gt;빌드 및 배포&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;github repo를 연결한다.
&lt;ul&gt;
&lt;li&gt;소스 repo에 프로젝트 폴더를 연결&lt;/li&gt;
&lt;li&gt;host repo에 &lt;code&gt;public&lt;/code&gt; 폴더를 연결&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git remote add origin https://github.com/muonkmu/blog.git
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;rm -r public
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git submodule add -b master https://github.com/muonkmu/muonkmu.github.io.git public
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;소스를 빌드한다.
&lt;ul&gt;
&lt;li&gt;하기 예제에서는 stack 테마의 사용 경우이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; hugo -t hugo-theme-stack
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;빌드 및 소스 파일을 push 한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; public
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git add .
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git commit -m &lt;span class=&#34;s2&#34;&gt;&amp;#34;first commit&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git branch -M main
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git push origin main
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; ..
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git add .
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git commit -m &lt;span class=&#34;s2&#34;&gt;&amp;#34;first commit&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git branch -M main
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git push origin main
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;(option)배포에 시 사용할 쉘 스크립트를 작성한다. ex)deploy.sh&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#!/bin/bash
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hugo -t hugo-theme-stack
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; public
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git add .
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;msg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;rebuilding site `date`&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;$#&lt;/span&gt; -eq &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;then&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;msg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$1&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;fi&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git commit -m &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$msg&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git push origin main
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; ..
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git add .
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;msg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;rebuilding site `date`&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;$#&lt;/span&gt; -eq &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;then&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;msg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$1&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;fi&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git commit -m &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$msg&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git push origin main
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;debug&#34;&gt;Debug&lt;/h2&gt;
&lt;h3 id=&#34;hugo-받침-분리-표기-문제&#34;&gt;HUGO 받침 분리 표기 문제&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;사용하던 중 &amp;lsquo;가&amp;rsquo; 받침이 분리되어 표기되는 문제가 발견되었다. ex) &amp;lsquo;각&amp;rsquo; 이 &amp;lsquo;가ㄱ&amp;rsquo; 로 표기&lt;/li&gt;
&lt;li&gt;구글링을 해보니 &lt;code&gt;Droid Sans Fallback&lt;/code&gt; 폰트의 문제라고 생각되어 관련 폰트를 삭제하여 문제를 해결&lt;/li&gt;
&lt;li&gt;&lt;code&gt;./themes/hugo-theme-stack/assets/scss/variables.scss&lt;/code&gt; 의 &lt;code&gt;--sys-font-family&lt;/code&gt;, &lt;code&gt;--zh-font-family&lt;/code&gt; 변수 내 Droid Sans 관련 폰트를 모두 삭제한다.&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>[AI HW Design] Chap03 Parallel Architecture (1/3)</title>
        <link>https://muonkmu.github.io/p/ai-hw-design-chap03-parallel-architecture-1/3/</link>
        <pubDate>Mon, 12 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/ai-hw-design-chap03-parallel-architecture-1/3/</guid>
        <description>&lt;p&gt;본 챕터에서는 몇가지 주요한 Paralle Architecture에 대하여 소개한다.
이 페이지에서는 CPU와 GPU에 대해서 우선 기술한다.&lt;/p&gt;
&lt;h2 id=&#34;intel-central-processing-unit-cpu&#34;&gt;Intel Central Processing Unit (CPU)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.intel.com/content/www/us/en/developer/articles/technical/xeon-processor-scalable-family-technical-overview.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.intel.com/content/www/us/en/developer/articles/technical/xeon-processor-scalable-family-technical-overview.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;CPU는 병렬 프로세싱을 위해 Single Instruction Single Data (SISD) architecture에서 Single Instruction Multiple Data (SIMD)로 진화함.&lt;/li&gt;
&lt;li&gt;그러나 이는 딥러닝과 같은 거대 병렬 처리에 적합하지 못하여 2017년 딥러닝 어플리케이션을 위한 Xeon processor scalable family (purley platform) 발표&lt;/li&gt;
&lt;li&gt;Purley platform은 하기 특징을 가짐&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;skylake-mesh-architecture&#34;&gt;Skylake mesh architecture&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;이전 Grantley platform에서는 Last-Level Chache(LLC)등이 Intel Quick Path Interconnect(QPI) ring achitecture로 연결&lt;/li&gt;
&lt;li&gt;상기 구조는 코어 증가 시 코어 마다 사용가능한 bandwidth가 줄어들어서 메모리 latency가 증가&lt;/li&gt;
&lt;li&gt;Grantley platform에서는 Intel Ultra Path Interconnect(UPI) mesh archictecture로 업그레이드&lt;/li&gt;
&lt;li&gt;Comnined Home Agent(CHA)가 통합, 이는 LLC 등의 주소 정보 지도를 작성하며 이는 mesh 연결에서 목적지까지의 라우팅 정보를 제공
&lt;img src=&#34;https://www.intel.com/content/dam/develop/external/us/en/images/xeon-processor-scalable-family-tech-overview-fig05-737410.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Intel Xeon processor Scalable family mesh architecture&#34;
	
	
&gt;
&lt;em&gt;Fig1. Intel Xeon processor Scalable family mesh architecture&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;intel-ultra-path-interconnect&#34;&gt;Intel Ultra Path Interconnect&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;UPI는 어드레스를 공유하는 mutiple processor coherent interconnect&lt;/li&gt;
&lt;li&gt;UPI는 vertical/horizontal path를 통한 한 코어에서 다른 코어로의 최단 경로를 제공&lt;/li&gt;
&lt;li&gt;2소켓, 4소켓 링, 8소켓+크로스바 등 다양한 구조 지원&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;subnon-unified-memory-access-clustering&#34;&gt;SubNon-Unified Memory Access Clustering&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;플랫폼은 모든 코어/LLC를 반씩 + 메모리 컨트롤를 1개씩 가진 SNC 0,1 도메인을 가짐&lt;/li&gt;
&lt;li&gt;각 도메인은 각 메모리 컨트롤러에 매핑되는 유니크한 LLC 주소를 가지며 이는 LLC access latency를 낮춤&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cache-hierarchy-change&#34;&gt;Cache Hierarchy Change&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;하기 그림과 같이 변경 LLC 및 MLC size 변경으로 hit rate 증가
&lt;img src=&#34;https://www.intel.com/content/dam/develop/external/us/en/images/xeon-processor-scalable-family-tech-overview-fig11-737410.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Generational cache comparison&#34;
	
	
&gt;
&lt;em&gt;Figure 11. Generational cache comparison&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;singlemultiple-socket-parallel-processing&#34;&gt;single/Multiple Socket Parallel Processing&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;UPI와 sub-NUMA의 지원으로 딥러닝 worker process들은 코어셋이나 싱글소켓, 다중소켓에 assign 될 수 있음&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;advanced-vector-software-extension&#34;&gt;Advanced vector software extension&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Intel Advanced Vector Extension 512(Intel AVX-512)가 Vector Neural Network Instruction(VNNI)를 지원하는 AVX-512)_VNNI로 발전&lt;/li&gt;
&lt;li&gt;대충 더 빨라지고 8/16/32 FP vector 연산을 지원한다는 듯(자세한 사항은 책 참조)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;math-kernel-library-for-deep-neural-networkmkl-dnn&#34;&gt;Math Kernel Library for Deep Neural Network(MKL-DNN)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Convolution, pooling, activation, batch normalization으로 구성된 최적화된 MKL-DNN 지원&lt;/li&gt;
&lt;li&gt;key feature는 prefetching, data reuse, cache blocking, data layout, vectorization, register blocking이며 자세한 사항은 책 참조&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;nvidia-graphics-processing-unit-gpu&#34;&gt;NVIDIA Graphics Processing Unit (GPU)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;GPU 장점 : 효율적인 floating point 연산, high speed memory support&lt;/li&gt;
&lt;li&gt;Turing architecture를 개발함 (NVLink2를 위한 HBM2 적용, 캐시 구조 변경 등등)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;tensor-core-architecture&#34;&gt;Tensor Core Architecture&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;tensor core란 : 행렬연산 및 MAC를 위한 전용 코어&lt;/li&gt;
&lt;li&gt;Turing Tensor core는 이전(Pascal)이 matrix row by row만 지원했으나 4X4X4 연산을 지원하도록 변경&lt;/li&gt;
&lt;li&gt;INT8, INT4를 지원하며 정확도를 낮추면 연산 속도 증가&lt;/li&gt;
&lt;li&gt;Matrix사이즈가 크면 이를 나누어 연산, 다양한 size의 매트릭스 연산에 대응 가능&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.nvidia.com/ko-kr/data-center/tensor-cores/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.nvidia.com/ko-kr/data-center/tensor-cores/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;winograd-transform&#34;&gt;Winograd Transform&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;곱셈 횟수를 줄일 수 있는 Winograd Transform을 지원&lt;/li&gt;
&lt;li&gt;상기 변환에 대한 연산식은 책과 다른 자료를 참조할 것&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;simultaneous-multithreading-smt&#34;&gt;Simultaneous Multithreading (SMT)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;SMT의 경우 Matrix는 행렬을 여러 그룹으로 나누고 이를 병렬로 처리 (Single Instruction Multiple Thread, SIMT 방식)&lt;/li&gt;
&lt;li&gt;연산 후 하위 그룹을 재그룹 시킴&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;high-bandwidth-memory-hbm2&#34;&gt;High Bandwidth Memory (HBM2)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Memory Bottleneck해결을 위해 HBM2 적용 (memory die를 TSV로 뚫어서 스택함)&lt;/li&gt;
&lt;li&gt;HBM2는 GPU와 NVLink2로 연결됨&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;nvlink2-configuration&#34;&gt;NVLink2 Configuration&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;NVLink는 엔비디아가 개발한 와이어 기반 통신 프로토콜 시리얼 멀티 레인 근범위 통신 링크 (PCIE의 속도 문제 해결)&lt;/li&gt;
&lt;li&gt;Turing 아키텍쳐는 sing MIO를 two×8 bidirectional differential pair NVLink2로 대체&lt;/li&gt;
&lt;li&gt;CPU/GPU 메모리 간 directly load/store/atomic 가능 (데이터를 GPU메모리에서 바로 읽을 수 있고 CPU cache에 바로 저장 가능)&lt;/li&gt;
&lt;li&gt;다양한 구성을 지원한다. (책을 참조하자)&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Ubuntu 20.04 개인 환경 설정</title>
        <link>https://muonkmu.github.io/p/ubuntu-20.04-%EA%B0%9C%EC%9D%B8-%ED%99%98%EA%B2%BD-%EC%84%A4%EC%A0%95/</link>
        <pubDate>Mon, 12 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/ubuntu-20.04-%EA%B0%9C%EC%9D%B8-%ED%99%98%EA%B2%BD-%EC%84%A4%EC%A0%95/</guid>
        <description>&lt;h2 id=&#34;목적&#34;&gt;목적&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Ubuntu 20.04 LTS 설치 후 나에게 맞는 설정 및 설정 방법 정리&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;유의사항&#34;&gt;유의사항&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;설치 시 언어는 영어, 키보드 영어 자판으로 설치를 권장&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;개인-설정&#34;&gt;개인 설정&lt;/h2&gt;
&lt;h3 id=&#34;nvidia-그래픽-카드-설정&#34;&gt;Nvidia 그래픽 카드 설정&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;설치 가능한 드라이버 확인&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ubuntu-drivers devices
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;권장 드라이버 설치&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo ubuntu-drivers autoinstall
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;한영키-동작-설정&#34;&gt;한영키 동작 설정&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;입력기 설치 :
&lt;ul&gt;
&lt;li&gt;setting → Region and Language → Input Source → Korean(Hangul) 추가&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;1항의 추가된 항목 설정에서 Hangul Toggle Key를 Hangul만 남김(option)&lt;/li&gt;
&lt;li&gt;/usr/share/X11/xkb/symbols/altwin 편집
&lt;ul&gt;
&lt;li&gt;4행의 &lt;code&gt;key &amp;lt;RALT&amp;gt; ...&lt;/code&gt; 부분에서 &lt;code&gt;symbols[Gropu1] = [ Alt_R, Meta_R ]&lt;/code&gt; 부분을 &lt;code&gt;[ Hangul ]&lt;/code&gt; 로 수정한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;vnc-설치&#34;&gt;VNC 설치&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;tigerVNC 설치&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; sudo apt-get install tigervnc-standalone-server tigervnc-xorg-extension
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;비밀번호 설정&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; vncpasswd
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;~/.vnc/xstartup 작성&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#!/bin/sh
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;# Start Gnome 3 Desktop&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt; -x /etc/vnc/xstartup &lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; /etc/vnc/xstartup
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt; -r &lt;span class=&#34;nv&#34;&gt;$HOME&lt;/span&gt;/.Xresources &lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; xrdb &lt;span class=&#34;nv&#34;&gt;$HOME&lt;/span&gt;/.Xresources
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;vncconfig -iconic &lt;span class=&#34;p&#34;&gt;&amp;amp;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;dbus-launch --exit-with-session gnome-session &lt;span class=&#34;p&#34;&gt;&amp;amp;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;vnc 서버 실행&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  vncserver -localhost no
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;vnc 서버 종료&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  vncserver -kill :2
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;설정변경 :  $&amp;gt;sudo vim /etc/vnc.conf&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;$geometry&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;1920x1080&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;$depth&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;16&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;ssh-설치&#34;&gt;SSH 설치&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;서버 설치&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt install openssh-server
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;실행여부 확인&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo systemctl status ssh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;서버 실행&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo systemctl &lt;span class=&#34;nb&#34;&gt;enable&lt;/span&gt; ssh
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo systemctl start ssh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;xforward 설정 팡일의
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;/etc/ssh/ssh_config&lt;/code&gt; 의 &lt;code&gt;x11Forward no → x11Forward yes&lt;/code&gt;로 변경&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ssh서버 재실행 및 클라언트 실행 시 -X 옵션 추가&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;zshom-my-zsh-설치-및-설정&#34;&gt;ZSH/om-my-zsh 설치 및 설정&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;zsh 설치&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt-get install zsh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;설치확인&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cat /etc/shells
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;기본쉘 변경&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;chsh -s &lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;which zsh&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;oh-my-zsh 설치(curl설치필요)&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sh -c &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;테마변경
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;~/.zshrc&lt;/code&gt; 파일 내 &lt;code&gt;ZSH_THEME=&amp;quot;agnoster&amp;quot;&lt;/code&gt; 로 변경&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;글자깨질 시 Powerline폰트 설치&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt-get install fonts-powerline
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;7&#34;&gt;
&lt;li&gt;커맨드라인 컴퓨터 이름 감추기
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;~/.zshrc&lt;/code&gt; 하단에 하기 내용 추가&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;prompt_context&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;[[&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$USER&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt; !&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$DEFAULT_USER&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;||&lt;/span&gt; -n &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$SSH_CLIENT&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;]]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;then&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;prompt_segment black default &lt;span class=&#34;s2&#34;&gt;&amp;#34;%(!.%{%F{yellow}%}.)&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$USER&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;fi&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;8&#34;&gt;
&lt;li&gt;zsh-autosuggestions 플러그인 설치&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://github.com/zsh-users/zsh-autosuggestions.git &lt;span class=&#34;nv&#34;&gt;$ZSH_CUSTOM&lt;/span&gt;/plugins/zsh-autosuggestions
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;9&#34;&gt;
&lt;li&gt;zsh-syntax-highlighting 플러그인 설치&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://github.com/zsh-users/zsh-syntax-highlighting.git &lt;span class=&#34;nv&#34;&gt;$ZSH_CUSTOM&lt;/span&gt;/plugins/zsh-syntax-highlighting
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;10&#34;&gt;
&lt;li&gt;autojump 설치&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://github.com/wting/autojump.git
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; autojump
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;./install.py
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;사용법 &lt;code&gt;j [디렉토리 명]&lt;/code&gt; 또는  &lt;code&gt;j -s&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;11&#34;&gt;
&lt;li&gt;
&lt;p&gt;플러그인 활성화&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;~/.zshrc&lt;/code&gt; 파일 내 &lt;code&gt;plugins=(git zsh-autosuggestions zsh-syntax-highlighting autojump)&lt;/code&gt; 로 변경&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;줄바꿈 적용(멀티라인 입력)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;~/.oh-my-zsh/themes/agnoster.zsh-theme&lt;/code&gt;파일 수정&lt;/li&gt;
&lt;li&gt;&lt;code&gt;prompt_hg&lt;/code&gt; 하단에 &lt;code&gt;prompt_newline&lt;/code&gt; 추가 후 파일 최하단 하기 프롬프트 추가&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;prompt_newline&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;[[&lt;/span&gt; -n &lt;span class=&#34;nv&#34;&gt;$CURRENT_BG&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;]]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;then&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; -n &lt;span class=&#34;s2&#34;&gt;&amp;#34;%{%k%F{&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$CURRENT_BG&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;}%}&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$SEGMENT_SEPARATOR&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;%{%k%F{blue}%}&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$SEGMENT_SEPARATOR&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; -n &lt;span class=&#34;s2&#34;&gt;&amp;#34;%{%k%}&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;fi&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; -n &lt;span class=&#34;s2&#34;&gt;&amp;#34;%{%f%}&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;CURRENT_BG&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;option-tfpt-설치&#34;&gt;(option) TFPT 설치&lt;/h3&gt;
&lt;p&gt;xilinx petalinux를 사용할 생각이라면 tftp 설치가 필요하다&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;tftp 설치&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt-get update
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt-get install tftpd-hpa
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;서비스 확인&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo service tftpd-hpa status
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;설정 파일 &lt;code&gt;/etc/default/tftpd-hpa&lt;/code&gt; 를 원하는 대로 수정한다.
&lt;ul&gt;
&lt;li&gt;다른 것은 크게 의미가 없고 up/down 위치인 &lt;code&gt;TFTP_DIRECTORY&lt;/code&gt; 정도만 수정&lt;/li&gt;
&lt;li&gt;수정 후 디렉토리 권한 설정을 해준다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;vim /etc/default/tftpd-hpa
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo mkdir &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;tftp-dir&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo chmod &lt;span class=&#34;m&#34;&gt;777&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;tftp-dir&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo chown -R tftp:tftp &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;tftp-dir&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;설정 완료 후 재시작&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo service tftpd-hpa restart
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;option-nfs-server-설치&#34;&gt;(option) NFS server 설치&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;nfs서버 패키지 설치&lt;/li&gt;
&lt;li&gt;nfs 서버용 폴더를 만들고 모든 클라이언트 머신이 공유 디렉토리에 액세스하기 위하여 권한 제거 및 파일의 권한 제거&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/etc/exports&lt;/code&gt; 파일을 편집하여 공유할 폴더를 지정하고 클라언트 및 실행 권한 설정&lt;/li&gt;
&lt;li&gt;&lt;code&gt;exportfs&lt;/code&gt;로 설정된 폴더 내보내기&lt;/li&gt;
&lt;li&gt;nfs_server 재시작&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo apt install nfs-kernel-server
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;mkdir &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;공유폴더&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo chown -R nobody:nogroup &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;공유폴더&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo chmod &lt;span class=&#34;m&#34;&gt;777&lt;/span&gt; &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;공유폴더&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo &lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;${공유폴더} 192.168.1.1/24(rw,sync,no_root_squash,no_subtree_check)&amp;#39;&lt;/span&gt; &amp;gt;&amp;gt;  /etc/exports
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo exportfs -a
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo service nfs-kernel-server restart
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        <item>
        <title>원격 개발 서버 구축</title>
        <link>https://muonkmu.github.io/p/%EC%9B%90%EA%B2%A9-%EA%B0%9C%EB%B0%9C-%EC%84%9C%EB%B2%84-%EA%B5%AC%EC%B6%95/</link>
        <pubDate>Mon, 12 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/%EC%9B%90%EA%B2%A9-%EA%B0%9C%EB%B0%9C-%EC%84%9C%EB%B2%84-%EA%B5%AC%EC%B6%95/</guid>
        <description>&lt;h2 id=&#34;목적&#34;&gt;목적&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;클라우드 서버를 이용하여 원격으로 접속 가능한 개발 서버의 구축&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;최종-목표&#34;&gt;최종 목표&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;고정 IP를 가진 ubuntu 서버
&lt;ul&gt;
&lt;li&gt;무료 클라우드 서버 중 오라클이 ARM64-4core/24GB ram/200GB storage VM 머신 제공 (타사 대비 월등히 좋음)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;원격 개발을 위한 code-server 설치&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;서버-구축&#34;&gt;서버 구축&lt;/h2&gt;
&lt;h3 id=&#34;클라우드-서버-구축&#34;&gt;클라우드 서버 구축&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;오라클 클라우드 Free tier 가입
&lt;ul&gt;
&lt;li&gt;리전은 원하는 곳(춘천이 빠르고 ARM 서버 리소스가 남음)&lt;/li&gt;
&lt;li&gt;카드 정보를 기입(실제로 결제가 되지는 않음)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;가입 완료 후 하단의 &lt;code&gt;Create a VM instance&lt;/code&gt; 시작
&lt;ul&gt;
&lt;li&gt;instance Name 입력&lt;/li&gt;
&lt;li&gt;image는 원하는거 선택, ex) &lt;code&gt;canonical Ubuntu 20.04&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;shape는 &lt;code&gt;Ampere&lt;/code&gt; 선택 core는 4, memory는 24GB 까지 무료&lt;/li&gt;
&lt;li&gt;상기 리소스를 나누어 무료 VM를 생성할 수 있다.ex) 2core-12GB 인스턴스 2개 무료&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;VCN이 없다면 페이지에서 VCN을 생성하여 연결&lt;/li&gt;
&lt;li&gt;본인의 PC에서 SSH를 생성하여 Public키를 업로드 한다.
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;http://taewan.kim/oci_docs/98_misc_tips/ssh_key_pairs/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://taewan.kim/oci_docs/98_misc_tips/ssh_key_pairs/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;부트 볼륨 생성
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Specify a custom boot volume size&lt;/code&gt;을 클릭 후 원하는 볼륨생성&lt;/li&gt;
&lt;li&gt;200GB까지 무료이며 상기 리소스를 나누어 무료 VM생성 가능&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Create&lt;/code&gt;로 생성
&lt;ul&gt;
&lt;li&gt;해당 리전의 리소스가 부족하여 생성이 안되는 경우가 있다.&lt;/li&gt;
&lt;li&gt;상기의 경우 리소스가 풀릴 때 까지 기다리거나 유료계정으로 업그레이드 (승인되는데 시간 걸림)&lt;/li&gt;
&lt;li&gt;유료 계정이 되더라도 무료 리소스까지만 쓰면 과금이 되지 않는다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;클라우드-서버-환경-설정&#34;&gt;클라우드 서버 환경 설정&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;고정 IP 설정
&lt;ul&gt;
&lt;li&gt;Compute &amp;gt; Instances &amp;gt; Instance Details &amp;gt; Attached VNICs &amp;gt; VNIC Details &amp;gt; IPv4 Addresses&lt;/li&gt;
&lt;li&gt;상기 경로에서 &lt;code&gt;NO PUBLIC IP&lt;/code&gt; 선택하여 IP 삭제 후 &lt;code&gt;RESERVED PUBLIC IP&lt;/code&gt;로 변경&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;우분터 사용자 계정 생성(option)
&lt;ul&gt;
&lt;li&gt;ssh 로그인&lt;/li&gt;
&lt;li&gt;현재 계정 &lt;code&gt;ubuntu&lt;/code&gt; 암호 생성&lt;/li&gt;
&lt;li&gt;사용자 계정 생성&lt;/li&gt;
&lt;li&gt;생성 계정에 sudo 권한 부여&lt;/li&gt;
&lt;li&gt;계정 변경&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ssh 비번으로 접속 설정
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;/etc/ssh/sshd_config&lt;/code&gt;파일의 &lt;code&gt;PasswordAuthentication&lt;/code&gt; 값을 &amp;ldquo;yes&amp;quot;로 변경&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;클라우드 포트 개방
&lt;ul&gt;
&lt;li&gt;Networking &amp;gt; Virtual Cloud Networks &amp;gt; {사용중인 VNC} &amp;gt; Security List Details&lt;/li&gt;
&lt;li&gt;상기 경로에서 포트 개방 추가&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;우분투 방화벽 포트 개방
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo iptables -I INPUT &lt;span class=&#34;m&#34;&gt;5&lt;/span&gt; -p tcp --dport &lt;span class=&#34;m&#34;&gt;8070&lt;/span&gt; -m state --state NEW,ESTABLISHED -j ACCEPT
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;code-server-설치&#34;&gt;code-server 설치&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;code-server 다운로드 및 설치
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://coder.com/docs/code-server/latest/install&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://coder.com/docs/code-server/latest/install&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl -fsSL https://code-server.dev/install.sh &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;서비스로 실행하기 위해 systemctl로 enable
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo systemctl &lt;span class=&#34;nb&#34;&gt;enable&lt;/span&gt; --now code-server@&lt;span class=&#34;nv&#34;&gt;$USER&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;외부 접속을 위해 &lt;code&gt;.config/code-server/config.yaml&lt;/code&gt;파일을 수정한다.
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;bind-addr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0.0.0.0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;{&lt;span class=&#34;l&#34;&gt;포트번호}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;auth&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;password&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;password&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{&lt;span class=&#34;l&#34;&gt;비밀번호}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;cert&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;서비스를 재시작 후 동작을 확인한다.
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo systemctl restart --now code-server@&lt;span class=&#34;nv&#34;&gt;$USER&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo systemctl status code-server@&lt;span class=&#34;nv&#34;&gt;$USER&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;chrome 브라우저에서 접속 시 이미지가 안보일 경우 하기 세팅을 수행
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;chrome://flags&lt;/code&gt; 설정 의 &lt;code&gt;Insecure origins treated as secure&lt;/code&gt; Enable 후 &lt;code&gt;http://{접속IP}:{접속Port}&lt;/code&gt; 추가&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>[CS231n] Chap 04 Introduction to Neural Networks</title>
        <link>https://muonkmu.github.io/p/cs231n-chap-04-introduction-to-neural-networks/</link>
        <pubDate>Tue, 25 Oct 2022 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/cs231n-chap-04-introduction-to-neural-networks/</guid>
        <description>&lt;p&gt;본 chapter에서는 Gradient를 구하기 위한 Backpropagation을 이해하고 Neural Network의 기본에 대해 설명한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Video : &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=d14TUNcbn1k&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.youtube.com/watch?v=d14TUNcbn1k&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slide : &lt;a class=&#34;link&#34; href=&#34;http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture4.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture4.pdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(TODO: 귀차니즘의 압박으로 정리를 안해놓았지만 언젠간 해야지)&lt;/p&gt;
&lt;h2 id=&#34;backpropagation&#34;&gt;Backpropagation&lt;/h2&gt;
&lt;h3 id=&#34;chain-rule&#34;&gt;Chain rule&lt;/h3&gt;
&lt;h3 id=&#34;sigmoid-gate-example&#34;&gt;Sigmoid gate example&lt;/h3&gt;
&lt;h3 id=&#34;patterns-in-backward-flow&#34;&gt;Patterns in backward flow&lt;/h3&gt;
&lt;h3 id=&#34;gradients-add-at-branches&#34;&gt;Gradients add at branches&lt;/h3&gt;
&lt;h3 id=&#34;vectorized-operations&#34;&gt;Vectorized operations&lt;/h3&gt;
&lt;h2 id=&#34;neural-network&#34;&gt;Neural Network&lt;/h2&gt;
&lt;h3 id=&#34;artificial-neural-network&#34;&gt;Artificial Neural Network&lt;/h3&gt;
&lt;h3 id=&#34;activation-function&#34;&gt;Activation Function&lt;/h3&gt;
&lt;h3 id=&#34;neural-networks-architectures&#34;&gt;Neural networks Architectures&lt;/h3&gt;
</description>
        </item>
        <item>
        <title>[CS231n] Chap 03 Loss Function and Optimization</title>
        <link>https://muonkmu.github.io/p/cs231n-chap-03-loss-function-and-optimization/</link>
        <pubDate>Mon, 17 Oct 2022 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/cs231n-chap-03-loss-function-and-optimization/</guid>
        <description>&lt;p&gt;본 chapter에서는 딥러닝의 기본 개념인 Loss Function, Regularization, Optization(Gradient Descent)에 대해 다룬다&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Video : &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=h7iBpEHGVNc&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.youtube.com/watch?v=h7iBpEHGVNc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slide : &lt;a class=&#34;link&#34; href=&#34;http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture3.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture3.pdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(TODO: 귀차니즘의 압박으로 정리를 안해놓았지만 언젠간 해야지)&lt;/p&gt;
&lt;h2 id=&#34;loss-function&#34;&gt;Loss function&lt;/h2&gt;
&lt;h2 id=&#34;regularization&#34;&gt;Regularization&lt;/h2&gt;
&lt;h2 id=&#34;softmax-and-svm&#34;&gt;Softmax and SVM&lt;/h2&gt;
&lt;h2 id=&#34;optimization&#34;&gt;Optimization&lt;/h2&gt;
&lt;h2 id=&#34;image-feature&#34;&gt;Image Feature&lt;/h2&gt;
</description>
        </item>
        <item>
        <title>[CS231n] Chap 02 Image classification</title>
        <link>https://muonkmu.github.io/p/cs231n-chap-02-image-classification/</link>
        <pubDate>Sat, 08 Oct 2022 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/cs231n-chap-02-image-classification/</guid>
        <description>&lt;p&gt;본 chapter에서는 Computer Vision의 핵심 Task 중 하나인 Image classification에 대해 이해하고 초기의 방법인 K-Nearest Neighbor Algorithm과 Linear Classification에 대하여 다룬다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Video : &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=OoUX-nOEjG0&amp;amp;list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk&amp;amp;index=2&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;www.youtube.com/watch?v=OoUX-nOEjG0&amp;list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk&amp;index=2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slide : &lt;a class=&#34;link&#34; href=&#34;http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture2.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture2.pdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(TODO: 귀차니즘의 압박으로 정리를 안해놓았지만 언젠간 해야지)&lt;/p&gt;
&lt;h2 id=&#34;image-classification-개요&#34;&gt;Image Classification 개요&lt;/h2&gt;
&lt;h2 id=&#34;k-nearest-neighbor-algorithm&#34;&gt;K-Nearest Neighbor Algorithm&lt;/h2&gt;
&lt;h2 id=&#34;linear-classification&#34;&gt;Linear Classification&lt;/h2&gt;
</description>
        </item>
        <item>
        <title>[Coursera_ML] Course certificate</title>
        <link>https://muonkmu.github.io/p/coursera_ml-course-certificate/</link>
        <pubDate>Tue, 25 Jan 2022 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/coursera_ml-course-certificate/</guid>
        <description>&lt;p&gt;6개월에 걸쳐 수료를 완료 했다. 3개월 코스라고 하던데&amp;hellip;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.coursera.org/learn/machine-learning&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.coursera.org/learn/machine-learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;homework repo : &lt;a class=&#34;link&#34; href=&#34;https://github.com/muonkmu/Coursera_AndrewNg_ML_Program.git&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/muonkmu/Coursera_AndrewNg_ML_Program.git&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(TODO: 귀차니즘의 압박으로 정리를 안해놓았지만 언젠간 해야지)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://muonkmu.github.io/p/coursera_ml-course-certificate/Coursera_ML_certificate.png&#34;
	width=&#34;1840&#34;
	height=&#34;1418&#34;
	srcset=&#34;https://muonkmu.github.io/p/coursera_ml-course-certificate/Coursera_ML_certificate_hub85ecee238eda8ef117fcde3ffb4434c_1057751_480x0_resize_box_3.png 480w, https://muonkmu.github.io/p/coursera_ml-course-certificate/Coursera_ML_certificate_hub85ecee238eda8ef117fcde3ffb4434c_1057751_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;129&#34;
		data-flex-basis=&#34;311px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>[Coursera_ML] Week_10) Gradient Descent with Large Datasets</title>
        <link>https://muonkmu.github.io/p/coursera_ml-week_10-gradient-descent-with-large-datasets/</link>
        <pubDate>Fri, 07 Jan 2022 00:00:00 +0000</pubDate>
        
        <guid>https://muonkmu.github.io/p/coursera_ml-week_10-gradient-descent-with-large-datasets/</guid>
        <description>&lt;p&gt;이번 강의에서는 대규모의 대규모의 데이터가 있을 때, 처리하는 알고리즘에 대해서 알아보자.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.coursera.org/learn/machine-learning&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.coursera.org/learn/machine-learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;homework repo : &lt;a class=&#34;link&#34; href=&#34;https://github.com/muonkmu/Coursera_AndrewNg_ML_Program.git&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/muonkmu/Coursera_AndrewNg_ML_Program.git&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(TODO: 귀차니즘의 압박으로 정리를 안해놓았지만 언젠간 해야지)&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
